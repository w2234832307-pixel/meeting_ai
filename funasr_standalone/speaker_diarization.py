#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯´è¯äººåˆ†ç¦»æ¨¡å—
ç”¨äº SenseVoiceSmall æ¨¡å‹çš„è¯´è¯äººè¯†åˆ«åŠŸèƒ½
"""
import logging
import subprocess
import tempfile
import os
from pathlib import Path
from typing import List, Dict
import numpy as np
from sklearn.cluster import AgglomerativeClustering

logger = logging.getLogger(__name__)


def perform_speaker_diarization_with_vad(
    audio_path: str,
    vad_segments: List,
    speaker_model,
    device: str = "cuda",
    min_segment_duration: float = 1.0,
    distance_threshold: float = 0.5
) -> List[Dict]:
    """
    åŸºäº VAD åˆ†æ®µè¿›è¡Œè¯´è¯äººåˆ†ç¦»
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        vad_segments: VAD åˆ†æ®µä¿¡æ¯ [[start_ms, end_ms], ...]
        speaker_model: Cam++ è¯´è¯äººæ¨¡å‹
        device: è®¾å¤‡
        min_segment_duration: æœ€å°ç‰‡æ®µæ—¶é•¿ï¼ˆç§’ï¼‰
        distance_threshold: èšç±»è·ç¦»é˜ˆå€¼ï¼ˆ0.3-0.7ï¼‰
    
    Returns:
        [{"start_time": 0.0, "end_time": 2.5, "speaker_id": "0"}, ...]
    """
    try:
        # 1. è¿‡æ»¤å¤ªçŸ­çš„ç‰‡æ®µå¹¶æå–å£°çº¹
        valid_segments = []
        embeddings = []
        
        logger.info(f"ğŸ”¬ ä¸º {len(vad_segments)} ä¸ª VAD æ®µæå–å£°çº¹ç‰¹å¾...")
        
        for idx, segment in enumerate(vad_segments):
            if not isinstance(segment, list) or len(segment) < 2:
                continue
            
            start_ms, end_ms = segment[0], segment[1]
            
            # å¤„ç† end_ms = -1 çš„æƒ…å†µï¼ˆè¡¨ç¤ºåˆ°éŸ³é¢‘ç»“å°¾ï¼‰
            if end_ms == -1:
                duration = 999999  # ä¸€ä¸ªå¾ˆå¤§çš„æ•°
            else:
                duration = (end_ms - start_ms) / 1000.0
            
            # è¿‡æ»¤å¤ªçŸ­çš„ç‰‡æ®µ
            if duration < min_segment_duration:
                logger.debug(f"â­ï¸ è·³è¿‡è¿‡çŸ­ç‰‡æ®µ {idx}: {duration:.2f}s")
                continue
            
            # æå–éŸ³é¢‘ç‰‡æ®µå¹¶è·å–å£°çº¹
            try:
                embedding = extract_speaker_embedding(
                    audio_path=audio_path,
                    start_ms=start_ms,
                    end_ms=end_ms if end_ms != -1 else None,
                    speaker_model=speaker_model
                )
                
                if embedding is not None:
                    embeddings.append(embedding)
                    valid_segments.append({
                        "start_time": round(start_ms / 1000.0, 2),
                        "end_time": round(end_ms / 1000.0, 2) if end_ms != -1 else 999999,
                        "segment_idx": idx
                    })
                    
            except Exception as e:
                logger.warning(f"âš ï¸ æå–ç‰‡æ®µ {idx} å£°çº¹å¤±è´¥: {e}")
                continue
        
        if len(valid_segments) == 0:
            logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„è¯­éŸ³ç‰‡æ®µ")
            return []
        
        logger.info(f"âœ… æˆåŠŸæå– {len(embeddings)} ä¸ªå£°çº¹ç‰¹å¾")
        
        # 2. å¦‚æœåªæœ‰ä¸€ä¸ªç‰‡æ®µï¼Œç›´æ¥æ ‡è®°ä¸ºè¯´è¯äºº0
        if len(embeddings) == 1:
            logger.info("â„¹ï¸ åªæœ‰ä¸€ä¸ªè¯­éŸ³æ®µï¼Œæ ‡è®°ä¸ºè¯´è¯äºº0")
            valid_segments[0]["speaker_id"] = "0"
            return valid_segments
        
        # 2.5. å¦‚æœåªæœ‰2ä¸ªç‰‡æ®µï¼Œç›´æ¥æ ‡è®°ä¸ºè¯´è¯äºº0å’Œ1
        if len(embeddings) == 2:
            logger.info("â„¹ï¸ åªæœ‰ä¸¤ä¸ªè¯­éŸ³æ®µï¼Œæ ‡è®°ä¸ºè¯´è¯äºº0å’Œ1")
            valid_segments[0]["speaker_id"] = "0"
            valid_segments[1]["speaker_id"] = "1"
            return valid_segments
        
        # 3. ä½¿ç”¨å±‚æ¬¡èšç±»è¿›è¡Œè¯´è¯äººåˆ†ç¦»
        logger.info(f"ğŸ”¬ è¿›è¡Œè¯´è¯äººèšç±»...")
        
        # ç¡®ä¿ embeddings æ˜¯ 2D æ•°ç»„ (n_samples, n_features)
        # Cam++ å¯èƒ½è¿”å› 3D æ•°ç»„ï¼Œéœ€è¦å±•å¹³
        embeddings_2d = []
        for emb in embeddings:
            emb_array = np.array(emb)
            # å¦‚æœæ˜¯ 3D æˆ–æ›´é«˜ç»´åº¦ï¼Œå±•å¹³ä¸º 1D
            if emb_array.ndim > 1:
                emb_array = emb_array.flatten()
            embeddings_2d.append(emb_array)
        
        embeddings_array = np.array(embeddings_2d)
        
        # éªŒè¯ç»´åº¦
        if embeddings_array.ndim != 2:
            logger.error(f"âŒ å£°çº¹å‘é‡ç»´åº¦é”™è¯¯: {embeddings_array.shape}ï¼ŒæœŸæœ› 2D (n_samples, n_features)")
            # é™çº§å¤„ç†ï¼šæ‰€æœ‰ç‰‡æ®µæ ‡è®°ä¸ºåŒä¸€è¯´è¯äºº
            for segment in valid_segments:
                segment["speaker_id"] = "0"
            return valid_segments
        
        logger.debug(f"âœ… å£°çº¹å‘é‡å½¢çŠ¶: {embeddings_array.shape}")
        
        # ä¼˜åŒ–èšç±»å‚æ•°ï¼šå‡å°‘è¯´è¯äººæ•°é‡ï¼ˆ12ä¸ªå¤ªå¤šï¼Œé€šå¸¸ä¼šè®®3-5äººï¼‰
        # è‡ªåŠ¨è°ƒæ•´è·ç¦»é˜ˆå€¼ï¼šå¦‚æœç‰‡æ®µå¾ˆå¤šï¼Œå¢å¤§é˜ˆå€¼ä»¥å‡å°‘è¯´è¯äººæ•°é‡
        if len(embeddings) > 30:
            # ç‰‡æ®µå¾ˆå¤šï¼Œå¢å¤§é˜ˆå€¼ï¼Œå‡å°‘è¯´è¯äººæ•°é‡
            adjusted_threshold = min(0.7, distance_threshold + 0.1)
            logger.info(f"ğŸ”§ ç‰‡æ®µè¾ƒå¤š({len(embeddings)}ä¸ª)ï¼Œè°ƒæ•´èšç±»é˜ˆå€¼ä¸º {adjusted_threshold:.2f}")
        else:
            adjusted_threshold = distance_threshold
        
        clustering = AgglomerativeClustering(
            n_clusters=None,
            distance_threshold=adjusted_threshold,  # è°ƒæ•´åçš„è·ç¦»é˜ˆå€¼
            metric='cosine',
            linkage='average'
        )
        
        cluster_labels = clustering.fit_predict(embeddings_array)
        
        # 4. æ˜¾ç¤ºçœŸå®çš„èšç±»ç»“æœï¼ˆè¯æ˜ä¸æ˜¯å†™æ­»çš„ï¼‰
        unique_labels = sorted(set(cluster_labels))
        logger.info(f"ğŸ¯ ã€çœŸå®èšç±»ç»“æœã€‘è¯†åˆ«å‡º {len(unique_labels)} ä¸ªä¸åŒçš„è¯´è¯äºº")
        logger.info(f"   åŸå§‹èšç±»æ ‡ç­¾: {unique_labels} (èŒƒå›´: {min(cluster_labels)}-{max(cluster_labels)})")
        
        # ç»Ÿè®¡æ¯ä¸ªèšç±»çš„ç‰‡æ®µæ•°é‡ï¼ˆè¯æ˜æ˜¯çœŸå®è¯†åˆ«ï¼‰
        cluster_counts = {}
        for label in cluster_labels:
            cluster_counts[label] = cluster_counts.get(label, 0) + 1
        logger.info(f"   å„è¯´è¯äººçš„ç‰‡æ®µæ•°é‡: {dict(sorted(cluster_counts.items()))}")
        
        # é‡æ–°æ˜ å°„è¯´è¯äººIDä¸ºè¿ç»­ç¼–å·ï¼ˆ0, 1, 2, 3...ï¼‰
        # æ³¨æ„ï¼šè¿™åªæ˜¯ç¼–å·è§„èŒƒåŒ–ï¼Œä¸å½±å“è¯†åˆ«ç»“æœï¼
        # å“ªäº›ç‰‡æ®µå±äºå“ªä¸ªè¯´è¯äººæ˜¯ç”±èšç±»ç®—æ³•å†³å®šçš„ï¼Œä¸æ˜¯å†™æ­»çš„
        label_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_labels)}
        logger.info(f"   ç¼–å·è§„èŒƒåŒ–æ˜ å°„: {label_mapping} (ä»…ç”¨äºç»Ÿä¸€ç¼–å·ï¼Œä¸å½±å“è¯†åˆ«ç»“æœ)")
        
        # 5. å°†èšç±»ç»“æœæ˜ å°„åˆ°ç‰‡æ®µï¼Œå¹¶é‡æ–°ç¼–å·
        # ä¿ç•™åŸå§‹èšç±»æ ‡ç­¾ç”¨äºéªŒè¯ï¼ˆè¯æ˜ä¸æ˜¯å†™æ­»çš„ï¼‰
        for idx, segment in enumerate(valid_segments):
            old_label = cluster_labels[idx]  # è¿™æ˜¯èšç±»ç®—æ³•çš„çœŸå®ç»“æœ
            new_label = label_mapping[old_label]  # è¿™åªæ˜¯ç¼–å·è§„èŒƒåŒ–
            segment["speaker_id"] = str(new_label)
            segment["_original_cluster_id"] = int(old_label)  # ä¿ç•™åŸå§‹æ ‡ç­¾ç”¨äºéªŒè¯
        
        n_speakers = len(unique_labels)
        
        # éªŒè¯æ˜ å°„åçš„IDæ˜¯å¦è¿ç»­
        mapped_ids = sorted(set(int(s["speaker_id"]) for s in valid_segments))
        expected_ids = list(range(n_speakers))
        
        if mapped_ids != expected_ids:
            logger.error(f"âŒ è¯´è¯äººIDæ˜ å°„é”™è¯¯: å®é™…={mapped_ids}, æœŸæœ›={expected_ids}")
            # å¼ºåˆ¶é‡æ–°æ˜ å°„
            for idx, segment in enumerate(valid_segments):
                segment["speaker_id"] = str(mapped_ids.index(int(segment["speaker_id"])))
        
        # æ˜¾ç¤ºè¯†åˆ«ç»“æœç¤ºä¾‹ï¼ˆè¯æ˜æ˜¯çœŸå®è¯†åˆ«ï¼‰
        logger.info(f"âœ… è¯†åˆ«å‡º {n_speakers} ä¸ªè¯´è¯äººï¼ˆID: 0-{n_speakers-1}ï¼‰")
        logger.info(f"   ã€éªŒè¯ã€‘å‰3ä¸ªç‰‡æ®µçš„åŸå§‹èšç±»ID: {[s.get('_original_cluster_id') for s in valid_segments[:3]]}")
        
        return valid_segments
        
    except Exception as e:
        logger.error(f"âŒ è¯´è¯äººåˆ†ç¦»å¤±è´¥: {e}", exc_info=True)
        return []


def extract_speaker_embedding(
    audio_path: str,
    start_ms: float,
    end_ms: float = None,
    speaker_model = None
) -> List[float]:
    """
    æå–éŸ³é¢‘ç‰‡æ®µçš„å£°çº¹ç‰¹å¾å‘é‡
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        start_ms: å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        end_ms: ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ï¼ŒNone è¡¨ç¤ºåˆ°éŸ³é¢‘ç»“å°¾
        speaker_model: Cam++ æ¨¡å‹
    
    Returns:
        å£°çº¹å‘é‡ï¼ˆ192ç»´ï¼‰
    """
    temp_segment_path = None
    
    try:
        # 1. ä½¿ç”¨ ffmpeg æå–éŸ³é¢‘ç‰‡æ®µ
        temp_segment = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
        temp_segment.close()
        temp_segment_path = temp_segment.name
        
        # æ„å»º ffmpeg å‘½ä»¤
        cmd = [
            "ffmpeg",
            "-i", audio_path,
            "-ss", str(start_ms / 1000.0),
        ]
        
        if end_ms is not None:
            duration = (end_ms - start_ms) / 1000.0
            cmd.extend(["-t", str(duration)])
        
        cmd.extend([
            "-ac", "1",              # å•å£°é“
            "-ar", "16000",          # 16kHz é‡‡æ ·ç‡
            "-y",
            "-loglevel", "error",
            temp_segment_path
        ])
        
        subprocess.run(cmd, check=True, capture_output=True, timeout=30)
        
        # 2. ä½¿ç”¨ Cam++ æ¨¡å‹æå–å£°çº¹
        emb_res = speaker_model.generate(input=temp_segment_path)
        
        if emb_res and len(emb_res) > 0:
            emb = emb_res[0].get("spk_embedding", None)
            if emb is not None:
                # è½¬æ¢ä¸º numpy æ•°ç»„å¹¶ç¡®ä¿æ˜¯ 1D
                emb_array = np.array(emb)
                
                # å¦‚æœæ˜¯å¤šç»´æ•°ç»„ï¼Œå±•å¹³ä¸º 1D
                if emb_array.ndim > 1:
                    emb_array = emb_array.flatten()
                
                # è½¬æ¢ä¸º Python list
                return emb_array.tolist()
        
        return None
        
    except subprocess.TimeoutExpired:
        logger.warning("âš ï¸ ffmpeg æå–è¶…æ—¶")
        return None
    except subprocess.CalledProcessError as e:
        logger.warning(f"âš ï¸ ffmpeg æå–å¤±è´¥: {e}")
        return None
    except Exception as e:
        logger.warning(f"âš ï¸ å£°çº¹æå–å¼‚å¸¸: {e}")
        return None
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_segment_path and os.path.exists(temp_segment_path):
            try:
                os.remove(temp_segment_path)
            except:
                pass
