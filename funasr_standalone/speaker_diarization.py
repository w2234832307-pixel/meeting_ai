#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯´è¯äººåˆ†ç¦»æ¨¡å—
ç”¨äº SenseVoiceSmall æ¨¡å‹çš„è¯´è¯äººè¯†åˆ«åŠŸèƒ½
"""
import logging
import subprocess
import tempfile
import os
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import numpy as np
from sklearn.cluster import AgglomerativeClustering
import soundfile as sf

logger = logging.getLogger(__name__)


def perform_speaker_diarization_with_vad(
    audio_path: str,
    vad_segments: List,
    speaker_model,
    device: str = "cuda",
    min_segment_duration: float = 1.0,
    distance_threshold: float = 0.3  # é™ä½é»˜è®¤é˜ˆå€¼ï¼Œç¡®ä¿èƒ½è¯†åˆ«å‡ºå¤šä¸ªè¯´è¯äºº
) -> List[Dict]:
    """
    åŸºäº VAD åˆ†æ®µè¿›è¡Œè¯´è¯äººåˆ†ç¦»
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        vad_segments: VAD åˆ†æ®µä¿¡æ¯ [[start_ms, end_ms], ...]
        speaker_model: Cam++ è¯´è¯äººæ¨¡å‹
        device: è®¾å¤‡
        min_segment_duration: æœ€å°ç‰‡æ®µæ—¶é•¿ï¼ˆç§’ï¼‰
        distance_threshold: èšç±»è·ç¦»é˜ˆå€¼ï¼ˆ0.3-0.7ï¼‰
    
    Returns:
        [{"start_time": 0.0, "end_time": 2.5, "speaker_id": "0"}, ...]
    """
    try:
        # 1. è¿‡æ»¤å¤ªçŸ­çš„ç‰‡æ®µå¹¶æå–å£°çº¹
        valid_segments = []
        embeddings = []
        
        logger.info(f"ğŸ”¬ ä¸º {len(vad_segments)} ä¸ª VAD æ®µæå–å£°çº¹ç‰¹å¾...")
        
        for idx, segment in enumerate(vad_segments):
            if not isinstance(segment, list) or len(segment) < 2:
                continue
            
            start_ms, end_ms = segment[0], segment[1]
            
            # å¤„ç† end_ms = -1 çš„æƒ…å†µï¼ˆè¡¨ç¤ºåˆ°éŸ³é¢‘ç»“å°¾ï¼‰
            if end_ms == -1:
                duration = 999999  # ä¸€ä¸ªå¾ˆå¤§çš„æ•°
            else:
                duration = (end_ms - start_ms) / 1000.0
            
            # è¿‡æ»¤å¤ªçŸ­çš„ç‰‡æ®µ
            if duration < min_segment_duration:
                logger.debug(f"â­ï¸ è·³è¿‡è¿‡çŸ­ç‰‡æ®µ {idx}: {duration:.2f}s")
                continue
            
            # æå–éŸ³é¢‘ç‰‡æ®µå¹¶è·å–å£°çº¹
            try:
                embedding = extract_speaker_embedding(
                    audio_path=audio_path,
                    start_ms=start_ms,
                    end_ms=end_ms if end_ms != -1 else None,
                    speaker_model=speaker_model
                )
                
                if embedding is not None:
                    embeddings.append(embedding)
                    valid_segments.append({
                        "start_time": round(start_ms / 1000.0, 2),
                        "end_time": round(end_ms / 1000.0, 2) if end_ms != -1 else 999999,
                        "segment_idx": idx
                    })
                    
            except Exception as e:
                logger.warning(f"âš ï¸ æå–ç‰‡æ®µ {idx} å£°çº¹å¤±è´¥: {e}")
                continue
        
        if len(valid_segments) == 0:
            logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„è¯­éŸ³ç‰‡æ®µ")
            return []
        
        logger.info(f"âœ… æˆåŠŸæå– {len(embeddings)} ä¸ªå£°çº¹ç‰¹å¾")
        
        # 2. å¦‚æœåªæœ‰ä¸€ä¸ªç‰‡æ®µï¼Œç›´æ¥æ ‡è®°ä¸ºè¯´è¯äºº0
        if len(embeddings) == 1:
            logger.info("â„¹ï¸ åªæœ‰ä¸€ä¸ªè¯­éŸ³æ®µï¼Œæ ‡è®°ä¸ºè¯´è¯äºº0")
            valid_segments[0]["speaker_id"] = "0"
            return valid_segments
        
        # 2.5. å¦‚æœåªæœ‰2ä¸ªç‰‡æ®µï¼Œç›´æ¥æ ‡è®°ä¸ºè¯´è¯äºº0å’Œ1
        if len(embeddings) == 2:
            logger.info("â„¹ï¸ åªæœ‰ä¸¤ä¸ªè¯­éŸ³æ®µï¼Œæ ‡è®°ä¸ºè¯´è¯äºº0å’Œ1")
            valid_segments[0]["speaker_id"] = "0"
            valid_segments[1]["speaker_id"] = "1"
            return valid_segments
        
        # 3. ä½¿ç”¨å±‚æ¬¡èšç±»è¿›è¡Œè¯´è¯äººåˆ†ç¦»
        logger.info(f"ğŸ”¬ è¿›è¡Œè¯´è¯äººèšç±»...")
        
        # ç¡®ä¿ embeddings æ˜¯ 2D æ•°ç»„ (n_samples, n_features)
        # Cam++ å¯èƒ½è¿”å› 3D æ•°ç»„ï¼Œéœ€è¦å±•å¹³
        embeddings_2d = []
        for emb in embeddings:
            emb_array = np.array(emb)
            # å¦‚æœæ˜¯ 3D æˆ–æ›´é«˜ç»´åº¦ï¼Œå±•å¹³ä¸º 1D
            if emb_array.ndim > 1:
                emb_array = emb_array.flatten()
            embeddings_2d.append(emb_array)
        
        embeddings_array = np.array(embeddings_2d)
        
        # éªŒè¯ç»´åº¦
        if embeddings_array.ndim != 2:
            logger.error(f"âŒ å£°çº¹å‘é‡ç»´åº¦é”™è¯¯: {embeddings_array.shape}ï¼ŒæœŸæœ› 2D (n_samples, n_features)")
            # é™çº§å¤„ç†ï¼šæ‰€æœ‰ç‰‡æ®µæ ‡è®°ä¸ºåŒä¸€è¯´è¯äºº
            for segment in valid_segments:
                segment["speaker_id"] = "0"
            return valid_segments
        
        logger.debug(f"âœ… å£°çº¹å‘é‡å½¢çŠ¶: {embeddings_array.shape}")
        
        # ä¼˜åŒ–èšç±»å‚æ•°ï¼šé™ä½é˜ˆå€¼ï¼Œç¡®ä¿èƒ½è¯†åˆ«å‡ºå¤šä¸ªè¯´è¯äºº
        # å¦‚æœåªè¯†åˆ«å‡º1ä¸ªè¯´è¯äººï¼Œè¯´æ˜é˜ˆå€¼å¤ªé«˜ï¼Œéœ€è¦é™ä½
        # è‡ªåŠ¨è°ƒæ•´è·ç¦»é˜ˆå€¼ï¼šæ ¹æ®ç‰‡æ®µæ•°é‡åŠ¨æ€è°ƒæ•´
        if len(embeddings) > 100:
            # ç‰‡æ®µå¾ˆå¤šï¼Œç¨å¾®å¢å¤§é˜ˆå€¼ï¼ˆä½†ä¸è¦å¤ªå¤§ï¼Œé¿å…åªè¯†åˆ«å‡º1ä¸ªäººï¼‰
            adjusted_threshold = min(0.6, distance_threshold + 0.05)
            logger.info(f"ğŸ”§ ç‰‡æ®µè¾ƒå¤š({len(embeddings)}ä¸ª)ï¼Œè°ƒæ•´èšç±»é˜ˆå€¼ä¸º {adjusted_threshold:.2f}")
        elif len(embeddings) > 50:
            # ç‰‡æ®µä¸­ç­‰ï¼Œä¿æŒæˆ–ç¨å¾®é™ä½é˜ˆå€¼
            adjusted_threshold = max(0.3, distance_threshold - 0.05)
            logger.info(f"ğŸ”§ ç‰‡æ®µä¸­ç­‰({len(embeddings)}ä¸ª)ï¼Œè°ƒæ•´èšç±»é˜ˆå€¼ä¸º {adjusted_threshold:.2f}")
        else:
            # ç‰‡æ®µè¾ƒå°‘ï¼Œé™ä½é˜ˆå€¼ï¼Œç¡®ä¿èƒ½è¯†åˆ«å‡ºå¤šä¸ªè¯´è¯äºº
            adjusted_threshold = max(0.25, distance_threshold - 0.1)
            logger.info(f"ğŸ”§ ç‰‡æ®µè¾ƒå°‘({len(embeddings)}ä¸ª)ï¼Œé™ä½èšç±»é˜ˆå€¼ä¸º {adjusted_threshold:.2f} ä»¥è¯†åˆ«æ›´å¤šè¯´è¯äºº")
        
        clustering = AgglomerativeClustering(
            n_clusters=None,
            distance_threshold=adjusted_threshold,  # è°ƒæ•´åçš„è·ç¦»é˜ˆå€¼
            metric='cosine',
            linkage='average'
        )
        
        cluster_labels = clustering.fit_predict(embeddings_array)
        
        # 4. æ˜¾ç¤ºçœŸå®çš„èšç±»ç»“æœï¼ˆè¯æ˜ä¸æ˜¯å†™æ­»çš„ï¼‰
        unique_labels = sorted(set(cluster_labels))
        logger.info(f"ğŸ¯ ã€çœŸå®èšç±»ç»“æœã€‘è¯†åˆ«å‡º {len(unique_labels)} ä¸ªä¸åŒçš„è¯´è¯äºº")
        logger.info(f"   åŸå§‹èšç±»æ ‡ç­¾: {unique_labels} (èŒƒå›´: {min(cluster_labels)}-{max(cluster_labels)})")
        
        # ç»Ÿè®¡æ¯ä¸ªèšç±»çš„ç‰‡æ®µæ•°é‡ï¼ˆè¯æ˜æ˜¯çœŸå®è¯†åˆ«ï¼‰
        cluster_counts = {}
        for label in cluster_labels:
            cluster_counts[label] = cluster_counts.get(label, 0) + 1
        logger.info(f"   å„è¯´è¯äººçš„ç‰‡æ®µæ•°é‡: {dict(sorted(cluster_counts.items()))}")
        
        # é‡æ–°æ˜ å°„è¯´è¯äººIDä¸ºè¿ç»­ç¼–å·ï¼ˆ0, 1, 2, 3...ï¼‰
        # æ³¨æ„ï¼šè¿™åªæ˜¯ç¼–å·è§„èŒƒåŒ–ï¼Œä¸å½±å“è¯†åˆ«ç»“æœï¼
        # å“ªäº›ç‰‡æ®µå±äºå“ªä¸ªè¯´è¯äººæ˜¯ç”±èšç±»ç®—æ³•å†³å®šçš„ï¼Œä¸æ˜¯å†™æ­»çš„
        label_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_labels)}
        logger.info(f"   ç¼–å·è§„èŒƒåŒ–æ˜ å°„: {label_mapping} (ä»…ç”¨äºç»Ÿä¸€ç¼–å·ï¼Œä¸å½±å“è¯†åˆ«ç»“æœ)")
        
        # 5. å°†èšç±»ç»“æœæ˜ å°„åˆ°ç‰‡æ®µï¼Œå¹¶é‡æ–°ç¼–å·
        # ä¿ç•™åŸå§‹èšç±»æ ‡ç­¾ç”¨äºéªŒè¯ï¼ˆè¯æ˜ä¸æ˜¯å†™æ­»çš„ï¼‰
        for idx, segment in enumerate(valid_segments):
            old_label = cluster_labels[idx]  # è¿™æ˜¯èšç±»ç®—æ³•çš„çœŸå®ç»“æœ
            new_label = label_mapping[old_label]  # è¿™åªæ˜¯ç¼–å·è§„èŒƒåŒ–
            segment["speaker_id"] = str(new_label)
            segment["_original_cluster_id"] = int(old_label)  # ä¿ç•™åŸå§‹æ ‡ç­¾ç”¨äºéªŒè¯
        
        n_speakers = len(unique_labels)
        
        # éªŒè¯æ˜ å°„åçš„IDæ˜¯å¦è¿ç»­
        mapped_ids = sorted(set(int(s["speaker_id"]) for s in valid_segments))
        expected_ids = list(range(n_speakers))
        
        if mapped_ids != expected_ids:
            logger.error(f"âŒ è¯´è¯äººIDæ˜ å°„é”™è¯¯: å®é™…={mapped_ids}, æœŸæœ›={expected_ids}")
            # å¼ºåˆ¶é‡æ–°æ˜ å°„
            for idx, segment in enumerate(valid_segments):
                segment["speaker_id"] = str(mapped_ids.index(int(segment["speaker_id"])))
        
        # æ˜¾ç¤ºè¯†åˆ«ç»“æœç¤ºä¾‹ï¼ˆè¯æ˜æ˜¯çœŸå®è¯†åˆ«ï¼‰
        logger.info(f"âœ… è¯†åˆ«å‡º {n_speakers} ä¸ªè¯´è¯äººï¼ˆID: 0-{n_speakers-1}ï¼‰")
        logger.info(f"   ã€éªŒè¯ã€‘å‰3ä¸ªç‰‡æ®µçš„åŸå§‹èšç±»ID: {[s.get('_original_cluster_id') for s in valid_segments[:3]]}")
        
        return valid_segments
        
    except Exception as e:
        logger.error(f"âŒ è¯´è¯äººåˆ†ç¦»å¤±è´¥: {e}", exc_info=True)
        return []


def perform_speaker_diarization_with_cached_audio(
    vad_segments: List,
    cached_audio_map: Dict[int, Tuple[np.ndarray, int]],
    speaker_model,
    device: str = "cuda",
    min_segment_duration: float = 1.0,
    distance_threshold: float = 0.5,
    audio_file_path: str = None
) -> List[Dict]:
    """
    åŸºäºç¼“å­˜çš„éŸ³é¢‘æ•°æ®è¿›è¡Œè¯´è¯äººåˆ†ç¦»ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    
    Args:
        vad_segments: VAD åˆ†æ®µä¿¡æ¯ [[start_ms, end_ms], ...]
        cached_audio_map: ç¼“å­˜çš„éŸ³é¢‘æ•°æ® {segment_idx: (audio_data, sample_rate)}
        speaker_model: Cam++ è¯´è¯äººæ¨¡å‹
        device: è®¾å¤‡
        min_segment_duration: æœ€å°ç‰‡æ®µæ—¶é•¿ï¼ˆç§’ï¼‰
        distance_threshold: èšç±»è·ç¦»é˜ˆå€¼ï¼ˆ0.3-0.7ï¼‰
        audio_file_path: åŸå§‹éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆé™çº§æ—¶ä½¿ç”¨ï¼‰
    
    Returns:
        [{"start_time": 0.0, "end_time": 2.5, "speaker_id": "0"}, ...]
    """
    try:
        # 1. è¿‡æ»¤å¤ªçŸ­çš„ç‰‡æ®µå¹¶æå–å£°çº¹ï¼ˆä½¿ç”¨ç¼“å­˜çš„éŸ³é¢‘æ•°æ®ï¼‰
        valid_segments = []
        embeddings = []
        
        logger.info(f"ğŸ”¬ ä¸º {len(vad_segments)} ä¸ª VAD æ®µæå–å£°çº¹ç‰¹å¾ï¼ˆä½¿ç”¨ç¼“å­˜éŸ³é¢‘ï¼‰...")
        
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        MAX_CONCURRENT = 2  # æ§åˆ¶å¹¶å‘æ•°ï¼ˆ10GBæ˜¾å­˜ï¼‰
        
        def extract_embedding_from_cache(idx, segment):
            """ä»ç¼“å­˜éŸ³é¢‘æ•°æ®æå–å£°çº¹"""
            if not isinstance(segment, list) or len(segment) < 2:
                return None, None
            
            start_ms, end_ms = segment[0], segment[1]
            
            # å¤„ç† end_ms = -1 çš„æƒ…å†µ
            if end_ms == -1:
                duration = 999999
            else:
                duration = (end_ms - start_ms) / 1000.0
            
            # è¿‡æ»¤å¤ªçŸ­çš„ç‰‡æ®µ
            if duration < min_segment_duration:
                logger.debug(f"â­ï¸ è·³è¿‡è¿‡çŸ­ç‰‡æ®µ {idx}: {duration:.2f}s")
                return None, None
            
            # ä¼˜å…ˆä½¿ç”¨ç¼“å­˜çš„éŸ³é¢‘æ•°æ®
            if idx in cached_audio_map:
                audio_data, sample_rate = cached_audio_map[idx]
                
                try:
                    # å°†å†…å­˜ä¸­çš„éŸ³é¢‘æ•°æ®å†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼ˆæ¨¡å‹éœ€è¦æ–‡ä»¶è·¯å¾„ï¼‰
                    temp_segment = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
                    temp_segment.close()
                    temp_segment_path = temp_segment.name
                    
                    sf.write(temp_segment_path, audio_data, sample_rate)
                    
                    # ä½¿ç”¨ Cam++ æ¨¡å‹æå–å£°çº¹
                    emb_res = speaker_model.generate(input=temp_segment_path)
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    try:
                        os.remove(temp_segment_path)
                    except:
                        pass
                    
                    if emb_res and len(emb_res) > 0:
                        emb = emb_res[0].get("spk_embedding", None)
                        if emb is not None:
                            emb_array = np.array(emb)
                            if emb_array.ndim > 1:
                                emb_array = emb_array.flatten()
                            return emb_array.tolist(), {
                                "start_time": round(start_ms / 1000.0, 2),
                                "end_time": round(end_ms / 1000.0, 2) if end_ms != -1 else 999999,
                                "segment_idx": idx
                            }
                except Exception as e:
                    logger.warning(f"âš ï¸ ä»ç¼“å­˜æå–ç‰‡æ®µ {idx} å£°çº¹å¤±è´¥: {e}")
            
            # é™çº§ï¼šå¦‚æœç¼“å­˜ä¸­æ²¡æœ‰ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶æå–
            if audio_file_path:
                try:
                    embedding = extract_speaker_embedding(
                        audio_path=audio_file_path,
                        start_ms=start_ms,
                        end_ms=end_ms if end_ms != -1 else None,
                        speaker_model=speaker_model
                    )
                    if embedding:
                        return embedding, {
                            "start_time": round(start_ms / 1000.0, 2),
                            "end_time": round(end_ms / 1000.0, 2) if end_ms != -1 else 999999,
                            "segment_idx": idx
                        }
                except Exception as e:
                    logger.warning(f"âš ï¸ é™çº§æå–ç‰‡æ®µ {idx} å£°çº¹å¤±è´¥: {e}")
            
            return None, None
        
        # ä¼˜åŒ–3: å¹¶è¡Œæå–å£°çº¹ï¼ˆæ§åˆ¶å¹¶å‘æ•°ï¼‰
        with ThreadPoolExecutor(max_workers=MAX_CONCURRENT) as executor:
            futures = {
                executor.submit(extract_embedding_from_cache, idx, segment): idx
                for idx, segment in enumerate(vad_segments)
            }
            
            for future in as_completed(futures):
                idx = futures[future]
                try:
                    embedding, segment_info = future.result()
                    if embedding is not None and segment_info is not None:
                        embeddings.append(embedding)
                        valid_segments.append(segment_info)
                except Exception as e:
                    logger.warning(f"âš ï¸ æå–ç‰‡æ®µ {idx} å£°çº¹å¼‚å¸¸: {e}")
        
        if len(valid_segments) == 0:
            logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„è¯­éŸ³ç‰‡æ®µ")
            return []
        
        logger.info(f"âœ… æˆåŠŸæå– {len(embeddings)} ä¸ªå£°çº¹ç‰¹å¾ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰")
        
        # 2. å¦‚æœåªæœ‰ä¸€ä¸ªç‰‡æ®µï¼Œç›´æ¥æ ‡è®°ä¸ºè¯´è¯äºº0
        if len(embeddings) == 1:
            logger.info("â„¹ï¸ åªæœ‰ä¸€ä¸ªè¯­éŸ³æ®µï¼Œæ ‡è®°ä¸ºè¯´è¯äºº0")
            valid_segments[0]["speaker_id"] = "0"
            return valid_segments
        
        # 2.5. å¦‚æœåªæœ‰2ä¸ªç‰‡æ®µï¼Œç›´æ¥æ ‡è®°ä¸ºè¯´è¯äºº0å’Œ1
        if len(embeddings) == 2:
            logger.info("â„¹ï¸ åªæœ‰ä¸¤ä¸ªè¯­éŸ³æ®µï¼Œæ ‡è®°ä¸ºè¯´è¯äºº0å’Œ1")
            valid_segments[0]["speaker_id"] = "0"
            valid_segments[1]["speaker_id"] = "1"
            return valid_segments
        
        # 3. ä½¿ç”¨å±‚æ¬¡èšç±»è¿›è¡Œè¯´è¯äººåˆ†ç¦»ï¼ˆä¸åŸå‡½æ•°ç›¸åŒï¼‰
        logger.info(f"ğŸ”¬ è¿›è¡Œè¯´è¯äººèšç±»...")
        
        embeddings_2d = []
        for emb in embeddings:
            emb_array = np.array(emb)
            if emb_array.ndim > 1:
                emb_array = emb_array.flatten()
            embeddings_2d.append(emb_array)
        
        embeddings_array = np.array(embeddings_2d)
        
        if embeddings_array.ndim != 2:
            logger.error(f"âŒ å£°çº¹å‘é‡ç»´åº¦é”™è¯¯: {embeddings_array.shape}")
            for segment in valid_segments:
                segment["speaker_id"] = "0"
            return valid_segments
        
        logger.debug(f"âœ… å£°çº¹å‘é‡å½¢çŠ¶: {embeddings_array.shape}")
        
        # è‡ªåŠ¨è°ƒæ•´è·ç¦»é˜ˆå€¼
        if len(embeddings) > 30:
            adjusted_threshold = min(0.7, distance_threshold + 0.1)
            logger.info(f"ğŸ”§ ç‰‡æ®µè¾ƒå¤š({len(embeddings)}ä¸ª)ï¼Œè°ƒæ•´èšç±»é˜ˆå€¼ä¸º {adjusted_threshold:.2f}")
        else:
            adjusted_threshold = distance_threshold
        
        clustering = AgglomerativeClustering(
            n_clusters=None,
            distance_threshold=adjusted_threshold,
            metric='cosine',
            linkage='average'
        )
        
        cluster_labels = clustering.fit_predict(embeddings_array)
        
        # 4. æ˜¾ç¤ºçœŸå®çš„èšç±»ç»“æœ
        unique_labels = sorted(set(cluster_labels))
        logger.info(f"ğŸ¯ ã€çœŸå®èšç±»ç»“æœã€‘è¯†åˆ«å‡º {len(unique_labels)} ä¸ªä¸åŒçš„è¯´è¯äºº")
        logger.info(f"   åŸå§‹èšç±»æ ‡ç­¾: {unique_labels} (èŒƒå›´: {min(cluster_labels)}-{max(cluster_labels)})")
        
        cluster_counts = {}
        for label in cluster_labels:
            cluster_counts[label] = cluster_counts.get(label, 0) + 1
        logger.info(f"   å„è¯´è¯äººçš„ç‰‡æ®µæ•°é‡: {dict(sorted(cluster_counts.items()))}")
        
        # é‡æ–°æ˜ å°„è¯´è¯äººIDä¸ºè¿ç»­ç¼–å·ï¼ˆ0, 1, 2, 3...ï¼‰
        label_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_labels)}
        logger.info(f"   ç¼–å·è§„èŒƒåŒ–æ˜ å°„: {label_mapping}")
        
        # 5. å°†èšç±»ç»“æœæ˜ å°„åˆ°ç‰‡æ®µ
        for idx, segment in enumerate(valid_segments):
            old_label = cluster_labels[idx]
            new_label = label_mapping[old_label]
            segment["speaker_id"] = str(new_label)
            segment["_original_cluster_id"] = int(old_label)
        
        n_speakers = len(unique_labels)
        
        # éªŒè¯æ˜ å°„åçš„IDæ˜¯å¦è¿ç»­
        mapped_ids = sorted(set(int(s["speaker_id"]) for s in valid_segments))
        expected_ids = list(range(n_speakers))
        
        if mapped_ids != expected_ids:
            logger.error(f"âŒ è¯´è¯äººIDæ˜ å°„é”™è¯¯: å®é™…={mapped_ids}, æœŸæœ›={expected_ids}")
            for idx, segment in enumerate(valid_segments):
                segment["speaker_id"] = str(mapped_ids.index(int(segment["speaker_id"])))
        
        logger.info(f"âœ… è¯†åˆ«å‡º {n_speakers} ä¸ªè¯´è¯äººï¼ˆID: 0-{n_speakers-1}ï¼‰")
        
        return valid_segments
        
    except Exception as e:
        logger.error(f"âŒ è¯´è¯äººåˆ†ç¦»å¤±è´¥: {e}", exc_info=True)
        return []


def extract_speaker_embedding(
    audio_path: str,
    start_ms: float,
    end_ms: float = None,
    speaker_model = None
) -> List[float]:
    """
    æå–éŸ³é¢‘ç‰‡æ®µçš„å£°çº¹ç‰¹å¾å‘é‡
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        start_ms: å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        end_ms: ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ï¼ŒNone è¡¨ç¤ºåˆ°éŸ³é¢‘ç»“å°¾
        speaker_model: Cam++ æ¨¡å‹
    
    Returns:
        å£°çº¹å‘é‡ï¼ˆ192ç»´ï¼‰
    """
    temp_segment_path = None
    
    try:
        # 1. ä½¿ç”¨ ffmpeg æå–éŸ³é¢‘ç‰‡æ®µ
        temp_segment = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
        temp_segment.close()
        temp_segment_path = temp_segment.name
        
        # æ„å»º ffmpeg å‘½ä»¤
        cmd = [
            "ffmpeg",
            "-i", audio_path,
            "-ss", str(start_ms / 1000.0),
        ]
        
        if end_ms is not None:
            duration = (end_ms - start_ms) / 1000.0
            cmd.extend(["-t", str(duration)])
        
        cmd.extend([
            "-ac", "1",              # å•å£°é“
            "-ar", "16000",          # 16kHz é‡‡æ ·ç‡
            "-y",
            "-loglevel", "error",
            temp_segment_path
        ])
        
        subprocess.run(cmd, check=True, capture_output=True, timeout=30)
        
        # 2. ä½¿ç”¨ Cam++ æ¨¡å‹æå–å£°çº¹
        emb_res = speaker_model.generate(input=temp_segment_path)
        
        if emb_res and len(emb_res) > 0:
            emb = emb_res[0].get("spk_embedding", None)
            if emb is not None:
                # è½¬æ¢ä¸º numpy æ•°ç»„å¹¶ç¡®ä¿æ˜¯ 1D
                emb_array = np.array(emb)
                
                # å¦‚æœæ˜¯å¤šç»´æ•°ç»„ï¼Œå±•å¹³ä¸º 1D
                if emb_array.ndim > 1:
                    emb_array = emb_array.flatten()
                
                # è½¬æ¢ä¸º Python list
                return emb_array.tolist()
        
        return None
        
    except subprocess.TimeoutExpired:
        logger.warning("âš ï¸ ffmpeg æå–è¶…æ—¶")
        return None
    except subprocess.CalledProcessError as e:
        logger.warning(f"âš ï¸ ffmpeg æå–å¤±è´¥: {e}")
        return None
    except Exception as e:
        logger.warning(f"âš ï¸ å£°çº¹æå–å¼‚å¸¸: {e}")
        return None
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_segment_path and os.path.exists(temp_segment_path):
            try:
                os.remove(temp_segment_path)
            except:
                pass
