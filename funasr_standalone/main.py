#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FunASR ç‹¬ç«‹æœåŠ¡ - ç”Ÿäº§çº§é…ç½®
ç«¯å£: 8002
åŠŸèƒ½: CPUé‡åŒ–åŠ é€Ÿ + è‡ªåŠ¨æ—¥å¿—è®°å½•
"""
# =============================================
# 0. ä¿®å¤ datasets å…¼å®¹æ€§é—®é¢˜ï¼ˆå¿…é¡»åœ¨å¯¼å…¥å…¶ä»–æ¨¡å—ä¹‹å‰ï¼‰
# =============================================
def _fix_datasets_compatibility():
    """ä¿®å¤ datasets ä¸ modelscope çš„å…¼å®¹æ€§é—®é¢˜"""
    try:
        import datasets
        
        # ä¿®å¤ LargeList å¯¼å…¥
        if not hasattr(datasets, 'LargeList'):
            try:
                from datasets import LargeList
            except ImportError:
                try:
                    import pyarrow as pa
                    if hasattr(pa, 'large_list'):
                        datasets.LargeList = pa.large_list
                    elif hasattr(pa, 'LargeList'):
                        datasets.LargeList = pa.LargeList
                except Exception:
                    pass
        
        # ä¿®å¤ _FEATURE_TYPES å¯¼å…¥ï¼ˆdatasets 2.19+ ä¸­å¯èƒ½å·²ç§»é™¤ï¼‰
        try:
            from datasets.features.features import _FEATURE_TYPES
        except ImportError:
            try:
                # å°è¯•ä»æ–°ä½ç½®å¯¼å…¥
                from datasets.features import _FEATURE_TYPES
            except ImportError:
                try:
                    # å¦‚æœä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªå…¼å®¹çš„å ä½ç¬¦
                    import datasets.features.features as features_module
                    if not hasattr(features_module, '_FEATURE_TYPES'):
                        # åˆ›å»ºä¸€ä¸ªç©ºçš„å­—å…¸ä½œä¸ºå ä½ç¬¦
                        features_module._FEATURE_TYPES = {}
                except Exception:
                    pass
    except Exception:
        pass  # å¦‚æœ datasets éƒ½å¯¼å…¥ä¸äº†ï¼Œè®©åç»­ä»£ç è‡ªå·±å¤„ç†é”™è¯¯

# ç«‹å³æ‰§è¡Œä¿®å¤
_fix_datasets_compatibility()

import os
import sys
import logging
from logging.handlers import RotatingFileHandler
from pathlib import Path
from fastapi import FastAPI, UploadFile, File, HTTPException, Form, APIRouter
import uvicorn
import tempfile
import shutil
import gc
import torch
from hotword_service import get_hotword_service  # âœ… å¯¼å…¥çƒ­è¯æœåŠ¡
from audio_preprocessor import audio_preprocessor  # âœ… å¯¼å…¥éŸ³é¢‘é¢„å¤„ç†
# å£°çº¹åŒ¹é…å»¶è¿ŸåŠ è½½ï¼Œé¿å…å¯åŠ¨æ—¶çš„ä¾èµ–é”™è¯¯
# from voice_matcher import get_voice_matcher

# =============================================
# 1. æ—¥å¿—é…ç½® (å­˜å…¥ ./logs ç›®å½•)
# =============================================
# ç¡®ä¿ logs ç›®å½•å­˜åœ¨
LOG_DIR = Path(__file__).parent / "logs"
LOG_DIR.mkdir(exist_ok=True)
LOG_FILE = LOG_DIR / "funasr_service.log"

# åˆ›å»º logger
logger = logging.getLogger("funasr_service")
logger.setLevel(logging.INFO)

# æ ¼å¼ï¼šæ—¶é—´ - çº§åˆ« - æ¶ˆæ¯
formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")

# å¤„ç†å™¨1ï¼šæ§åˆ¶å°è¾“å‡º 
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setFormatter(formatter)

# å¤„ç†å™¨2ï¼šæ–‡ä»¶è¾“å‡º (è‡ªåŠ¨åˆ‡å‰²ï¼Œé˜²æ­¢å æ»¡ç£ç›˜)
# maxBytes=10MB (æ¯ä¸ªæ–‡ä»¶æœ€å¤§10M), backupCount=10 (æœ€å¤šä¿ç•™10ä¸ªæ–‡ä»¶)
file_handler = RotatingFileHandler(LOG_FILE, maxBytes=10*1024*1024, backupCount=10, encoding='utf-8')
file_handler.setFormatter(formatter)

# é¿å…é‡å¤æ·»åŠ 
if not logger.handlers:
    logger.addHandler(console_handler)
    logger.addHandler(file_handler)

# =============================================
# 2. æ¨¡å‹åŠ è½½ (CPU ä¼˜åŒ–)
# =============================================
try:
    from funasr import AutoModel
    logger.info("ğŸ“¦ æ­£åœ¨åˆå§‹åŒ–æœåŠ¡...")
    
    if torch.cuda.is_available():
        DEVICE = "cuda"
        logger.info("âœ… æ£€æµ‹åˆ°å¯ç”¨ GPUï¼Œä½¿ç”¨ CUDA åŠ é€Ÿ")
    else:
        DEVICE = "cpu"
        logger.info("âš ï¸ æœªæ£€æµ‹åˆ° GPUï¼Œä½¿ç”¨ CPU æ¨¡å¼")
        
    # å¢åŠ çº¿ç¨‹æ•°ä»¥åˆ©ç”¨æœåŠ¡å™¨çš„ 16æ ¸ CPU
    NCPU = 8 
    
    logger.info(f"âš™ï¸ åŠ è½½æ¨¡å‹ä¸­... (Device: {DEVICE}, Threads: {NCPU})")
    
    # =================== é…ç½®ï¼šSenseVoiceSmall é«˜å‡†ç¡®ç‡æ–¹æ¡ˆ ===================
    # ç­–ç•¥ï¼šSenseVoiceSmall ç”¨äºé«˜å‡†ç¡®ç‡è¯†åˆ«ï¼ŒVAD å’Œè¯´è¯äººåˆ†ç¦»ç‹¬ç«‹å¤„ç†
    
    # 1. SenseVoiceSmall ä¸»æ¨¡å‹ï¼ˆä»…è¯†åˆ«ï¼Œä¸ä½¿ç”¨ spk_modelï¼‰
    logger.info("ğŸ“¦ åŠ è½½ SenseVoiceSmall ä¸»æ¨¡å‹ï¼ˆé«˜å‡†ç¡®ç‡è¯†åˆ«ï¼‰...")
    asr_model = AutoModel(
        model="iic/SenseVoiceSmall",
        device=DEVICE,
        ncpu=NCPU,
        disable_update=True
    )
    logger.info("âœ… SenseVoiceSmall åŠ è½½æˆåŠŸ")
    
    # 2. VAD æ¨¡å‹ï¼ˆç”¨äºè·å–æ—¶é—´æˆ³ï¼‰
    logger.info("ğŸ“¦ åŠ è½½ VAD æ¨¡å‹ï¼ˆæ—¶é—´æˆ³åˆ†å‰²ï¼‰...")
    vad_model = AutoModel(
        model="fsmn-vad",
        device=DEVICE,
        disable_update=True
    )
    logger.info("âœ… VAD æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    # 3. è¯´è¯äººè¯†åˆ«æ¨¡å‹ï¼ˆç”¨äºå£°çº¹æå–å’Œèšç±»ï¼‰
    logger.info("ğŸ“¦ åŠ è½½ Cam++ è¯´è¯äººæ¨¡å‹ï¼ˆè¯´è¯äººåˆ†ç¦»ï¼‰...")
    speaker_model = AutoModel(
        model="iic/speech_campplus_sv_zh-cn_16k-common",
        device=DEVICE,
        disable_update=True
    )
    logger.info("âœ… Cam++ è¯´è¯äººæ¨¡å‹åŠ è½½æˆåŠŸ")
    
    # =================== æ—§æ¨¡å‹é…ç½®ï¼ˆå·²æ³¨é‡Šï¼Œå¯å›é€€ï¼‰===================
    # # Paraformer-zhï¼ˆæ ‡å‡†æ¨¡å‹ï¼‰
    # model = AutoModel(
    #     model="paraformer-zh",
    #     vad_model="fsmn-vad",
    #     punc_model="ct-punc",
    #     spk_model="cam++",
    #     device=DEVICE,
    #     ncpu=NCPU,
    #     disable_update=True,
    #     quantize=False
    # )
    
    # # Paraformer-Largeï¼ˆå¤§æ¨¡å‹ï¼Œéœ€è¦12GB+æ˜¾å­˜ï¼‰
    # model = AutoModel(
    #     model="iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
    #     model_revision="v2.0.4",
    #     spk_model="iic/speech_campplus_sv_zh-cn_16k-common",
    #     device=DEVICE,
    #     ncpu=NCPU,
    #     disable_update=True,
    #     quantize=False
    # )
    
    logger.info("âœ… æ‰€æœ‰æ¨¡å‹åŠ è½½æˆåŠŸï¼æœåŠ¡å°±ç»ªã€‚")
    
except Exception as e:
    logger.critical(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}", exc_info=True)
    sys.exit(1)

# =============================================
# 3. FastAPI æœåŠ¡
# =============================================
app = FastAPI(title="FunASR Service", version="1.0.0")

router = APIRouter(prefix="/api/v1")

# å¥åº·æ£€æŸ¥æ¥å£ (è§£å†³ 404 Health é”™è¯¯)
@router.get("/health")
async def health_check():
    return {"status": "ok", "message": "FunASR Service is running"}

# æ”¯æŒ file ä¸Šä¼ æˆ– audio_url ä¸¤ç§è¾“å…¥æ–¹å¼
@router.post("/transcribe/word-level")
async def transcribe_word_level(
    file: UploadFile = File(None),  # æ–‡ä»¶ä¸Šä¼ ï¼ˆå¯é€‰ï¼‰
    audio_path: str = Form(None),  # éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    audio_url: str = Form(None),   # éŸ³é¢‘URLï¼ˆå¯é€‰ï¼‰
    hotword: str = Form("")
) -> dict:
    """
    å­—çº§åˆ« ASR è¯†åˆ«æ¥å£ï¼ˆç”¨äºå¹¶è¡Œå¤„ç†ï¼‰
    
    è¾“å…¥æ–¹å¼ï¼ˆä¸‰é€‰ä¸€ï¼‰ï¼š
    1. file: æ–‡ä»¶ä¸Šä¼ 
    2. audio_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
    3. audio_url: éŸ³é¢‘URL
    
    è¿”å›å­—çº§åˆ«æ—¶é—´æˆ³ï¼Œæ ¼å¼: [{"char": "ä½ ", "start": 0.5, "end": 0.6}, ...]
    """
    from word_level_asr import extract_word_level_timestamps
    
    temp_file_path = None
    input_data = None
    
    try:
        # === å¤„ç†è¾“å…¥ï¼šæ”¯æŒæ–‡ä»¶ä¸Šä¼ ã€æœ¬åœ°è·¯å¾„ã€URL ===
        if file:
            logger.info(f"ğŸ“¥ æ¥æ”¶åˆ°æ–‡ä»¶ä¸Šä¼ : {file.filename}")
            suffix = Path(file.filename).suffix if file.filename else ".mp3"
            # å­˜ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                shutil.copyfileobj(file.file, tmp)
                temp_file_path = Path(tmp.name)
            input_data = str(temp_file_path)
            
        elif audio_path:
            logger.info(f"ğŸ“‚ æ¥æ”¶åˆ°æœ¬åœ°æ–‡ä»¶è·¯å¾„: {audio_path}")
            if not os.path.exists(audio_path):
                return {
                    "code": 1,
                    "msg": f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}",
                    "words": []
                }
            input_data = audio_path.strip()
            
        elif audio_url:
            logger.info(f"ğŸ”— æ¥æ”¶åˆ°éŸ³é¢‘ URL: {audio_url}")
            input_data = audio_url.strip()
            
        else:
            return {
                "code": 1,
                "msg": "å¿…é¡»æä¾› fileã€audio_path æˆ– audio_url ä¹‹ä¸€",
                "words": []
            }
        
        # === éŸ³é¢‘é¢„å¤„ç†ï¼ˆå¯é€‰ï¼Œæå‡å‡†ç¡®ç‡3-5%ï¼‰===
        if isinstance(input_data, str) and Path(input_data).exists():
            processed_input = audio_preprocessor.preprocess(input_data)
            if processed_input != input_data:
                logger.info("âœ… ä½¿ç”¨é¢„å¤„ç†åçš„éŸ³é¢‘")
                input_data = processed_input
        
        # === ä½¿ç”¨ VAD åˆ†æ®µï¼Œé¿å…é•¿éŸ³é¢‘æ˜¾å­˜æº¢å‡º ===
        logger.info(f"ğŸ¤ å¼€å§‹å­—çº§åˆ«è¯†åˆ«ï¼ˆVADåˆ†æ®µæ¨¡å¼ï¼‰: {input_data}")
        
        # æ­¥éª¤1: VAD è¯­éŸ³åˆ†æ®µ
        logger.info("ğŸ¤ æ­¥éª¤1: VAD è¯­éŸ³åˆ†æ®µ...")
        vad_res = vad_model.generate(
            input=input_data,
            batch_size_s=60  # æ¯60ç§’ä¸€æ®µ
        )
        
        # æå– VAD åˆ†æ®µä¿¡æ¯
        vad_segments = []
        if vad_res and len(vad_res) > 0:
            vad_result = vad_res[0]
            vad_segments = vad_result.get("value", [])
        
        if not vad_segments or len(vad_segments) == 0:
            logger.warning("âš ï¸ VAD æœªæ£€æµ‹åˆ°è¯­éŸ³æ®µï¼Œä½¿ç”¨å…¨æ–‡è¯†åˆ«")
            vad_segments = [[0, -1]]  # ä½¿ç”¨æ•´ä¸ªéŸ³é¢‘
        
        logger.info(f"âœ… VAD æ£€æµ‹åˆ° {len(vad_segments)} ä¸ªè¯­éŸ³æ®µ")
        
        # ä¼˜åŒ–ï¼šå¦‚æœç‰‡æ®µè¿‡å¤šï¼Œå…ˆåˆå¹¶çŸ­ç‰‡æ®µï¼ˆå‡å°‘ç‰‡æ®µæ•°é‡ï¼Œæå‡å¤„ç†é€Ÿåº¦ï¼‰
        if len(vad_segments) > 200:
            logger.info(f"ğŸ”§ ç‰‡æ®µè¿‡å¤š({len(vad_segments)}ä¸ª)ï¼Œåˆå¹¶çŸ­ç‰‡æ®µä»¥æå‡å¤„ç†é€Ÿåº¦...")
            merged_segments = []
            current_segment = None
            MIN_SEGMENT_DURATION_MS = 5000  # æœ€å°ç‰‡æ®µæ—¶é•¿5ç§’
            MAX_GAP_MS = 2000  # æœ€å¤§é—´éš”2ç§’
            
            for segment in vad_segments:
                if not isinstance(segment, list) or len(segment) < 2:
                    continue
                
                start_ms, end_ms = segment[0], segment[1]
                
                if end_ms == -1:
                    if current_segment:
                        merged_segments.append(current_segment)
                    merged_segments.append(segment)
                    current_segment = None
                    continue
                
                duration_ms = end_ms - start_ms
                
                if current_segment is None:
                    if duration_ms >= MIN_SEGMENT_DURATION_MS:
                        merged_segments.append(segment)
                    else:
                        current_segment = segment
                else:
                    prev_end = current_segment[1]
                    gap_ms = start_ms - prev_end
                    
                    if gap_ms <= MAX_GAP_MS:
                        current_segment[1] = end_ms
                        merged_duration = current_segment[1] - current_segment[0]
                        if merged_duration >= MIN_SEGMENT_DURATION_MS:
                            merged_segments.append(current_segment)
                            current_segment = None
                    else:
                        if current_segment[1] != -1:
                            prev_duration = current_segment[1] - current_segment[0]
                            if prev_duration >= MIN_SEGMENT_DURATION_MS:
                                merged_segments.append(current_segment)
                            elif len(merged_segments) > 0:
                                merged_segments[-1][1] = current_segment[1]
                        if duration_ms >= MIN_SEGMENT_DURATION_MS:
                            merged_segments.append(segment)
                            current_segment = None
                        else:
                            current_segment = segment
            
            if current_segment:
                merged_duration = current_segment[1] - current_segment[0] if current_segment[1] != -1 else 999999
                if merged_duration >= 1.0:
                    merged_segments.append(current_segment)
                elif len(merged_segments) > 0:
                    merged_segments[-1][1] = current_segment[1]
            
            original_count = len(vad_segments)
            vad_segments = merged_segments
            logger.info(f"âœ… åˆå¹¶å®Œæˆ: {original_count} â†’ {len(merged_segments)} ä¸ªç‰‡æ®µï¼ˆå‡å°‘ {original_count - len(merged_segments)} ä¸ªï¼‰")
        
        # æ­¥éª¤2: æ‰¹é‡è¯†åˆ«å¹¶æå–å­—çº§åˆ«æ—¶é—´æˆ³
        audio_file_path = str(temp_file_path) if temp_file_path else input_data
        
        # é…ç½®ï¼š10GBæ˜¾å­˜ä¼˜åŒ–
        BATCH_SIZE = 8  # æ¯æ‰¹å¤„ç†8ä¸ªç‰‡æ®µ
        MAX_CONCURRENT = 4  # å¢åŠ åˆ°4ä¸ªå¹¶å‘çº¿ç¨‹ï¼ˆæå‡ç‰‡æ®µæå–é€Ÿåº¦ï¼‰
        
        import subprocess
        import tempfile as tmp
        from concurrent.futures import ThreadPoolExecutor, as_completed
        import io
        import soundfile as sf
        import numpy as np
        
        # æ‰¹é‡æå–ç‰‡æ®µåˆ°å†…å­˜
        logger.info(f"ğŸ“¦ æ‰¹é‡æå– {len(vad_segments)} ä¸ªéŸ³é¢‘ç‰‡æ®µåˆ°å†…å­˜...")
        segment_audio_data = {}
        segment_metadata = {}
        
        def extract_segment_to_memory(idx, segment):
            """æå–å•ä¸ªç‰‡æ®µåˆ°å†…å­˜"""
            if not isinstance(segment, list) or len(segment) < 2:
                return None, None
            
            start_ms, end_ms = segment[0], segment[1]
            
            try:
                cmd = ["ffmpeg", "-i", audio_file_path, "-ss", str(start_ms / 1000.0)]
                if end_ms != -1:
                    duration = (end_ms - start_ms) / 1000.0
                    cmd.extend(["-t", str(duration)])
                cmd.extend(["-ac", "1", "-ar", "16000", "-f", "wav", "-"])
                
                result = subprocess.run(cmd, check=True, capture_output=True, timeout=30)
                audio_io = io.BytesIO(result.stdout)
                audio_data, sample_rate = sf.read(audio_io)
                return (audio_data, sample_rate), (start_ms, end_ms)
            except Exception as e:
                logger.warning(f"âš ï¸ æå–ç‰‡æ®µ {idx} å¤±è´¥: {e}")
                return None, None
        
        # å¹¶è¡Œæå–ç‰‡æ®µ
        with ThreadPoolExecutor(max_workers=MAX_CONCURRENT) as executor:
            futures = {
                executor.submit(extract_segment_to_memory, idx, segment): idx 
                for idx, segment in enumerate(vad_segments)
            }
            for future in as_completed(futures):
                idx = futures[future]
                try:
                    audio_data_info, metadata = future.result()
                    if audio_data_info is not None:
                        segment_audio_data[idx] = audio_data_info
                        segment_metadata[idx] = metadata
                except Exception as e:
                    logger.warning(f"âš ï¸ æå–ç‰‡æ®µ {idx} å¼‚å¸¸: {e}")
        
        logger.info(f"âœ… æˆåŠŸæå– {len(segment_audio_data)} ä¸ªç‰‡æ®µåˆ°å†…å­˜")
        
        # æ‰¹é‡è¯†åˆ«å¹¶æå–å­—çº§åˆ«æ—¶é—´æˆ³
        all_words = []
        sorted_indices = sorted(segment_audio_data.keys())
        
        # åˆ†æ‰¹å¤„ç†
        for batch_start in range(0, len(sorted_indices), BATCH_SIZE):
            batch_indices = sorted_indices[batch_start:batch_start + BATCH_SIZE]
            logger.info(f"ğŸ”„ æ‰¹é‡è¯†åˆ«ç‰‡æ®µ {batch_start+1}-{min(batch_start+BATCH_SIZE, len(sorted_indices))}/{len(sorted_indices)}")
            
            # å°†å†…å­˜ä¸­çš„éŸ³é¢‘æ•°æ®å†™å…¥ä¸´æ—¶æ–‡ä»¶
            batch_files = []
            batch_metadata = []
            
            for idx in batch_indices:
                audio_data, sample_rate = segment_audio_data[idx]
                start_ms, end_ms = segment_metadata[idx]
                
                temp_segment = tmp.NamedTemporaryFile(delete=False, suffix=".wav")
                temp_segment.close()
                temp_segment_path = temp_segment.name
                
                sf.write(temp_segment_path, audio_data, sample_rate)
                batch_files.append(temp_segment_path)
                batch_metadata.append((idx, start_ms, end_ms))
            
            # æ‰¹é‡è¯†åˆ«
            try:
                batch_results = asr_model.generate(
                    input=batch_files,
                    language="zh",
                    use_itn=True
                )
                
                # æå–å­—çº§åˆ«æ—¶é—´æˆ³å¹¶è°ƒæ•´æ—¶é—´åç§»
                for i, (idx, start_ms, end_ms) in enumerate(batch_metadata):
                    if i < len(batch_results) and batch_results[i]:
                        result_item = batch_results[i]
                        
                        # è°ƒè¯•ï¼šæ‰“å°ASRç»“æœç»“æ„
                        if i == 0 and batch_start == 0:
                            logger.debug(f"ğŸ” ASRç»“æœç»“æ„: {list(result_item.keys())}")
                            if "text" in result_item:
                                logger.debug(f"ğŸ” æ–‡æœ¬å†…å®¹: {result_item['text'][:50]}...")
                            if "timestamp" in result_item:
                                logger.debug(f"ğŸ” timestampå­—æ®µ: {type(result_item['timestamp'])}")
                            if "sentences" in result_item:
                                logger.debug(f"ğŸ” sentenceså­—æ®µ: {len(result_item.get('sentences', []))} ä¸ªå¥å­")
                        
                        words = extract_word_level_timestamps(result_item)
                        
                        if not words and i == 0 and batch_start == 0:
                            logger.warning(f"âš ï¸ ç‰‡æ®µ {idx} æœªæå–åˆ°å­—çº§åˆ«æ—¶é—´æˆ³ï¼ŒASRç»“æœ: {result_item}")
                        
                        # è°ƒæ•´æ—¶é—´æˆ³ï¼šåŠ ä¸Šç‰‡æ®µçš„èµ·å§‹æ—¶é—´
                        segment_start_sec = start_ms / 1000.0
                        for word in words:
                            word["start"] = round(word["start"] + segment_start_sec, 3)
                            word["end"] = round(word["end"] + segment_start_sec, 3)
                        
                        all_words.extend(words)
                
            except Exception as e:
                logger.warning(f"âš ï¸ æ‰¹é‡è¯†åˆ«å¤±è´¥: {e}ï¼Œé™çº§ä¸ºå•æ®µè¯†åˆ«")
                # é™çº§ï¼šå•æ®µè¯†åˆ«
                for i, (idx, start_ms, end_ms) in enumerate(batch_metadata):
                    if i < len(batch_files):
                        try:
                            seg_res = asr_model.generate(
                                input=batch_files[i],
                                language="zh",
                                use_itn=True
                            )
                            if seg_res and len(seg_res) > 0:
                                words = extract_word_level_timestamps(seg_res[0])
                                segment_start_sec = start_ms / 1000.0
                                for word in words:
                                    word["start"] = round(word["start"] + segment_start_sec, 3)
                                    word["end"] = round(word["end"] + segment_start_sec, 3)
                                all_words.extend(words)
                        except Exception as e2:
                            logger.warning(f"âš ï¸ è¯†åˆ«ç‰‡æ®µ {idx} å¤±è´¥: {e2}")
            finally:
                # æ¸…ç†æ‰¹é‡ä¸´æ—¶æ–‡ä»¶
                for temp_file in batch_files:
                    try:
                        os.remove(temp_file)
                    except:
                        pass
        
        # æŒ‰æ—¶é—´æ’åº
        all_words.sort(key=lambda x: x["start"])
        
        logger.info(f"âœ… å­—çº§åˆ«è¯†åˆ«å®Œæˆ: {len(all_words)} ä¸ªå­—")
        return {
            "code": 0,
            "msg": "success",
            "words": all_words
        }
        
    except Exception as e:
        logger.error(f"âŒ å­—çº§åˆ«è¯†åˆ«å¤±è´¥: {e}")
        return {
            "code": 1,
            "msg": str(e),
            "words": []
        }
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_file_path and temp_file_path.exists():
            try:
                os.remove(temp_file_path)
                logger.debug(f"ğŸ§¹ å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_file_path}")
            except Exception as e:
                logger.warning(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")


@router.post("/transcribe")
async def transcribe(
    # 1. file æ”¹ä¸ºå¯é€‰
    file: UploadFile = File(None), 
    # 2. url å‚æ•°
    audio_url: str = Form(None),   
    hotword: str = Form(""),  # å¤–éƒ¨ä¼ å…¥çš„çƒ­è¯ï¼ˆå¯é€‰ï¼‰
    enable_speaker_diarization: bool = Form(True)  # æ˜¯å¦å¯ç”¨è¯´è¯äººåˆ†ç¦»ï¼ˆé»˜è®¤å¯ç”¨ï¼Œä¸»æœåŠ¡ç”¨Pyannoteæ—¶å¯è®¾ä¸ºFalseï¼‰
):
    temp_file_path = None
    input_data = None 

    try:
        # === é€»è¾‘åˆ¤æ–­ ===
        if file:
            logger.info(f"ğŸ“¥ æ¥æ”¶åˆ°æ–‡ä»¶ä¸Šä¼ : {file.filename}")
            suffix = Path(file.filename).suffix
            # å­˜ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                shutil.copyfileobj(file.file, tmp)
                temp_file_path = Path(tmp.name)
            input_data = str(temp_file_path)

        elif audio_url:
            logger.info(f"ğŸ”— æ¥æ”¶åˆ°éŸ³é¢‘ URL: {audio_url}")
            input_data = audio_url.strip() # å»é™¤ç©ºæ ¼
            
        else:
            raise HTTPException(status_code=400, detail="å¿…é¡»æä¾› file æˆ– audio_url")

        # === éŸ³é¢‘é¢„å¤„ç†ï¼ˆå¯é€‰ï¼Œæå‡å‡†ç¡®ç‡3-5%ï¼‰===
        if isinstance(input_data, str) and Path(input_data).exists():
            processed_input = audio_preprocessor.preprocess(input_data)
            if processed_input != input_data:
                logger.info("âœ… ä½¿ç”¨é¢„å¤„ç†åçš„éŸ³é¢‘")
                input_data = processed_input
        
        # === è‡ªåŠ¨åŠ è½½çƒ­è¯ ===
        try:
            hotword_svc = get_hotword_service()
            auto_hotwords = hotword_svc.get_hotwords_string()
            
            # åˆå¹¶å¤–éƒ¨ä¼ å…¥çš„çƒ­è¯å’Œè‡ªåŠ¨åŠ è½½çš„çƒ­è¯
            if hotword and auto_hotwords:
                combined_hotwords = f"{hotword} {auto_hotwords}"
            elif auto_hotwords:
                combined_hotwords = auto_hotwords
            else:
                combined_hotwords = hotword
                
            hotword_count = len(hotword_svc.get_all_hotwords())
            logger.info(f"ğŸ”¥ çƒ­è¯å·²åŠ è½½: {hotword_count} ä¸ª")
        except Exception as e:
            logger.warning(f"âš ï¸ çƒ­è¯åŠ è½½å¤±è´¥: {e}ï¼Œå°†ä¸ä½¿ç”¨çƒ­è¯")
            combined_hotwords = hotword
        
        # === å¼€å§‹æ¨ç† ===
        logger.info(f"ğŸ¤ å¼€å§‹è¯­éŸ³è¯†åˆ«... (çƒ­è¯: {len(combined_hotwords)} å­—ç¬¦)")

        # ===== æ­¥éª¤1ï¼šä½¿ç”¨ VAD è·å–è¯­éŸ³æ®µæ—¶é—´æˆ³ =====
        logger.info("ğŸ¤ æ­¥éª¤1: VAD è¯­éŸ³åˆ†æ®µ...")
        vad_res = vad_model.generate(
            input=input_data,
            batch_size_s=60  # æ¯60ç§’ä¸€æ®µ
        )
        
        # æå– VAD åˆ†æ®µä¿¡æ¯
        vad_segments = []
        if vad_res and len(vad_res) > 0:
            vad_result = vad_res[0]
            vad_segments = vad_result.get("value", [])
        
        if not vad_segments or len(vad_segments) == 0:
            logger.warning("âš ï¸ VAD æœªæ£€æµ‹åˆ°è¯­éŸ³æ®µï¼Œä½¿ç”¨å…¨æ–‡è¯†åˆ«")
            vad_segments = [[0, -1]]  # ä½¿ç”¨æ•´ä¸ªéŸ³é¢‘
        
        logger.info(f"âœ… VAD æ£€æµ‹åˆ° {len(vad_segments)} ä¸ªè¯­éŸ³æ®µ")
        
        # ===== ä¼˜åŒ–ï¼šæ€»æ˜¯åˆå¹¶ç›¸é‚»çŸ­ç‰‡æ®µï¼Œé¿å…è¿‡åº¦åˆ†æ®µå’Œä¸¢å†…å®¹ =====
        # æ— è®ºç‰‡æ®µå¤šå°‘ï¼Œéƒ½è¿›è¡Œåˆå¹¶ä¼˜åŒ–ï¼Œé¿å…ä¸¢å¤±å†…å®¹
        if len(vad_segments) > 1:  # åªè¦æœ‰å¤šä¸ªç‰‡æ®µï¼Œå°±è¿›è¡Œåˆå¹¶ä¼˜åŒ–
            logger.info(f"ğŸ”§ ä¼˜åŒ–VADåˆ†æ®µ({len(vad_segments)}ä¸ª)ï¼Œåˆå¹¶çŸ­ç‰‡æ®µé¿å…ä¸¢å†…å®¹...")
            merged_segments = []
            current_segment = None
            
            # åŠ¨æ€è°ƒæ•´ï¼šæ ¹æ®ç‰‡æ®µæ•°é‡è°ƒæ•´åˆå¹¶ç­–ç•¥
            if len(vad_segments) > 200:
                # ç‰‡æ®µéå¸¸å¤šï¼Œæ›´æ¿€è¿›çš„åˆå¹¶
                MIN_SEGMENT_DURATION_MS = 8000  # æœ€å°ç‰‡æ®µæ—¶é•¿8ç§’
                MAX_GAP_MS = 3000  # æœ€å¤§é—´éš”3ç§’
            elif len(vad_segments) > 100:
                # ç‰‡æ®µè¾ƒå¤šï¼Œä¸­ç­‰åˆå¹¶
                MIN_SEGMENT_DURATION_MS = 6000  # æœ€å°ç‰‡æ®µæ—¶é•¿6ç§’
                MAX_GAP_MS = 2500  # æœ€å¤§é—´éš”2.5ç§’
            else:
                # ç‰‡æ®µè¾ƒå°‘ï¼Œæ ‡å‡†åˆå¹¶
                MIN_SEGMENT_DURATION_MS = 5000  # æœ€å°ç‰‡æ®µæ—¶é•¿5ç§’
                MAX_GAP_MS = 2000  # æœ€å¤§é—´éš”2ç§’
            
            logger.info(f"ğŸ”§ åˆå¹¶ç­–ç•¥: æœ€å°ç‰‡æ®µ{MIN_SEGMENT_DURATION_MS/1000:.1f}ç§’, æœ€å¤§é—´éš”{MAX_GAP_MS/1000:.1f}ç§’")
            
            for segment in vad_segments:
                if not isinstance(segment, list) or len(segment) < 2:
                    continue
                
                start_ms, end_ms = segment[0], segment[1]
                
                if end_ms == -1:
                    # æœ€åä¸€ä¸ªç‰‡æ®µï¼Œç›´æ¥æ·»åŠ 
                    if current_segment:
                        merged_segments.append(current_segment)
                        current_segment = None
                    merged_segments.append(segment)
                    continue
                
                duration_ms = end_ms - start_ms
                
                if current_segment is None:
                    # ç¬¬ä¸€ä¸ªç‰‡æ®µ
                    if duration_ms >= MIN_SEGMENT_DURATION_MS:
                        merged_segments.append(segment)
                    else:
                        current_segment = segment  # æš‚å­˜ï¼Œç­‰å¾…åˆå¹¶
                else:
                    # æ£€æŸ¥æ˜¯å¦å¯ä»¥åˆå¹¶
                    prev_end = current_segment[1]
                    gap_ms = start_ms - prev_end
                    
                    if gap_ms <= MAX_GAP_MS:
                        # é—´éš”å°ï¼Œå¯ä»¥åˆå¹¶
                        current_segment[1] = end_ms
                        merged_duration = current_segment[1] - current_segment[0]
                        
                        # å¦‚æœåˆå¹¶åè¾¾åˆ°æœ€å°é•¿åº¦ï¼Œæ·»åŠ åˆ°ç»“æœ
                        if merged_duration >= MIN_SEGMENT_DURATION_MS:
                            merged_segments.append(current_segment)
                            current_segment = None
                    else:
                        # é—´éš”å¤§ï¼Œä¸èƒ½åˆå¹¶
                        # å…ˆå¤„ç†ä¹‹å‰çš„ç‰‡æ®µ
                        if current_segment[1] != -1:
                            prev_duration = current_segment[1] - current_segment[0]
                            if prev_duration >= MIN_SEGMENT_DURATION_MS:
                                merged_segments.append(current_segment)
                            else:
                                # å¤ªçŸ­ï¼Œå¼ºåˆ¶åˆå¹¶åˆ°æœ€åä¸€ä¸ªç‰‡æ®µï¼ˆé¿å…ä¸¢å†…å®¹ï¼‰
                                if len(merged_segments) > 0:
                                    last_segment = merged_segments[-1]
                                    if last_segment[1] != -1:
                                        last_segment[1] = current_segment[1]
                                    logger.debug(f"ğŸ”§ å°†çŸ­ç‰‡æ®µåˆå¹¶åˆ°å‰ä¸€ä¸ªç‰‡æ®µï¼Œé¿å…ä¸¢å†…å®¹")
                                else:
                                    # å¦‚æœæ²¡æœ‰å‰é¢çš„ç‰‡æ®µï¼Œå¼ºåˆ¶æ·»åŠ ï¼ˆé¿å…ä¸¢å†…å®¹ï¼‰
                                    merged_segments.append(current_segment)
                        
                        # å¤„ç†å½“å‰ç‰‡æ®µ
                        if duration_ms >= MIN_SEGMENT_DURATION_MS:
                            merged_segments.append(segment)
                            current_segment = None
                        else:
                            current_segment = segment
            
            # å¤„ç†æœ€åä¸€ä¸ªæš‚å­˜çš„ç‰‡æ®µï¼ˆä¸ä¸¢å¼ƒï¼Œå¼ºåˆ¶åˆå¹¶æˆ–æ·»åŠ ï¼‰
            if current_segment:
                merged_duration = current_segment[1] - current_segment[0] if current_segment[1] != -1 else 999999
                # å³ä½¿ä¸å¤Ÿæœ€å°é•¿åº¦ï¼Œä¹Ÿæ·»åŠ ï¼ˆé¿å…ä¸¢å†…å®¹ï¼‰
                if merged_duration >= 1.0:  # è‡³å°‘1ç§’å°±ä¿ç•™
                    merged_segments.append(current_segment)
                elif len(merged_segments) > 0:
                    # å¦‚æœå¤ªçŸ­ï¼Œåˆå¹¶åˆ°æœ€åä¸€ä¸ªç‰‡æ®µï¼ˆé¿å…ä¸¢å†…å®¹ï¼‰
                    last_segment = merged_segments[-1]
                    if last_segment[1] != -1 and current_segment[1] != -1:
                        last_segment[1] = current_segment[1]
                    logger.debug(f"ğŸ”§ å°†çŸ­ç‰‡æ®µåˆå¹¶åˆ°å‰ä¸€ä¸ªç‰‡æ®µï¼Œé¿å…ä¸¢å†…å®¹")
            
            original_count = len(vad_segments)
            vad_segments = merged_segments
            logger.info(f"âœ… åˆå¹¶å®Œæˆ: {original_count} â†’ {len(merged_segments)} ä¸ªç‰‡æ®µï¼ˆå‡å°‘ {original_count - len(merged_segments)} ä¸ªï¼Œé¿å…ä¸¢å†…å®¹ï¼‰")
        
        # ===== æ­¥éª¤2ï¼šæ‰¹é‡æå–ç‰‡æ®µå¹¶è¯†åˆ«ï¼ˆä¼˜åŒ–ï¼šæ‰¹é‡å¤„ç† + å†…å­˜ç¼“å­˜ï¼‰=====
        logger.info("ğŸ¤ æ­¥éª¤2: SenseVoiceSmall æ‰¹é‡è¯†åˆ«ï¼ˆä¼˜åŒ–ç‰ˆï¼‰...")
        
        # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæœ‰ï¼‰
        audio_file_path = str(temp_file_path) if temp_file_path else input_data
        
        # é…ç½®ï¼š10GBæ˜¾å­˜ä¼˜åŒ–
        BATCH_SIZE = 8  # æ¯æ‰¹å¤„ç†8ä¸ªç‰‡æ®µï¼ˆ10GBæ˜¾å­˜ï¼‰
        MAX_CONCURRENT = 2  # æœ€å¤š2ä¸ªå¹¶å‘çº¿ç¨‹
        
        import subprocess
        import tempfile as tmp
        import re
        from concurrent.futures import ThreadPoolExecutor, as_completed
        import io
        import soundfile as sf
        import numpy as np
        
        # ä¼˜åŒ–1&4: æ‰¹é‡æå–ç‰‡æ®µåˆ°å†…å­˜ï¼Œé¿å…é¢‘ç¹ç£ç›˜I/O
        logger.info(f"ğŸ“¦ æ‰¹é‡æå– {len(vad_segments)} ä¸ªéŸ³é¢‘ç‰‡æ®µåˆ°å†…å­˜...")
        segment_audio_data = {}  # {segment_idx: (audio_data, sample_rate)}
        segment_metadata = {}  # {segment_idx: (start_ms, end_ms)}
        
        def extract_segment_to_memory(idx, segment):
            """æå–å•ä¸ªç‰‡æ®µåˆ°å†…å­˜"""
            if not isinstance(segment, list) or len(segment) < 2:
                return None, None
            
            start_ms, end_ms = segment[0], segment[1]
            
            try:
                # ä½¿ç”¨ ffmpeg æå–åˆ°å†…å­˜ï¼ˆé€šè¿‡ç®¡é“ï¼‰
                cmd = ["ffmpeg", "-i", audio_file_path, "-ss", str(start_ms / 1000.0)]
                
                if end_ms != -1:
                    duration = (end_ms - start_ms) / 1000.0
                    cmd.extend(["-t", str(duration)])
                
                cmd.extend([
                    "-ac", "1", "-ar", "16000",
                    "-f", "wav",
                    "-"  # è¾“å‡ºåˆ°stdout
                ])
                
                # æå–éŸ³é¢‘æ•°æ®åˆ°å†…å­˜
                result = subprocess.run(
                    cmd, 
                    check=True, 
                    capture_output=True, 
                    timeout=30
                )
                
                # ä»å†…å­˜ä¸­è¯»å–éŸ³é¢‘æ•°æ®
                audio_io = io.BytesIO(result.stdout)
                audio_data, sample_rate = sf.read(audio_io)
                
                return (audio_data, sample_rate), (start_ms, end_ms)
                
            except Exception as e:
                logger.warning(f"âš ï¸ æå–ç‰‡æ®µ {idx} å¤±è´¥: {e}")
                return None, None
        
        # ä¼˜åŒ–3: å¹¶è¡Œæå–ç‰‡æ®µï¼ˆæ§åˆ¶å¹¶å‘æ•°ï¼‰
        with ThreadPoolExecutor(max_workers=MAX_CONCURRENT) as executor:
            futures = {
                executor.submit(extract_segment_to_memory, idx, segment): idx 
                for idx, segment in enumerate(vad_segments)
            }
            
            for future in as_completed(futures):
                idx = futures[future]
                try:
                    audio_data_info, metadata = future.result()
                    if audio_data_info is not None:
                        segment_audio_data[idx] = audio_data_info
                        segment_metadata[idx] = metadata
                except Exception as e:
                    logger.warning(f"âš ï¸ æå–ç‰‡æ®µ {idx} å¼‚å¸¸: {e}")
        
        logger.info(f"âœ… æˆåŠŸæå– {len(segment_audio_data)} ä¸ªç‰‡æ®µåˆ°å†…å­˜")
        
        # ä¼˜åŒ–2: æ‰¹é‡è¯†åˆ«ï¼ˆåˆ†æ‰¹å¤„ç†ï¼Œé¿å…æ˜¾å­˜æº¢å‡ºï¼‰
        segment_results = []
        full_text_parts = []
        
        # æŒ‰segment_idxæ’åºï¼Œç¡®ä¿é¡ºåº
        sorted_indices = sorted(segment_audio_data.keys())
        
        # åˆ†æ‰¹å¤„ç†
        for batch_start in range(0, len(sorted_indices), BATCH_SIZE):
            batch_indices = sorted_indices[batch_start:batch_start + BATCH_SIZE]
            logger.info(f"ğŸ”„ æ‰¹é‡è¯†åˆ«ç‰‡æ®µ {batch_start+1}-{min(batch_start+BATCH_SIZE, len(sorted_indices))}/{len(sorted_indices)}")
            
            # å°†å†…å­˜ä¸­çš„éŸ³é¢‘æ•°æ®å†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼ˆæ‰¹é‡è¯†åˆ«éœ€è¦æ–‡ä»¶è·¯å¾„ï¼‰
            batch_files = []
            batch_metadata = []
            
            for idx in batch_indices:
                audio_data, sample_rate = segment_audio_data[idx]
                start_ms, end_ms = segment_metadata[idx]
                
                # å†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼ˆæ‰¹é‡è¯†åˆ«éœ€è¦ï¼‰
                temp_segment = tmp.NamedTemporaryFile(delete=False, suffix=".wav")
                temp_segment.close()
                temp_segment_path = temp_segment.name
                
                sf.write(temp_segment_path, audio_data, sample_rate)
                batch_files.append(temp_segment_path)
                batch_metadata.append((idx, start_ms, end_ms))
            
            # æ‰¹é‡è¯†åˆ«
            try:
                batch_results = asr_model.generate(
                    input=batch_files,
                    language="zh",
                    use_itn=True
                )
                
                # å¤„ç†æ‰¹é‡è¯†åˆ«ç»“æœ - æŒ‰å¥å­åˆ‡åˆ†
                for i, (idx, start_ms, end_ms) in enumerate(batch_metadata):
                    if i < len(batch_results) and batch_results[i]:
                        result_item = batch_results[i]
                        text = result_item.get("text", "").strip()
                        
                        # æ¸…ç† SenseVoice çš„è¯­è¨€æ ‡ç­¾
                        text = re.sub(r'<\|[^|]+\|>', '', text).strip()
                        
                        # è¿‡æ»¤éä¸­æ–‡å†…å®¹
                        if text:
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ—¥æ–‡å‡å
                            if re.search(r'[\u3040-\u309F\u30A0-\u30FF]', text):
                                logger.debug(f"â­ï¸ è¿‡æ»¤æ—¥æ–‡å†…å®¹: {text[:20]}...")
                                continue
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«éŸ©æ–‡
                            if re.search(r'[\uAC00-\uD7AF]', text):
                                logger.debug(f"â­ï¸ è¿‡æ»¤éŸ©æ–‡å†…å®¹: {text[:20]}...")
                                continue
                            # æ£€æŸ¥æ˜¯å¦ä¸»è¦æ˜¯è‹±æ–‡å•è¯
                            english_chars = len(re.findall(r'[a-zA-Z]', text))
                            if len(text) > 0 and english_chars / len(text) > 0.5:
                                logger.debug(f"â­ï¸ è¿‡æ»¤è‹±æ–‡å†…å®¹: {text[:20]}...")
                                continue
                        
                        if not text:
                            continue
                        
                        # ä¼˜åŒ–ï¼šæŒ‰å¥å­åˆ‡åˆ†ï¼Œè€Œä¸æ˜¯æŒ‰VADæ®µ
                        # æ£€æŸ¥æ˜¯å¦æœ‰timestampä¿¡æ¯ï¼ˆå¥å­çº§åˆ«ï¼‰
                        timestamp = result_item.get("timestamp", [])
                        sentences = result_item.get("sentences", [])
                        
                        if sentences and len(sentences) > 0:
                            # ä½¿ç”¨å¥å­çº§åˆ«çš„ä¿¡æ¯
                            for sent in sentences:
                                sent_text = sent.get("text", "").strip()
                                if not sent_text or len(sent_text) < 2:  # è¿‡æ»¤å¤ªçŸ­çš„å¥å­
                                    continue
                                
                                sent_timestamp = sent.get("timestamp", [])
                                if sent_timestamp and len(sent_timestamp) >= 2:
                                    sent_start = sent_timestamp[0] / 1000.0 if isinstance(sent_timestamp[0], (int, float)) else start_ms / 1000.0
                                    sent_end = sent_timestamp[1] / 1000.0 if isinstance(sent_timestamp[1], (int, float)) else end_ms / 1000.0
                                else:
                                    # å¦‚æœæ²¡æœ‰æ—¶é—´æˆ³ï¼Œä½¿ç”¨VADæ®µçš„æ—¶é—´ï¼Œä½†æŒ‰å¥å­æ¯”ä¾‹åˆ†é…
                                    sent_start = start_ms / 1000.0
                                    sent_end = end_ms / 1000.0 if end_ms != -1 else 999999
                                
                                segment_results.append({
                                    "start_time": round(sent_start, 2),
                                    "end_time": round(sent_end, 2),
                                    "text": sent_text,
                                    "segment_idx": idx,
                                    "_audio_data": segment_audio_data[idx]  # ç¼“å­˜éŸ³é¢‘æ•°æ®ä¾›æ­¥éª¤3ä½¿ç”¨
                                })
                                full_text_parts.append(sent_text)
                        elif timestamp and len(timestamp) > 0:
                            # ä½¿ç”¨timestampä¿¡æ¯æŒ‰å¥å­åˆ‡åˆ†
                            # timestampæ ¼å¼å¯èƒ½æ˜¯ [[start, end, word], ...] æˆ– [[start, end], ...]
                            current_sentence = []
                            current_start = None
                            current_end = None
                            
                            for ts_item in timestamp:
                                if not isinstance(ts_item, list) or len(ts_item) < 2:
                                    continue
                                
                                ts_start = ts_item[0] / 1000.0 if isinstance(ts_item[0], (int, float)) else start_ms / 1000.0
                                ts_end = ts_item[1] / 1000.0 if isinstance(ts_item[1], (int, float)) else end_ms / 1000.0
                                word = ts_item[-1] if len(ts_item) > 2 else ""
                                
                                if current_start is None:
                                    current_start = ts_start
                                
                                current_sentence.append(word)
                                current_end = ts_end
                                
                                # é‡åˆ°æ ‡ç‚¹ç¬¦å·æˆ–åœé¡¿è¶…è¿‡0.5ç§’ï¼Œåˆ†å¥
                                if word in ["ã€‚", "ï¼Ÿ", "ï¼", ".", "?", "!"] or (len(current_sentence) > 1 and ts_start - current_end > 0.5):
                                    sent_text = "".join(current_sentence).strip()
                                    if sent_text and len(sent_text) >= 2:  # è¿‡æ»¤å¤ªçŸ­çš„å¥å­
                                        segment_results.append({
                                            "start_time": round(current_start, 2),
                                            "end_time": round(current_end, 2),
                                            "text": sent_text,
                                            "segment_idx": idx,
                                            "_audio_data": segment_audio_data[idx]
                                        })
                                        full_text_parts.append(sent_text)
                                    current_sentence = []
                                    current_start = None
                            
                            # å¤„ç†æœ€åä¸€å¥
                            if current_sentence:
                                sent_text = "".join(current_sentence).strip()
                                if sent_text and len(sent_text) >= 2:
                                    segment_results.append({
                                        "start_time": round(current_start, 2),
                                        "end_time": round(current_end, 2),
                                        "text": sent_text,
                                        "segment_idx": idx,
                                        "_audio_data": segment_audio_data[idx]
                                    })
                                    full_text_parts.append(sent_text)
                        else:
                            # æ²¡æœ‰å¥å­çº§åˆ«ä¿¡æ¯ï¼ŒæŒ‰æ ‡ç‚¹ç¬¦å·åˆ‡åˆ†æ–‡æœ¬
                            # è¿‡æ»¤å¤ªçŸ­çš„æ–‡æœ¬ï¼ˆå°‘äº3ä¸ªå­—ï¼‰
                            if len(text) < 3:
                                continue
                            
                            # æŒ‰æ ‡ç‚¹ç¬¦å·åˆ‡åˆ†
                            sentences = re.split(r'([ã€‚ï¼ï¼Ÿ\n])', text)
                            current_sent = ""
                            sent_start = start_ms / 1000.0
                            segment_duration = (end_ms - start_ms) / 1000.0 if end_ms != -1 else 1.0
                            char_duration = segment_duration / max(len(text), 1)
                            
                            for part in sentences:
                                if not part.strip():
                                    continue
                                
                                if part in ["ã€‚", "ï¼", "ï¼Ÿ", "\n"]:
                                    if current_sent.strip() and len(current_sent.strip()) >= 2:
                                        sent_end = sent_start + len(current_sent) * char_duration
                                        segment_results.append({
                                            "start_time": round(sent_start, 2),
                                            "end_time": round(sent_end, 2),
                                            "text": current_sent.strip(),
                                            "segment_idx": idx,
                                            "_audio_data": segment_audio_data[idx]
                                        })
                                        full_text_parts.append(current_sent.strip())
                                    sent_start = sent_end
                                    current_sent = ""
                                else:
                                    current_sent += part
                            
                            # å¤„ç†æœ€åä¸€å¥
                            if current_sent.strip() and len(current_sent.strip()) >= 2:
                                sent_end = sent_start + len(current_sent) * char_duration
                                segment_results.append({
                                    "start_time": round(sent_start, 2),
                                    "end_time": round(sent_end, 2),
                                    "text": current_sent.strip(),
                                    "segment_idx": idx,
                                    "_audio_data": segment_audio_data[idx]
                                })
                                full_text_parts.append(current_sent.strip())
                
            except Exception as e:
                logger.warning(f"âš ï¸ æ‰¹é‡è¯†åˆ«å¤±è´¥: {e}ï¼Œé™çº§ä¸ºå•æ®µè¯†åˆ«")
                # é™çº§ï¼šå•æ®µè¯†åˆ«
                for idx, (start_ms, end_ms) in batch_metadata:
                    audio_data, sample_rate = segment_audio_data[idx]
                    temp_segment = tmp.NamedTemporaryFile(delete=False, suffix=".wav")
                    temp_segment.close()
                    temp_segment_path = temp_segment.name
                    sf.write(temp_segment_path, audio_data, sample_rate)
                    
                    try:
                        seg_res = asr_model.generate(
                            input=temp_segment_path,
                            language="zh",
                            use_itn=True
                        )
                        
                        if seg_res and len(seg_res) > 0:
                            text = seg_res[0].get("text", "").strip()
                            text = re.sub(r'<\|[^|]+\|>', '', text).strip()
                            
                        # é™çº§å¤„ç†ï¼šæŒ‰æ ‡ç‚¹ç¬¦å·åˆ‡åˆ†
                        if len(text) < 3:
                            continue
                        
                        # æŒ‰æ ‡ç‚¹ç¬¦å·åˆ‡åˆ†
                        sentences = re.split(r'([ã€‚ï¼ï¼Ÿ\n])', text)
                        current_sent = ""
                        sent_start = start_ms / 1000.0
                        segment_duration = (end_ms - start_ms) / 1000.0 if end_ms != -1 else 1.0
                        char_duration = segment_duration / max(len(text), 1)
                        
                        for part in sentences:
                            if not part.strip():
                                continue
                            
                            if part in ["ã€‚", "ï¼", "ï¼Ÿ", "\n"]:
                                if current_sent.strip() and len(current_sent.strip()) >= 2:
                                    sent_end = sent_start + len(current_sent) * char_duration
                                    segment_results.append({
                                        "start_time": round(sent_start, 2),
                                        "end_time": round(sent_end, 2),
                                        "text": current_sent.strip(),
                                        "segment_idx": idx,
                                        "_audio_data": segment_audio_data[idx]
                                    })
                                    full_text_parts.append(current_sent.strip())
                                sent_start = sent_end
                                current_sent = ""
                            else:
                                current_sent += part
                        
                        # å¤„ç†æœ€åä¸€å¥
                        if current_sent.strip() and len(current_sent.strip()) >= 2:
                            sent_end = sent_start + len(current_sent) * char_duration
                            segment_results.append({
                                "start_time": round(sent_start, 2),
                                "end_time": round(sent_end, 2),
                                "text": current_sent.strip(),
                                "segment_idx": idx,
                                "_audio_data": segment_audio_data[idx]
                            })
                            full_text_parts.append(current_sent.strip())
                    except Exception as e2:
                        logger.warning(f"âš ï¸ è¯†åˆ«ç‰‡æ®µ {idx} å¤±è´¥: {e2}")
                    finally:
                        try:
                            os.remove(temp_segment_path)
                        except:
                            pass
            
            finally:
                # æ¸…ç†æ‰¹é‡ä¸´æ—¶æ–‡ä»¶
                for temp_file in batch_files:
                    try:
                        os.remove(temp_file)
                    except:
                        pass
        
        full_text = "".join(full_text_parts)
        logger.info(f"âœ… ASR è¯†åˆ«å®Œæˆï¼Œå…± {len(segment_results)} ä¸ªç‰‡æ®µï¼Œæ–‡æœ¬é•¿åº¦: {len(full_text)} å­—")
        
        # ===== æ­¥éª¤3ï¼šè¯´è¯äººåˆ†ç¦»ï¼ˆæ”¯æŒPyannoteå’ŒCam++ä¸¤ç§æ–¹æ¡ˆï¼‰=====
        # å¦‚æœä¸»æœåŠ¡ç¦ç”¨è¯´è¯äººåˆ†ç¦»ï¼ˆå°†ä½¿ç”¨å¤–éƒ¨PyannoteæœåŠ¡ï¼‰ï¼Œåˆ™è·³è¿‡
        if not enable_speaker_diarization:
            logger.info("â„¹ï¸ è¯´è¯äººåˆ†ç¦»å·²ç¦ç”¨ï¼ˆå°†ç”±ä¸»æœåŠ¡ä½¿ç”¨Pyannoteå¤„ç†ï¼‰")
            # ä¸ºæ‰€æœ‰ç‰‡æ®µè®¾ç½®é»˜è®¤ speaker_id
            for result in segment_results:
                result['speaker_id'] = '0'
            speaker_info = []
            # è·³è¿‡åç»­çš„ç¼–å·è§„èŒƒåŒ–å’Œè¯´è¯äººç»Ÿè®¡é€»è¾‘
            skip_speaker_normalization = True
        else:
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨Pyannoteï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡æˆ–é…ç½®ï¼‰
            use_pyannote = os.getenv("USE_PYANNOTE", "false").lower() == "true"
            
            if use_pyannote:
                logger.info("ğŸ¤ æ­¥éª¤3: ä½¿ç”¨ Pyannote.audio è¿›è¡Œè¯´è¯äººåˆ†ç¦»ï¼ˆä¸“ä¸šæ¨¡å‹ï¼‰...")
                try:
                    from pyannote_diarization import perform_pyannote_diarization
                    
                    # å‡†å¤‡transcriptæ ¼å¼çš„æ•°æ®
                    transcript_for_pyannote = [
                        {
                            "text": result.get("text", ""),
                            "start_time": result.get("start_time", 0),
                            "end_time": result.get("end_time", 0)
                        }
                        for result in segment_results
                    ]
                    
                    # ä½¿ç”¨Pyannoteè¿›è¡Œè¯´è¯äººåˆ†ç¦»
                    transcript_with_speakers = perform_pyannote_diarization(
                        audio_path=audio_file_path,
                        transcript=transcript_for_pyannote
                    )
                    
                    # å°†è¯´è¯äººä¿¡æ¯åˆå¹¶åˆ°segment_results
                    for i, result in enumerate(segment_results):
                        if i < len(transcript_with_speakers):
                            result['speaker_id'] = transcript_with_speakers[i].get('speaker_id', '0')
                        else:
                            result['speaker_id'] = '0'
                    
                    logger.info("âœ… Pyannote è¯´è¯äººåˆ†ç¦»å®Œæˆ")
                    speaker_info = []  # Pyannoteä¸éœ€è¦speaker_info
                    
                except ImportError:
                    logger.warning("âš ï¸ Pyannote æœªå®‰è£…ï¼Œé™çº§ä½¿ç”¨ Cam++ æ–¹æ¡ˆ")
                    logger.warning("   å®‰è£…å‘½ä»¤: pip install pyannote.audio")
                    use_pyannote = False
                except Exception as e:
                    logger.error(f"âŒ Pyannote è¯´è¯äººåˆ†ç¦»å¤±è´¥: {e}ï¼Œé™çº§ä½¿ç”¨ Cam++ æ–¹æ¡ˆ")
                    use_pyannote = False
            
            if not use_pyannote:
                logger.info("ğŸ¤ æ­¥éª¤3: ä½¿ç”¨ Cam++ è¿›è¡Œè¯´è¯äººåˆ†ç¦»ï¼ˆä¼˜åŒ–ï¼šå¤ç”¨ç¼“å­˜éŸ³é¢‘ï¼‰...")
                
                # ä¼˜åŒ–2: å¤ç”¨æ­¥éª¤2æå–çš„éŸ³é¢‘æ•°æ®ï¼Œé¿å…é‡å¤æå–
                from speaker_diarization import perform_speaker_diarization_with_cached_audio
                
                # æ„å»ºç¼“å­˜çš„éŸ³é¢‘æ•°æ®æ˜ å°„
                cached_audio_map = {
                    result['segment_idx']: result.get('_audio_data')
                    for result in segment_results
                    if '_audio_data' in result
                }
                
                # è°ƒç”¨ä¼˜åŒ–åçš„è¯´è¯äººåˆ†ç¦»å‡½æ•°ï¼ˆä½¿ç”¨ç¼“å­˜çš„éŸ³é¢‘æ•°æ®ï¼‰
                speaker_info = perform_speaker_diarization_with_cached_audio(
                    vad_segments=vad_segments,
                    cached_audio_map=cached_audio_map,
                    speaker_model=speaker_model,
                    device=DEVICE,
                    min_segment_duration=2.0,  # æé«˜æœ€å°ç‰‡æ®µæ—¶é•¿åˆ°2ç§’
                    distance_threshold=0.2,  # è¿›ä¸€æ­¥é™ä½é˜ˆå€¼åˆ°0.2
                    audio_file_path=audio_file_path  # é™çº§æ—¶ä½¿ç”¨åŸå§‹æ–‡ä»¶
                )
            
            # å°†è¯´è¯äººä¿¡æ¯åˆå¹¶åˆ°è¯†åˆ«ç»“æœ
            if not use_pyannote:
                # Cam++ æ–¹æ¡ˆï¼šéœ€è¦æ˜ å°„speaker_infoåˆ°segment_results
                # speaker_info ä¸­çš„ speaker_id å·²ç»æ˜¯é‡æ–°æ˜ å°„åçš„è¿ç»­ç¼–å·ï¼ˆ0, 1, 2, 3...ï¼‰
                speaker_dict = {s['segment_idx']: s['speaker_id'] for s in speaker_info if 'segment_idx' in s}
                
                # ç»Ÿè®¡å“ªäº› segment_idx æœ‰å£°çº¹ä¿¡æ¯
                valid_segment_indices = set(speaker_dict.keys())
                logger.debug(f"ğŸ” æœ‰æ•ˆå£°çº¹ç‰‡æ®µç´¢å¼•: {sorted(valid_segment_indices)}")
                
                # ä¸ºæ‰€æœ‰ç‰‡æ®µåˆ†é…è¯´è¯äººIDï¼ˆå¦‚æœæŸä¸ªç‰‡æ®µæ²¡æœ‰å£°çº¹ï¼Œä½¿ç”¨æœ€è¿‘çš„æœ‰å£°çº¹ç‰‡æ®µçš„è¯´è¯äººï¼‰
                for idx, result in enumerate(segment_results):
                    seg_idx = result.get('segment_idx', -1)
                    
                    if seg_idx in speaker_dict:
                        # æœ‰å£°çº¹ä¿¡æ¯ï¼Œç›´æ¥ä½¿ç”¨ï¼ˆå·²ç»æ˜¯è¿ç»­ç¼–å· 0, 1, 2, 3...ï¼‰
                        result['speaker_id'] = speaker_dict[seg_idx]
                    else:
                        # æ²¡æœ‰å£°çº¹ä¿¡æ¯ï¼Œæ‰¾åˆ°æœ€è¿‘çš„æœ‰å£°çº¹ç‰‡æ®µ
                        found_speaker = None
                        min_distance = float('inf')
                        
                        # æŸ¥æ‰¾æœ€è¿‘çš„æœ‰æ•ˆç‰‡æ®µ
                        for valid_idx in valid_segment_indices:
                            distance = abs(valid_idx - seg_idx)
                            if distance < min_distance:
                                min_distance = distance
                                found_speaker = speaker_dict[valid_idx]
                        
                        # å¦‚æœæ‰¾åˆ°äº†ï¼Œä½¿ç”¨è¯¥è¯´è¯äººIDï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤å€¼"0"
                        result['speaker_id'] = found_speaker if found_speaker is not None else "0"
            else:
                # Pyannote æ–¹æ¡ˆï¼šå·²ç»ç›´æ¥æ›´æ–°äº†segment_resultsï¼Œä¸éœ€è¦é¢å¤–å¤„ç†
                logger.debug("âœ… Pyannote å·²ç›´æ¥æ›´æ–°è¯´è¯äººä¿¡æ¯ï¼Œè·³è¿‡æ˜ å°„æ­¥éª¤")
        
        # å¼ºåˆ¶é‡æ–°æ˜ å°„è¯´è¯äººIDï¼Œç¡®ä¿ä»0å¼€å§‹è¿ç»­ç¼–å·
        # æ³¨æ„ï¼šè¿™åªæ˜¯ç¼–å·è§„èŒƒåŒ–ï¼Œä¸å½±å“è¯†åˆ«ç»“æœï¼
        # å“ªäº›ç‰‡æ®µå±äºå“ªä¸ªè¯´è¯äººæ˜¯ç”±å£°çº¹èšç±»ç®—æ³•å†³å®šçš„ï¼Œä¸æ˜¯å†™æ­»çš„
        # å¦‚æœè¯´è¯äººåˆ†ç¦»å·²ç¦ç”¨ï¼ˆç”±ä¸»æœåŠ¡ä½¿ç”¨Pyannoteå¤„ç†ï¼‰ï¼Œåˆ™è·³è¿‡æ­¤æ­¥éª¤
        
        if not enable_speaker_diarization:
            # è¯´è¯äººåˆ†ç¦»å·²ç¦ç”¨ï¼Œè·³è¿‡ç¼–å·è§„èŒƒåŒ–
            logger.debug("â„¹ï¸ è¯´è¯äººåˆ†ç¦»å·²ç¦ç”¨ï¼Œè·³è¿‡ç¼–å·è§„èŒƒåŒ–ï¼ˆå°†ç”±ä¸»æœåŠ¡å¤„ç†ï¼‰")
        else:
            all_speaker_ids = set(r['speaker_id'] for r in segment_results)
            
            # æ‰¾å‡ºæ¯ä¸ªè¯´è¯äººIDç¬¬ä¸€æ¬¡å‡ºç°çš„æ—¶é—´
            first_occurrence = {}
            for result in segment_results:
                speaker_id = result['speaker_id']
                start_time = result.get('start_time', 0)
                if speaker_id not in first_occurrence or start_time < first_occurrence[speaker_id]:
                    first_occurrence[speaker_id] = start_time
            
            # æŒ‰ç¬¬ä¸€æ¬¡å‡ºç°çš„æ—¶é—´æ’åºï¼ˆç¬¬ä¸€ä¸ªå‡ºç°çš„è¯´è¯äºº -> 0ï¼Œç¬¬äºŒä¸ª -> 1...ï¼‰
            unique_speakers = sorted(all_speaker_ids, key=lambda x: first_occurrence[x])
            n_speakers = len(unique_speakers)
            
            # é‡æ–°æ˜ å°„ï¼šç¬¬ä¸€ä¸ªå‡ºç°çš„è¯´è¯äºº -> 0ï¼Œç¬¬äºŒä¸ª -> 1...
            # è¿™åªæ˜¯ç¼–å·è§„èŒƒåŒ–ï¼Œä¸å½±å“å“ªäº›ç‰‡æ®µå±äºå“ªä¸ªè¯´è¯äºº
            
            speaker_remap = {old_id: str(new_id) for new_id, old_id in enumerate(unique_speakers)}
            logger.debug(f"ğŸ” æ˜ å°„å…³ç³»: {speaker_remap}")
            
            for result in segment_results:
                old_id = result['speaker_id']
                result['speaker_id'] = speaker_remap[old_id]
            
            # éªŒè¯æ˜ å°„ç»“æœ
            final_ids = sorted(set(int(r['speaker_id']) for r in segment_results))
            if final_ids != list(range(n_speakers)):
                logger.error(f"âŒ æ˜ å°„åIDä»ä¸è¿ç»­: {final_ids}")
            else:
                # æ£€æŸ¥ç¬¬ä¸€ä¸ªç‰‡æ®µçš„ID
                first_speaker_id = segment_results[0]['speaker_id'] if segment_results else "N/A"
                logger.info(f"âœ… ç¼–å·è§„èŒƒåŒ–å®Œæˆ: 0-{n_speakers-1}ï¼Œç¬¬ä¸€ä¸ªç‰‡æ®µ speaker_id={first_speaker_id}")
            
            logger.info(f"âœ… è¯´è¯äººåˆ†ç¦»å®Œæˆï¼Œè¯†åˆ«å‡º {n_speakers} ä¸ªè¯´è¯äººï¼ˆåŸºäºçœŸå®å£°çº¹èšç±»ï¼‰")
        
        # ===== æ­¥éª¤4ï¼šæ„å»ºæœ€ç»ˆç»“æœ =====
        html_text = full_text  # ä¿æŒå…¼å®¹æ€§
        transcript = segment_results
        
        # æ¸…ç† transcript ä¸­çš„ä¸´æ—¶å­—æ®µ
        for item in transcript:
            if 'segment_idx' in item:
                del item['segment_idx']
            if '_audio_data' in item:
                del item['_audio_data']  # æ¸…ç†ç¼“å­˜çš„éŸ³é¢‘æ•°æ®
        
        logger.info(f"âœ… æœ€ç»ˆç»“æœ: {len(transcript)} ä¸ªç‰‡æ®µ, {len(set(t['speaker_id'] for t in transcript))} ä¸ªè¯´è¯äºº")
        
        # å…¼å®¹æ—§çš„è§£æé€»è¾‘ï¼ˆä»¥ä¸‹ä»£ç ä¸ä¼šæ‰§è¡Œï¼Œä½†ä¿ç•™ä»¥é˜²ä¸‡ä¸€ï¼‰
        if False:  # ç¦ç”¨æ—§é€»è¾‘
            result = {}
            sentence_info = None
            
            if sentence_info and len(sentence_info) > 0:
                logger.info(f"âœ… ä½¿ç”¨å¥å­çº§åˆ«è§£æï¼ˆå«è¯´è¯äººè¯†åˆ«ï¼‰")
                for sent in sentence_info:
                    text = sent.get("text", "").strip()
                    if not text:
                        continue
                    
                    # æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
                    timestamps = sent.get("timestamp", [])
                    if timestamps and len(timestamps) > 0:
                        start_ms = timestamps[0][0] if isinstance(timestamps[0], list) else 0
                        end_ms = timestamps[-1][1] if isinstance(timestamps[-1], list) else 0
                    else:
                        start_ms = 0
                        end_ms = 0
                    
                    # è¯´è¯äººIDï¼ˆSenseVoiceSmall ä½¿ç”¨ speaker_id å­—æ®µï¼‰
                    speaker_id = str(sent.get("speaker_id", sent.get("spk", "0")))
                    
                    # âœ… æå–ç½®ä¿¡åº¦ï¼ˆå¦‚æœæœ‰ï¼‰
                    confidence = sent.get("confidence", None)
                    
                    item = {
                        "text": text,
                        "start_time": round(start_ms / 1000.0, 2),
                        "end_time": round(end_ms / 1000.0, 2),
                        "speaker_id": speaker_id
                    }
                    
                    # å¦‚æœæœ‰ç½®ä¿¡åº¦ä¿¡æ¯ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
                    if confidence is not None:
                        item["confidence"] = round(confidence, 3)
                    
                    transcript.append(item)
            
            # ===== æ–¹æ¡ˆ2: è¯çº§åˆ«ï¼ˆéœ€è¦åˆå¹¶æˆå¥å­ï¼‰ =====
            else:
                logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°å¥å­çº§ä¿¡æ¯ï¼Œä½¿ç”¨è¯çº§åˆ«åˆå¹¶")
                raw_stamp = result.get("timestamp", [])
                
                if raw_stamp and len(raw_stamp) > 0:
                    # åˆå¹¶ç­–ç•¥ï¼šé‡åˆ°æ ‡ç‚¹æˆ–åœé¡¿è¶…è¿‡1ç§’åˆ™åˆ†å¥
                    current_sentence = []
                    current_start = None
                    current_end = None
                    sentence_count = 0
                    
                    for item in raw_stamp:
                        if not isinstance(item, list) or len(item) < 2:
                            continue
                        
                        t_range = item[0]
                        word = str(item[-1]).strip()
                        
                        if not isinstance(t_range, list) or len(t_range) < 2:
                            continue
                        
                        start_ms = t_range[0]
                        end_ms = t_range[1]
                        
                        # ç¬¬ä¸€ä¸ªè¯
                        if current_start is None:
                            current_start = start_ms
                        
                        current_sentence.append(word)
                        current_end = end_ms
                        
                        # åˆ†å¥æ¡ä»¶ï¼šé‡åˆ°æ ‡ç‚¹ç¬¦å·
                        if word in ["ã€‚", "ï¼Ÿ", "ï¼", ".", "?", "!"]:
                            sentence_text = "".join(current_sentence)
                            if sentence_text and sentence_text not in ["ã€‚", "ï¼Ÿ", "ï¼"]:
                                sentence_count += 1
                                transcript.append({
                                    "text": sentence_text,
                                    "start_time": round(current_start / 1000.0, 2),
                                    "end_time": round(current_end / 1000.0, 2),
                                    "speaker_id": str((sentence_count - 1) % 5 + 1)  # å‡è®¾æœ€å¤š5ä¸ªäººï¼Œå¾ªç¯åˆ†é…
                                })
                            # é‡ç½®
                            current_sentence = []
                            current_start = None
                    
                    # å¤„ç†æœ€åä¸€å¥ï¼ˆæ²¡æœ‰æ ‡ç‚¹ç»“å°¾çš„ï¼‰
                    if current_sentence:
                        sentence_text = "".join(current_sentence)
                        if sentence_text:
                            sentence_count += 1
                            transcript.append({
                                "text": sentence_text,
                                "start_time": round(current_start / 1000.0, 2),
                                "end_time": round(current_end / 1000.0, 2),
                                "speaker_id": str((sentence_count - 1) % 5 + 1)
                            })
                    
                    logger.info(f"ğŸ“ åˆå¹¶å®Œæˆ: {len(raw_stamp)}ä¸ªè¯ -> {len(transcript)}ä¸ªå¥å­")
                else:
                    # å®Œå…¨æ²¡æœ‰æ—¶é—´æˆ³ä¿¡æ¯
                    logger.warning("âš ï¸ æ— æ—¶é—´æˆ³ä¿¡æ¯ï¼Œè¿”å›çº¯æ–‡æœ¬")
                    transcript.append({
                        "text": full_text,
                        "start_time": 0.0,
                        "end_time": 0.0,
                        "speaker_id": "1"
                    })

        # æ ¹æ®è¾“å…¥æ¥æºæ„é€ æ—¥å¿—æè¿°ï¼ˆfile å¯èƒ½ä¸º Noneï¼Œä¾‹å¦‚é€šè¿‡ audio_url è°ƒç”¨æ—¶ï¼‰
        if file is not None and getattr(file, "filename", None):
            src_desc = file.filename
        elif isinstance(input_data, str) and input_data.startswith(("http://", "https://")):
            src_desc = input_data
        elif isinstance(input_data, str):
            src_desc = input_data
        else:
            src_desc = "æœªçŸ¥æ¥æºéŸ³é¢‘"

        logger.info(f"âœ… è¯†åˆ«æˆåŠŸ: {src_desc} (é•¿åº¦: {len(full_text)}å­—)")
        
        # ===== çƒ­è¯åå¤„ç†æ›¿æ¢ï¼ˆSenseVoiceSmall ä¸“ç”¨ï¼‰=====
        # SenseVoiceSmall ä¸æ”¯æŒåŸç”Ÿçƒ­è¯ï¼Œéœ€è¦åœ¨ç»“æœä¸­è¿›è¡Œæ–‡æœ¬æ›¿æ¢
        try:
            if combined_hotwords:
                hotword_svc = get_hotword_service()
                # è¯»å– hotwords.json æ–‡ä»¶è·å– mappings
                import json
                hotwords_path = Path(__file__).parent / "hotwords.json"
                if hotwords_path.exists():
                    with open(hotwords_path, 'r', encoding='utf-8') as f:
                        hotwords_data = json.load(f)
                    mappings = hotwords_data.get("mappings", {})
                else:
                    mappings = {}
                
                if mappings:
                    # åˆå¹¶æ‰€æœ‰æ˜ å°„è¡¨
                    all_mappings = {}
                    for category, mapping_dict in mappings.items():
                        if isinstance(mapping_dict, dict):
                            all_mappings.update(mapping_dict)
                    
                    if all_mappings:
                        logger.info(f"ğŸ”„ åº”ç”¨çƒ­è¯æ˜ å°„: {len(all_mappings)} ä¸ª")
                        
                        # å¯¹ transcript ä¸­çš„æ¯ä¸ªæ–‡æœ¬è¿›è¡Œæ›¿æ¢
                        for item in transcript:
                            text = item.get("text", "")
                            for oral_form, standard_form in all_mappings.items():
                                text = text.replace(oral_form, standard_form)
                            item["text"] = text
                        
                        # åŒæ—¶æ›´æ–° full_text
                        for oral_form, standard_form in all_mappings.items():
                            full_text = full_text.replace(oral_form, standard_form)
                        
                        logger.info("âœ… çƒ­è¯æ›¿æ¢å®Œæˆ")
        except Exception as e:
            logger.warning(f"âš ï¸ çƒ­è¯æ›¿æ¢å¤±è´¥: {e}")
        
        # ===== æ³¨æ„ï¼šå£°çº¹åŒ¹é…å·²ç§»è‡³ä¸»æœåŠ¡ï¼ˆapp/api/endpoints.pyï¼‰=====
        # å£°çº¹åŒ¹é…åº”è¯¥åœ¨ Pyannote è¯´è¯äººåˆ†ç¦»ä¹‹åæ‰§è¡Œï¼Œç”¨äºè¯†åˆ«è¯´è¯äººçš„çœŸå®èº«ä»½
        # å› æ­¤ä¸å†åœ¨ FunASR æœåŠ¡ä¸­æ‰§è¡Œå£°çº¹åŒ¹é…
        
        return {
            "code": 0,
            "msg": "success",
            "text": full_text,
            "html": html_text,
            "data": {
                "text": full_text,
                "html": html_text,
                "transcript": transcript
            }
        }

    except Exception as e:
        # è¿™é‡ŒåŒæ ·è¦è€ƒè™‘ file å¯èƒ½ä¸º None çš„æƒ…å†µ
        err_src = None
        if file is not None and getattr(file, "filename", None):
            err_src = file.filename
        elif "input_data" in locals():
            err_src = str(input_data)
        else:
            err_src = "æœªçŸ¥æ¥æºéŸ³é¢‘"

        logger.error(f"âŒ è¯†åˆ«å‡ºé”™: {err_src} - {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail="Internal Server Error")
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œå˜é‡
        if temp_file_path and temp_file_path.exists():
            try:
                temp_file_path.unlink()
            except Exception:
                pass

        if 'input_data' in locals(): del input_data
        if 'res' in locals(): del res
        
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            
        logger.info("ğŸ§¹ å†…å­˜æ¸…ç†å®Œæˆï¼Œå‡†å¤‡è¿æ¥ä¸‹ä¸€ä¸ªä»»åŠ¡")


# =============================================
# çƒ­è¯ç®¡ç†API
# =============================================

@router.get("/hotwords")
async def get_hotwords():
    """è·å–å½“å‰çƒ­è¯åˆ—è¡¨"""
    try:
        hotword_svc = get_hotword_service()
        return {
            "code": 0,
            "msg": "success",
            "data": {
                "categories": hotword_svc.get_categories(),
                "hotwords": hotword_svc.hotwords_cache,
                "stats": hotword_svc.get_stats(),
                "total": len(hotword_svc.get_all_hotwords())
            }
        }
    except Exception as e:
        logger.error(f"âŒ è·å–çƒ­è¯å¤±è´¥: {e}")
        return {"code": 500, "msg": str(e)}


@router.post("/hotwords/reload")
async def reload_hotwords():
    """é‡æ–°åŠ è½½çƒ­è¯é…ç½®"""
    try:
        hotword_svc = get_hotword_service()
        success = hotword_svc.reload()
        
        if success:
            return {
                "code": 0,
                "msg": "çƒ­è¯é‡è½½æˆåŠŸ",
                "data": {
                    "total": len(hotword_svc.get_all_hotwords()),
                    "stats": hotword_svc.get_stats()
                }
            }
        else:
            return {"code": 500, "msg": "é‡è½½å¤±è´¥"}
    except Exception as e:
        logger.error(f"âŒ é‡è½½çƒ­è¯å¤±è´¥: {e}")
        return {"code": 500, "msg": str(e)}


app.include_router(router)

if __name__ == "__main__":
    logger.info("ğŸš€ å¯åŠ¨ HTTP æœåŠ¡: http://0.0.0.0:8002")
    uvicorn.run(app, host="0.0.0.0", port=8002)