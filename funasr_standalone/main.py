#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FunASR ç‹¬ç«‹æœåŠ¡ - ç”Ÿäº§çº§é…ç½®
ç«¯å£: 8002
åŠŸèƒ½: CPUé‡åŒ–åŠ é€Ÿ + è‡ªåŠ¨æ—¥å¿—è®°å½•
"""
# =============================================
# 0. ä¿®å¤ datasets å…¼å®¹æ€§é—®é¢˜ï¼ˆå¿…é¡»åœ¨å¯¼å…¥å…¶ä»–æ¨¡å—ä¹‹å‰ï¼‰
# =============================================
def _fix_datasets_compatibility():
    """ä¿®å¤ datasets ä¸ modelscope çš„å…¼å®¹æ€§é—®é¢˜"""
    try:
        import datasets
        
        # ä¿®å¤ LargeList å¯¼å…¥
        if not hasattr(datasets, 'LargeList'):
            try:
                from datasets import LargeList
            except ImportError:
                try:
                    import pyarrow as pa
                    if hasattr(pa, 'large_list'):
                        datasets.LargeList = pa.large_list
                    elif hasattr(pa, 'LargeList'):
                        datasets.LargeList = pa.LargeList
                except Exception:
                    pass
        
        # ä¿®å¤ _FEATURE_TYPES å¯¼å…¥ï¼ˆdatasets 2.19+ ä¸­å¯èƒ½å·²ç§»é™¤ï¼‰
        try:
            from datasets.features.features import _FEATURE_TYPES
        except ImportError:
            try:
                # å°è¯•ä»æ–°ä½ç½®å¯¼å…¥
                from datasets.features import _FEATURE_TYPES
            except ImportError:
                try:
                    # å¦‚æœä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªå…¼å®¹çš„å ä½ç¬¦
                    import datasets.features.features as features_module
                    if not hasattr(features_module, '_FEATURE_TYPES'):
                        # åˆ›å»ºä¸€ä¸ªç©ºçš„å­—å…¸ä½œä¸ºå ä½ç¬¦
                        features_module._FEATURE_TYPES = {}
                except Exception:
                    pass
    except Exception:
        pass  # å¦‚æœ datasets éƒ½å¯¼å…¥ä¸äº†ï¼Œè®©åç»­ä»£ç è‡ªå·±å¤„ç†é”™è¯¯

# ç«‹å³æ‰§è¡Œä¿®å¤
_fix_datasets_compatibility()

import os
import sys
import logging
from logging.handlers import RotatingFileHandler
from pathlib import Path
from fastapi import FastAPI, UploadFile, File, HTTPException, Form, APIRouter
import uvicorn
import tempfile
import shutil
import gc
import torch
from hotword_service import get_hotword_service  # âœ… å¯¼å…¥çƒ­è¯æœåŠ¡
from audio_preprocessor import audio_preprocessor  # âœ… å¯¼å…¥éŸ³é¢‘é¢„å¤„ç†
# å£°çº¹åŒ¹é…å»¶è¿ŸåŠ è½½ï¼Œé¿å…å¯åŠ¨æ—¶çš„ä¾èµ–é”™è¯¯
# from voice_matcher import get_voice_matcher

# =============================================
# 1. æ—¥å¿—é…ç½® (å­˜å…¥ ./logs ç›®å½•)
# =============================================
# ç¡®ä¿ logs ç›®å½•å­˜åœ¨
LOG_DIR = Path(__file__).parent / "logs"
LOG_DIR.mkdir(exist_ok=True)
LOG_FILE = LOG_DIR / "funasr_service.log"

# åˆ›å»º logger
logger = logging.getLogger("funasr_service")
logger.setLevel(logging.INFO)

# æ ¼å¼ï¼šæ—¶é—´ - çº§åˆ« - æ¶ˆæ¯
formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")

# å¤„ç†å™¨1ï¼šæ§åˆ¶å°è¾“å‡º 
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setFormatter(formatter)

# å¤„ç†å™¨2ï¼šæ–‡ä»¶è¾“å‡º (è‡ªåŠ¨åˆ‡å‰²ï¼Œé˜²æ­¢å æ»¡ç£ç›˜)
# maxBytes=10MB (æ¯ä¸ªæ–‡ä»¶æœ€å¤§10M), backupCount=10 (æœ€å¤šä¿ç•™10ä¸ªæ–‡ä»¶)
file_handler = RotatingFileHandler(LOG_FILE, maxBytes=10*1024*1024, backupCount=10, encoding='utf-8')
file_handler.setFormatter(formatter)

# é¿å…é‡å¤æ·»åŠ 
if not logger.handlers:
    logger.addHandler(console_handler)
    logger.addHandler(file_handler)

# =============================================
# 2. æ¨¡å‹åŠ è½½ (CPU ä¼˜åŒ–)
# =============================================
try:
    from funasr import AutoModel
    logger.info("ğŸ“¦ æ­£åœ¨åˆå§‹åŒ–æœåŠ¡...")
    
    if torch.cuda.is_available():
        DEVICE = "cuda"
        logger.info("âœ… æ£€æµ‹åˆ°å¯ç”¨ GPUï¼Œä½¿ç”¨ CUDA åŠ é€Ÿ")
    else:
        DEVICE = "cpu"
        logger.info("âš ï¸ æœªæ£€æµ‹åˆ° GPUï¼Œä½¿ç”¨ CPU æ¨¡å¼")
        
    # å¢åŠ çº¿ç¨‹æ•°ä»¥åˆ©ç”¨æœåŠ¡å™¨çš„ 16æ ¸ CPU
    NCPU = 8 
    
    logger.info(f"âš™ï¸ åŠ è½½æ¨¡å‹ä¸­... (Device: {DEVICE}, Threads: {NCPU})")
    
    # =================== é…ç½®ï¼šSenseVoiceSmall é«˜å‡†ç¡®ç‡æ–¹æ¡ˆ ===================
    # ç­–ç•¥ï¼šSenseVoiceSmall ç”¨äºé«˜å‡†ç¡®ç‡è¯†åˆ«ï¼ŒVAD å’Œè¯´è¯äººåˆ†ç¦»ç‹¬ç«‹å¤„ç†
    
    # 1. SenseVoiceSmall ä¸»æ¨¡å‹ï¼ˆä»…è¯†åˆ«ï¼Œä¸ä½¿ç”¨ spk_modelï¼‰
    logger.info("ğŸ“¦ åŠ è½½ SenseVoiceSmall ä¸»æ¨¡å‹ï¼ˆé«˜å‡†ç¡®ç‡è¯†åˆ«ï¼‰...")
    asr_model = AutoModel(
        model="iic/SenseVoiceSmall",
        device=DEVICE,
        ncpu=NCPU,
        disable_update=True
    )
    logger.info("âœ… SenseVoiceSmall åŠ è½½æˆåŠŸ")
    
    # 2. VAD æ¨¡å‹ï¼ˆç”¨äºè·å–æ—¶é—´æˆ³ï¼‰
    logger.info("ğŸ“¦ åŠ è½½ VAD æ¨¡å‹ï¼ˆæ—¶é—´æˆ³åˆ†å‰²ï¼‰...")
    vad_model = AutoModel(
        model="fsmn-vad",
        device=DEVICE,
        disable_update=True
    )
    logger.info("âœ… VAD æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    # 3. è¯´è¯äººè¯†åˆ«æ¨¡å‹ï¼ˆç”¨äºå£°çº¹æå–å’Œèšç±»ï¼‰
    logger.info("ğŸ“¦ åŠ è½½ Cam++ è¯´è¯äººæ¨¡å‹ï¼ˆè¯´è¯äººåˆ†ç¦»ï¼‰...")
    speaker_model = AutoModel(
        model="iic/speech_campplus_sv_zh-cn_16k-common",
        device=DEVICE,
        disable_update=True
    )
    logger.info("âœ… Cam++ è¯´è¯äººæ¨¡å‹åŠ è½½æˆåŠŸ")
    
    # =================== æ—§æ¨¡å‹é…ç½®ï¼ˆå·²æ³¨é‡Šï¼Œå¯å›é€€ï¼‰===================
    # # Paraformer-zhï¼ˆæ ‡å‡†æ¨¡å‹ï¼‰
    # model = AutoModel(
    #     model="paraformer-zh",
    #     vad_model="fsmn-vad",
    #     punc_model="ct-punc",
    #     spk_model="cam++",
    #     device=DEVICE,
    #     ncpu=NCPU,
    #     disable_update=True,
    #     quantize=False
    # )
    
    # # Paraformer-Largeï¼ˆå¤§æ¨¡å‹ï¼Œéœ€è¦12GB+æ˜¾å­˜ï¼‰
    # model = AutoModel(
    #     model="iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
    #     model_revision="v2.0.4",
    #     spk_model="iic/speech_campplus_sv_zh-cn_16k-common",
    #     device=DEVICE,
    #     ncpu=NCPU,
    #     disable_update=True,
    #     quantize=False
    # )
    
    logger.info("âœ… æ‰€æœ‰æ¨¡å‹åŠ è½½æˆåŠŸï¼æœåŠ¡å°±ç»ªã€‚")
    
except Exception as e:
    logger.critical(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}", exc_info=True)
    sys.exit(1)

# =============================================
# 3. FastAPI æœåŠ¡
# =============================================
app = FastAPI(title="FunASR Service", version="1.0.0")

router = APIRouter(prefix="/api/v1")

# å¥åº·æ£€æŸ¥æ¥å£ (è§£å†³ 404 Health é”™è¯¯)
@router.get("/health")
async def health_check():
    return {"status": "ok", "message": "FunASR Service is running"}

# æ”¯æŒ file ä¸Šä¼ æˆ– audio_url ä¸¤ç§è¾“å…¥æ–¹å¼
@router.post("/transcribe")
async def transcribe(
    # 1. file æ”¹ä¸ºå¯é€‰
    file: UploadFile = File(None), 
    # 2. url å‚æ•°
    audio_url: str = Form(None),   
    hotword: str = Form("")  # å¤–éƒ¨ä¼ å…¥çš„çƒ­è¯ï¼ˆå¯é€‰ï¼‰
):
    temp_file_path = None
    input_data = None 

    try:
        # === é€»è¾‘åˆ¤æ–­ ===
        if file:
            logger.info(f"ğŸ“¥ æ¥æ”¶åˆ°æ–‡ä»¶ä¸Šä¼ : {file.filename}")
            suffix = Path(file.filename).suffix
            # å­˜ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                shutil.copyfileobj(file.file, tmp)
                temp_file_path = Path(tmp.name)
            input_data = str(temp_file_path)

        elif audio_url:
            logger.info(f"ğŸ”— æ¥æ”¶åˆ°éŸ³é¢‘ URL: {audio_url}")
            input_data = audio_url.strip() # å»é™¤ç©ºæ ¼
            
        else:
            raise HTTPException(status_code=400, detail="å¿…é¡»æä¾› file æˆ– audio_url")

        # === éŸ³é¢‘é¢„å¤„ç†ï¼ˆå¯é€‰ï¼Œæå‡å‡†ç¡®ç‡3-5%ï¼‰===
        if isinstance(input_data, str) and Path(input_data).exists():
            processed_input = audio_preprocessor.preprocess(input_data)
            if processed_input != input_data:
                logger.info("âœ… ä½¿ç”¨é¢„å¤„ç†åçš„éŸ³é¢‘")
                input_data = processed_input
        
        # === è‡ªåŠ¨åŠ è½½çƒ­è¯ ===
        try:
            hotword_svc = get_hotword_service()
            auto_hotwords = hotword_svc.get_hotwords_string()
            
            # åˆå¹¶å¤–éƒ¨ä¼ å…¥çš„çƒ­è¯å’Œè‡ªåŠ¨åŠ è½½çš„çƒ­è¯
            if hotword and auto_hotwords:
                combined_hotwords = f"{hotword} {auto_hotwords}"
            elif auto_hotwords:
                combined_hotwords = auto_hotwords
            else:
                combined_hotwords = hotword
                
            hotword_count = len(hotword_svc.get_all_hotwords())
            logger.info(f"ğŸ”¥ çƒ­è¯å·²åŠ è½½: {hotword_count} ä¸ª")
        except Exception as e:
            logger.warning(f"âš ï¸ çƒ­è¯åŠ è½½å¤±è´¥: {e}ï¼Œå°†ä¸ä½¿ç”¨çƒ­è¯")
            combined_hotwords = hotword
        
        # === å¼€å§‹æ¨ç† ===
        logger.info(f"ğŸ¤ å¼€å§‹è¯­éŸ³è¯†åˆ«... (çƒ­è¯: {len(combined_hotwords)} å­—ç¬¦)")

        # ===== æ­¥éª¤1ï¼šä½¿ç”¨ VAD è·å–è¯­éŸ³æ®µæ—¶é—´æˆ³ =====
        logger.info("ğŸ¤ æ­¥éª¤1: VAD è¯­éŸ³åˆ†æ®µ...")
        vad_res = vad_model.generate(
            input=input_data,
            batch_size_s=60  # æ¯60ç§’ä¸€æ®µ
        )
        
        # æå– VAD åˆ†æ®µä¿¡æ¯
        vad_segments = []
        if vad_res and len(vad_res) > 0:
            vad_result = vad_res[0]
            vad_segments = vad_result.get("value", [])
        
        if not vad_segments or len(vad_segments) == 0:
            logger.warning("âš ï¸ VAD æœªæ£€æµ‹åˆ°è¯­éŸ³æ®µï¼Œä½¿ç”¨å…¨æ–‡è¯†åˆ«")
            vad_segments = [[0, -1]]  # ä½¿ç”¨æ•´ä¸ªéŸ³é¢‘
        
        logger.info(f"âœ… VAD æ£€æµ‹åˆ° {len(vad_segments)} ä¸ªè¯­éŸ³æ®µ")
        
        # ===== æ­¥éª¤2ï¼šæ‰¹é‡æå–ç‰‡æ®µå¹¶è¯†åˆ«ï¼ˆä¼˜åŒ–ï¼šæ‰¹é‡å¤„ç† + å†…å­˜ç¼“å­˜ï¼‰=====
        logger.info("ğŸ¤ æ­¥éª¤2: SenseVoiceSmall æ‰¹é‡è¯†åˆ«ï¼ˆä¼˜åŒ–ç‰ˆï¼‰...")
        
        # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæœ‰ï¼‰
        audio_file_path = str(temp_file_path) if temp_file_path else input_data
        
        # é…ç½®ï¼š10GBæ˜¾å­˜ä¼˜åŒ–
        BATCH_SIZE = 8  # æ¯æ‰¹å¤„ç†8ä¸ªç‰‡æ®µï¼ˆ10GBæ˜¾å­˜ï¼‰
        MAX_CONCURRENT = 2  # æœ€å¤š2ä¸ªå¹¶å‘çº¿ç¨‹
        
        import subprocess
        import tempfile as tmp
        import re
        from concurrent.futures import ThreadPoolExecutor, as_completed
        import io
        import soundfile as sf
        import numpy as np
        
        # ä¼˜åŒ–1&4: æ‰¹é‡æå–ç‰‡æ®µåˆ°å†…å­˜ï¼Œé¿å…é¢‘ç¹ç£ç›˜I/O
        logger.info(f"ğŸ“¦ æ‰¹é‡æå– {len(vad_segments)} ä¸ªéŸ³é¢‘ç‰‡æ®µåˆ°å†…å­˜...")
        segment_audio_data = {}  # {segment_idx: (audio_data, sample_rate)}
        segment_metadata = {}  # {segment_idx: (start_ms, end_ms)}
        
        def extract_segment_to_memory(idx, segment):
            """æå–å•ä¸ªç‰‡æ®µåˆ°å†…å­˜"""
            if not isinstance(segment, list) or len(segment) < 2:
                return None, None
            
            start_ms, end_ms = segment[0], segment[1]
            
            try:
                # ä½¿ç”¨ ffmpeg æå–åˆ°å†…å­˜ï¼ˆé€šè¿‡ç®¡é“ï¼‰
                cmd = ["ffmpeg", "-i", audio_file_path, "-ss", str(start_ms / 1000.0)]
                
                if end_ms != -1:
                    duration = (end_ms - start_ms) / 1000.0
                    cmd.extend(["-t", str(duration)])
                
                cmd.extend([
                    "-ac", "1", "-ar", "16000",
                    "-f", "wav",
                    "-"  # è¾“å‡ºåˆ°stdout
                ])
                
                # æå–éŸ³é¢‘æ•°æ®åˆ°å†…å­˜
                result = subprocess.run(
                    cmd, 
                    check=True, 
                    capture_output=True, 
                    timeout=30
                )
                
                # ä»å†…å­˜ä¸­è¯»å–éŸ³é¢‘æ•°æ®
                audio_io = io.BytesIO(result.stdout)
                audio_data, sample_rate = sf.read(audio_io)
                
                return (audio_data, sample_rate), (start_ms, end_ms)
                
            except Exception as e:
                logger.warning(f"âš ï¸ æå–ç‰‡æ®µ {idx} å¤±è´¥: {e}")
                return None, None
        
        # ä¼˜åŒ–3: å¹¶è¡Œæå–ç‰‡æ®µï¼ˆæ§åˆ¶å¹¶å‘æ•°ï¼‰
        with ThreadPoolExecutor(max_workers=MAX_CONCURRENT) as executor:
            futures = {
                executor.submit(extract_segment_to_memory, idx, segment): idx 
                for idx, segment in enumerate(vad_segments)
            }
            
            for future in as_completed(futures):
                idx = futures[future]
                try:
                    audio_data_info, metadata = future.result()
                    if audio_data_info is not None:
                        segment_audio_data[idx] = audio_data_info
                        segment_metadata[idx] = metadata
                except Exception as e:
                    logger.warning(f"âš ï¸ æå–ç‰‡æ®µ {idx} å¼‚å¸¸: {e}")
        
        logger.info(f"âœ… æˆåŠŸæå– {len(segment_audio_data)} ä¸ªç‰‡æ®µåˆ°å†…å­˜")
        
        # ä¼˜åŒ–2: æ‰¹é‡è¯†åˆ«ï¼ˆåˆ†æ‰¹å¤„ç†ï¼Œé¿å…æ˜¾å­˜æº¢å‡ºï¼‰
        segment_results = []
        full_text_parts = []
        
        # æŒ‰segment_idxæ’åºï¼Œç¡®ä¿é¡ºåº
        sorted_indices = sorted(segment_audio_data.keys())
        
        # åˆ†æ‰¹å¤„ç†
        for batch_start in range(0, len(sorted_indices), BATCH_SIZE):
            batch_indices = sorted_indices[batch_start:batch_start + BATCH_SIZE]
            logger.info(f"ğŸ”„ æ‰¹é‡è¯†åˆ«ç‰‡æ®µ {batch_start+1}-{min(batch_start+BATCH_SIZE, len(sorted_indices))}/{len(sorted_indices)}")
            
            # å°†å†…å­˜ä¸­çš„éŸ³é¢‘æ•°æ®å†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼ˆæ‰¹é‡è¯†åˆ«éœ€è¦æ–‡ä»¶è·¯å¾„ï¼‰
            batch_files = []
            batch_metadata = []
            
            for idx in batch_indices:
                audio_data, sample_rate = segment_audio_data[idx]
                start_ms, end_ms = segment_metadata[idx]
                
                # å†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼ˆæ‰¹é‡è¯†åˆ«éœ€è¦ï¼‰
                temp_segment = tmp.NamedTemporaryFile(delete=False, suffix=".wav")
                temp_segment.close()
                temp_segment_path = temp_segment.name
                
                sf.write(temp_segment_path, audio_data, sample_rate)
                batch_files.append(temp_segment_path)
                batch_metadata.append((idx, start_ms, end_ms))
            
            # æ‰¹é‡è¯†åˆ«
            try:
                batch_results = asr_model.generate(
                    input=batch_files,
                    language="zh",
                    use_itn=True
                )
                
                # å¤„ç†æ‰¹é‡è¯†åˆ«ç»“æœ - æŒ‰å¥å­åˆ‡åˆ†
                for i, (idx, start_ms, end_ms) in enumerate(batch_metadata):
                    if i < len(batch_results) and batch_results[i]:
                        result_item = batch_results[i]
                        text = result_item.get("text", "").strip()
                        
                        # æ¸…ç† SenseVoice çš„è¯­è¨€æ ‡ç­¾
                        text = re.sub(r'<\|[^|]+\|>', '', text).strip()
                        
                        # è¿‡æ»¤éä¸­æ–‡å†…å®¹
                        if text:
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ—¥æ–‡å‡å
                            if re.search(r'[\u3040-\u309F\u30A0-\u30FF]', text):
                                logger.debug(f"â­ï¸ è¿‡æ»¤æ—¥æ–‡å†…å®¹: {text[:20]}...")
                                continue
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«éŸ©æ–‡
                            if re.search(r'[\uAC00-\uD7AF]', text):
                                logger.debug(f"â­ï¸ è¿‡æ»¤éŸ©æ–‡å†…å®¹: {text[:20]}...")
                                continue
                            # æ£€æŸ¥æ˜¯å¦ä¸»è¦æ˜¯è‹±æ–‡å•è¯
                            english_chars = len(re.findall(r'[a-zA-Z]', text))
                            if len(text) > 0 and english_chars / len(text) > 0.5:
                                logger.debug(f"â­ï¸ è¿‡æ»¤è‹±æ–‡å†…å®¹: {text[:20]}...")
                                continue
                        
                        if not text:
                            continue
                        
                        # ä¼˜åŒ–ï¼šæŒ‰å¥å­åˆ‡åˆ†ï¼Œè€Œä¸æ˜¯æŒ‰VADæ®µ
                        # æ£€æŸ¥æ˜¯å¦æœ‰timestampä¿¡æ¯ï¼ˆå¥å­çº§åˆ«ï¼‰
                        timestamp = result_item.get("timestamp", [])
                        sentences = result_item.get("sentences", [])
                        
                        if sentences and len(sentences) > 0:
                            # ä½¿ç”¨å¥å­çº§åˆ«çš„ä¿¡æ¯
                            for sent in sentences:
                                sent_text = sent.get("text", "").strip()
                                if not sent_text or len(sent_text) < 2:  # è¿‡æ»¤å¤ªçŸ­çš„å¥å­
                                    continue
                                
                                sent_timestamp = sent.get("timestamp", [])
                                if sent_timestamp and len(sent_timestamp) >= 2:
                                    sent_start = sent_timestamp[0] / 1000.0 if isinstance(sent_timestamp[0], (int, float)) else start_ms / 1000.0
                                    sent_end = sent_timestamp[1] / 1000.0 if isinstance(sent_timestamp[1], (int, float)) else end_ms / 1000.0
                                else:
                                    # å¦‚æœæ²¡æœ‰æ—¶é—´æˆ³ï¼Œä½¿ç”¨VADæ®µçš„æ—¶é—´ï¼Œä½†æŒ‰å¥å­æ¯”ä¾‹åˆ†é…
                                    sent_start = start_ms / 1000.0
                                    sent_end = end_ms / 1000.0 if end_ms != -1 else 999999
                                
                                segment_results.append({
                                    "start_time": round(sent_start, 2),
                                    "end_time": round(sent_end, 2),
                                    "text": sent_text,
                                    "segment_idx": idx,
                                    "_audio_data": segment_audio_data[idx]  # ç¼“å­˜éŸ³é¢‘æ•°æ®ä¾›æ­¥éª¤3ä½¿ç”¨
                                })
                                full_text_parts.append(sent_text)
                        elif timestamp and len(timestamp) > 0:
                            # ä½¿ç”¨timestampä¿¡æ¯æŒ‰å¥å­åˆ‡åˆ†
                            # timestampæ ¼å¼å¯èƒ½æ˜¯ [[start, end, word], ...] æˆ– [[start, end], ...]
                            current_sentence = []
                            current_start = None
                            current_end = None
                            
                            for ts_item in timestamp:
                                if not isinstance(ts_item, list) or len(ts_item) < 2:
                                    continue
                                
                                ts_start = ts_item[0] / 1000.0 if isinstance(ts_item[0], (int, float)) else start_ms / 1000.0
                                ts_end = ts_item[1] / 1000.0 if isinstance(ts_item[1], (int, float)) else end_ms / 1000.0
                                word = ts_item[-1] if len(ts_item) > 2 else ""
                                
                                if current_start is None:
                                    current_start = ts_start
                                
                                current_sentence.append(word)
                                current_end = ts_end
                                
                                # é‡åˆ°æ ‡ç‚¹ç¬¦å·æˆ–åœé¡¿è¶…è¿‡0.5ç§’ï¼Œåˆ†å¥
                                if word in ["ã€‚", "ï¼Ÿ", "ï¼", ".", "?", "!"] or (len(current_sentence) > 1 and ts_start - current_end > 0.5):
                                    sent_text = "".join(current_sentence).strip()
                                    if sent_text and len(sent_text) >= 2:  # è¿‡æ»¤å¤ªçŸ­çš„å¥å­
                                        segment_results.append({
                                            "start_time": round(current_start, 2),
                                            "end_time": round(current_end, 2),
                                            "text": sent_text,
                                            "segment_idx": idx,
                                            "_audio_data": segment_audio_data[idx]
                                        })
                                        full_text_parts.append(sent_text)
                                    current_sentence = []
                                    current_start = None
                            
                            # å¤„ç†æœ€åä¸€å¥
                            if current_sentence:
                                sent_text = "".join(current_sentence).strip()
                                if sent_text and len(sent_text) >= 2:
                                    segment_results.append({
                                        "start_time": round(current_start, 2),
                                        "end_time": round(current_end, 2),
                                        "text": sent_text,
                                        "segment_idx": idx,
                                        "_audio_data": segment_audio_data[idx]
                                    })
                                    full_text_parts.append(sent_text)
                        else:
                            # æ²¡æœ‰å¥å­çº§åˆ«ä¿¡æ¯ï¼ŒæŒ‰æ ‡ç‚¹ç¬¦å·åˆ‡åˆ†æ–‡æœ¬
                            # è¿‡æ»¤å¤ªçŸ­çš„æ–‡æœ¬ï¼ˆå°‘äº3ä¸ªå­—ï¼‰
                            if len(text) < 3:
                                continue
                            
                            # æŒ‰æ ‡ç‚¹ç¬¦å·åˆ‡åˆ†
                            sentences = re.split(r'([ã€‚ï¼ï¼Ÿ\n])', text)
                            current_sent = ""
                            sent_start = start_ms / 1000.0
                            segment_duration = (end_ms - start_ms) / 1000.0 if end_ms != -1 else 1.0
                            char_duration = segment_duration / max(len(text), 1)
                            
                            for part in sentences:
                                if not part.strip():
                                    continue
                                
                                if part in ["ã€‚", "ï¼", "ï¼Ÿ", "\n"]:
                                    if current_sent.strip() and len(current_sent.strip()) >= 2:
                                        sent_end = sent_start + len(current_sent) * char_duration
                                        segment_results.append({
                                            "start_time": round(sent_start, 2),
                                            "end_time": round(sent_end, 2),
                                            "text": current_sent.strip(),
                                            "segment_idx": idx,
                                            "_audio_data": segment_audio_data[idx]
                                        })
                                        full_text_parts.append(current_sent.strip())
                                    sent_start = sent_end
                                    current_sent = ""
                                else:
                                    current_sent += part
                            
                            # å¤„ç†æœ€åä¸€å¥
                            if current_sent.strip() and len(current_sent.strip()) >= 2:
                                sent_end = sent_start + len(current_sent) * char_duration
                                segment_results.append({
                                    "start_time": round(sent_start, 2),
                                    "end_time": round(sent_end, 2),
                                    "text": current_sent.strip(),
                                    "segment_idx": idx,
                                    "_audio_data": segment_audio_data[idx]
                                })
                                full_text_parts.append(current_sent.strip())
                
            except Exception as e:
                logger.warning(f"âš ï¸ æ‰¹é‡è¯†åˆ«å¤±è´¥: {e}ï¼Œé™çº§ä¸ºå•æ®µè¯†åˆ«")
                # é™çº§ï¼šå•æ®µè¯†åˆ«
                for idx, (start_ms, end_ms) in batch_metadata:
                    audio_data, sample_rate = segment_audio_data[idx]
                    temp_segment = tmp.NamedTemporaryFile(delete=False, suffix=".wav")
                    temp_segment.close()
                    temp_segment_path = temp_segment.name
                    sf.write(temp_segment_path, audio_data, sample_rate)
                    
                    try:
                        seg_res = asr_model.generate(
                            input=temp_segment_path,
                            language="zh",
                            use_itn=True
                        )
                        
                        if seg_res and len(seg_res) > 0:
                            text = seg_res[0].get("text", "").strip()
                            text = re.sub(r'<\|[^|]+\|>', '', text).strip()
                            
                        # é™çº§å¤„ç†ï¼šæŒ‰æ ‡ç‚¹ç¬¦å·åˆ‡åˆ†
                        if len(text) < 3:
                            continue
                        
                        # æŒ‰æ ‡ç‚¹ç¬¦å·åˆ‡åˆ†
                        sentences = re.split(r'([ã€‚ï¼ï¼Ÿ\n])', text)
                        current_sent = ""
                        sent_start = start_ms / 1000.0
                        segment_duration = (end_ms - start_ms) / 1000.0 if end_ms != -1 else 1.0
                        char_duration = segment_duration / max(len(text), 1)
                        
                        for part in sentences:
                            if not part.strip():
                                continue
                            
                            if part in ["ã€‚", "ï¼", "ï¼Ÿ", "\n"]:
                                if current_sent.strip() and len(current_sent.strip()) >= 2:
                                    sent_end = sent_start + len(current_sent) * char_duration
                                    segment_results.append({
                                        "start_time": round(sent_start, 2),
                                        "end_time": round(sent_end, 2),
                                        "text": current_sent.strip(),
                                        "segment_idx": idx,
                                        "_audio_data": segment_audio_data[idx]
                                    })
                                    full_text_parts.append(current_sent.strip())
                                sent_start = sent_end
                                current_sent = ""
                            else:
                                current_sent += part
                        
                        # å¤„ç†æœ€åä¸€å¥
                        if current_sent.strip() and len(current_sent.strip()) >= 2:
                            sent_end = sent_start + len(current_sent) * char_duration
                            segment_results.append({
                                "start_time": round(sent_start, 2),
                                "end_time": round(sent_end, 2),
                                "text": current_sent.strip(),
                                "segment_idx": idx,
                                "_audio_data": segment_audio_data[idx]
                            })
                            full_text_parts.append(current_sent.strip())
                    except Exception as e2:
                        logger.warning(f"âš ï¸ è¯†åˆ«ç‰‡æ®µ {idx} å¤±è´¥: {e2}")
                    finally:
                        try:
                            os.remove(temp_segment_path)
                        except:
                            pass
            
            finally:
                # æ¸…ç†æ‰¹é‡ä¸´æ—¶æ–‡ä»¶
                for temp_file in batch_files:
                    try:
                        os.remove(temp_file)
                    except:
                        pass
        
        full_text = "".join(full_text_parts)
        logger.info(f"âœ… ASR è¯†åˆ«å®Œæˆï¼Œå…± {len(segment_results)} ä¸ªç‰‡æ®µï¼Œæ–‡æœ¬é•¿åº¦: {len(full_text)} å­—")
        
        # ===== æ­¥éª¤3ï¼šè¯´è¯äººåˆ†ç¦»ï¼ˆä¼˜åŒ–ï¼šå¤ç”¨æ­¥éª¤2çš„éŸ³é¢‘æ•°æ®ï¼‰=====
        logger.info("ğŸ¤ æ­¥éª¤3: è¯´è¯äººåˆ†ç¦»ï¼ˆä¼˜åŒ–ï¼šå¤ç”¨ç¼“å­˜éŸ³é¢‘ï¼‰...")
        
        # ä¼˜åŒ–2: å¤ç”¨æ­¥éª¤2æå–çš„éŸ³é¢‘æ•°æ®ï¼Œé¿å…é‡å¤æå–
        from speaker_diarization import perform_speaker_diarization_with_cached_audio
        
        # æ„å»ºç¼“å­˜çš„éŸ³é¢‘æ•°æ®æ˜ å°„
        cached_audio_map = {
            result['segment_idx']: result.get('_audio_data')
            for result in segment_results
            if '_audio_data' in result
        }
        
        # è°ƒç”¨ä¼˜åŒ–åçš„è¯´è¯äººåˆ†ç¦»å‡½æ•°ï¼ˆä½¿ç”¨ç¼“å­˜çš„éŸ³é¢‘æ•°æ®ï¼‰
        speaker_info = perform_speaker_diarization_with_cached_audio(
            vad_segments=vad_segments,
            cached_audio_map=cached_audio_map,
            speaker_model=speaker_model,
            device=DEVICE,
            audio_file_path=audio_file_path  # é™çº§æ—¶ä½¿ç”¨åŸå§‹æ–‡ä»¶
        )
        
        # å°†è¯´è¯äººä¿¡æ¯åˆå¹¶åˆ°è¯†åˆ«ç»“æœ
        # speaker_info ä¸­çš„ speaker_id å·²ç»æ˜¯é‡æ–°æ˜ å°„åçš„è¿ç»­ç¼–å·ï¼ˆ0, 1, 2, 3...ï¼‰
        speaker_dict = {s['segment_idx']: s['speaker_id'] for s in speaker_info if 'segment_idx' in s}
        
        # ç»Ÿè®¡å“ªäº› segment_idx æœ‰å£°çº¹ä¿¡æ¯
        valid_segment_indices = set(speaker_dict.keys())
        logger.debug(f"ğŸ” æœ‰æ•ˆå£°çº¹ç‰‡æ®µç´¢å¼•: {sorted(valid_segment_indices)}")
        
        # ä¸ºæ‰€æœ‰ç‰‡æ®µåˆ†é…è¯´è¯äººIDï¼ˆå¦‚æœæŸä¸ªç‰‡æ®µæ²¡æœ‰å£°çº¹ï¼Œä½¿ç”¨æœ€è¿‘çš„æœ‰å£°çº¹ç‰‡æ®µçš„è¯´è¯äººï¼‰
        for idx, result in enumerate(segment_results):
            seg_idx = result.get('segment_idx', -1)
            
            if seg_idx in speaker_dict:
                # æœ‰å£°çº¹ä¿¡æ¯ï¼Œç›´æ¥ä½¿ç”¨ï¼ˆå·²ç»æ˜¯è¿ç»­ç¼–å· 0, 1, 2, 3...ï¼‰
                result['speaker_id'] = speaker_dict[seg_idx]
            else:
                # æ²¡æœ‰å£°çº¹ä¿¡æ¯ï¼Œæ‰¾åˆ°æœ€è¿‘çš„æœ‰å£°çº¹ç‰‡æ®µ
                found_speaker = None
                min_distance = float('inf')
                
                # æŸ¥æ‰¾æœ€è¿‘çš„æœ‰æ•ˆç‰‡æ®µ
                for valid_idx in valid_segment_indices:
                    distance = abs(valid_idx - seg_idx)
                    if distance < min_distance:
                        min_distance = distance
                        found_speaker = speaker_dict[valid_idx]
                
                # å¦‚æœæ‰¾åˆ°äº†ï¼Œä½¿ç”¨è¯¥è¯´è¯äººIDï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤å€¼"0"
                result['speaker_id'] = found_speaker if found_speaker is not None else "0"
        
        # å¼ºåˆ¶é‡æ–°æ˜ å°„è¯´è¯äººIDï¼Œç¡®ä¿ä»0å¼€å§‹è¿ç»­ç¼–å·
        # æ³¨æ„ï¼šè¿™åªæ˜¯ç¼–å·è§„èŒƒåŒ–ï¼Œä¸å½±å“è¯†åˆ«ç»“æœï¼
        # å“ªäº›ç‰‡æ®µå±äºå“ªä¸ªè¯´è¯äººæ˜¯ç”±å£°çº¹èšç±»ç®—æ³•å†³å®šçš„ï¼Œä¸æ˜¯å†™æ­»çš„
        
        all_speaker_ids = set(r['speaker_id'] for r in segment_results)
        
        # æ‰¾å‡ºæ¯ä¸ªè¯´è¯äººIDç¬¬ä¸€æ¬¡å‡ºç°çš„æ—¶é—´
        first_occurrence = {}
        for result in segment_results:
            speaker_id = result['speaker_id']
            start_time = result.get('start_time', 0)
            if speaker_id not in first_occurrence or start_time < first_occurrence[speaker_id]:
                first_occurrence[speaker_id] = start_time
        
        # æŒ‰ç¬¬ä¸€æ¬¡å‡ºç°çš„æ—¶é—´æ’åºï¼ˆç¬¬ä¸€ä¸ªå‡ºç°çš„è¯´è¯äºº -> 0ï¼Œç¬¬äºŒä¸ª -> 1...ï¼‰
        unique_speakers = sorted(all_speaker_ids, key=lambda x: first_occurrence[x])
        n_speakers = len(unique_speakers)
        
        # é‡æ–°æ˜ å°„ï¼šç¬¬ä¸€ä¸ªå‡ºç°çš„è¯´è¯äºº -> 0ï¼Œç¬¬äºŒä¸ª -> 1...
        # è¿™åªæ˜¯ç¼–å·è§„èŒƒåŒ–ï¼Œä¸å½±å“å“ªäº›ç‰‡æ®µå±äºå“ªä¸ªè¯´è¯äºº
        
        speaker_remap = {old_id: str(new_id) for new_id, old_id in enumerate(unique_speakers)}
        logger.debug(f"ğŸ” æ˜ å°„å…³ç³»: {speaker_remap}")
        
        for result in segment_results:
            old_id = result['speaker_id']
            result['speaker_id'] = speaker_remap[old_id]
        
        # éªŒè¯æ˜ å°„ç»“æœ
        final_ids = sorted(set(int(r['speaker_id']) for r in segment_results))
        if final_ids != list(range(n_speakers)):
            logger.error(f"âŒ æ˜ å°„åIDä»ä¸è¿ç»­: {final_ids}")
        else:
            # æ£€æŸ¥ç¬¬ä¸€ä¸ªç‰‡æ®µçš„ID
            first_speaker_id = segment_results[0]['speaker_id'] if segment_results else "N/A"
            logger.info(f"âœ… ç¼–å·è§„èŒƒåŒ–å®Œæˆ: 0-{n_speakers-1}ï¼Œç¬¬ä¸€ä¸ªç‰‡æ®µ speaker_id={first_speaker_id}")
        
        logger.info(f"âœ… è¯´è¯äººåˆ†ç¦»å®Œæˆï¼Œè¯†åˆ«å‡º {n_speakers} ä¸ªè¯´è¯äººï¼ˆåŸºäºçœŸå®å£°çº¹èšç±»ï¼‰")
        
        # ===== æ­¥éª¤4ï¼šæ„å»ºæœ€ç»ˆç»“æœ =====
        html_text = full_text  # ä¿æŒå…¼å®¹æ€§
        transcript = segment_results
        
        # æ¸…ç† transcript ä¸­çš„ä¸´æ—¶å­—æ®µ
        for item in transcript:
            if 'segment_idx' in item:
                del item['segment_idx']
            if '_audio_data' in item:
                del item['_audio_data']  # æ¸…ç†ç¼“å­˜çš„éŸ³é¢‘æ•°æ®
        
        logger.info(f"âœ… æœ€ç»ˆç»“æœ: {len(transcript)} ä¸ªç‰‡æ®µ, {len(set(t['speaker_id'] for t in transcript))} ä¸ªè¯´è¯äºº")
        
        # å…¼å®¹æ—§çš„è§£æé€»è¾‘ï¼ˆä»¥ä¸‹ä»£ç ä¸ä¼šæ‰§è¡Œï¼Œä½†ä¿ç•™ä»¥é˜²ä¸‡ä¸€ï¼‰
        if False:  # ç¦ç”¨æ—§é€»è¾‘
            result = {}
            sentence_info = None
            
            if sentence_info and len(sentence_info) > 0:
                logger.info(f"âœ… ä½¿ç”¨å¥å­çº§åˆ«è§£æï¼ˆå«è¯´è¯äººè¯†åˆ«ï¼‰")
                for sent in sentence_info:
                    text = sent.get("text", "").strip()
                    if not text:
                        continue
                    
                    # æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
                    timestamps = sent.get("timestamp", [])
                    if timestamps and len(timestamps) > 0:
                        start_ms = timestamps[0][0] if isinstance(timestamps[0], list) else 0
                        end_ms = timestamps[-1][1] if isinstance(timestamps[-1], list) else 0
                    else:
                        start_ms = 0
                        end_ms = 0
                    
                    # è¯´è¯äººIDï¼ˆSenseVoiceSmall ä½¿ç”¨ speaker_id å­—æ®µï¼‰
                    speaker_id = str(sent.get("speaker_id", sent.get("spk", "0")))
                    
                    # âœ… æå–ç½®ä¿¡åº¦ï¼ˆå¦‚æœæœ‰ï¼‰
                    confidence = sent.get("confidence", None)
                    
                    item = {
                        "text": text,
                        "start_time": round(start_ms / 1000.0, 2),
                        "end_time": round(end_ms / 1000.0, 2),
                        "speaker_id": speaker_id
                    }
                    
                    # å¦‚æœæœ‰ç½®ä¿¡åº¦ä¿¡æ¯ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
                    if confidence is not None:
                        item["confidence"] = round(confidence, 3)
                    
                    transcript.append(item)
            
            # ===== æ–¹æ¡ˆ2: è¯çº§åˆ«ï¼ˆéœ€è¦åˆå¹¶æˆå¥å­ï¼‰ =====
            else:
                logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°å¥å­çº§ä¿¡æ¯ï¼Œä½¿ç”¨è¯çº§åˆ«åˆå¹¶")
                raw_stamp = result.get("timestamp", [])
                
                if raw_stamp and len(raw_stamp) > 0:
                    # åˆå¹¶ç­–ç•¥ï¼šé‡åˆ°æ ‡ç‚¹æˆ–åœé¡¿è¶…è¿‡1ç§’åˆ™åˆ†å¥
                    current_sentence = []
                    current_start = None
                    current_end = None
                    sentence_count = 0
                    
                    for item in raw_stamp:
                        if not isinstance(item, list) or len(item) < 2:
                            continue
                        
                        t_range = item[0]
                        word = str(item[-1]).strip()
                        
                        if not isinstance(t_range, list) or len(t_range) < 2:
                            continue
                        
                        start_ms = t_range[0]
                        end_ms = t_range[1]
                        
                        # ç¬¬ä¸€ä¸ªè¯
                        if current_start is None:
                            current_start = start_ms
                        
                        current_sentence.append(word)
                        current_end = end_ms
                        
                        # åˆ†å¥æ¡ä»¶ï¼šé‡åˆ°æ ‡ç‚¹ç¬¦å·
                        if word in ["ã€‚", "ï¼Ÿ", "ï¼", ".", "?", "!"]:
                            sentence_text = "".join(current_sentence)
                            if sentence_text and sentence_text not in ["ã€‚", "ï¼Ÿ", "ï¼"]:
                                sentence_count += 1
                                transcript.append({
                                    "text": sentence_text,
                                    "start_time": round(current_start / 1000.0, 2),
                                    "end_time": round(current_end / 1000.0, 2),
                                    "speaker_id": str((sentence_count - 1) % 5 + 1)  # å‡è®¾æœ€å¤š5ä¸ªäººï¼Œå¾ªç¯åˆ†é…
                                })
                            # é‡ç½®
                            current_sentence = []
                            current_start = None
                    
                    # å¤„ç†æœ€åä¸€å¥ï¼ˆæ²¡æœ‰æ ‡ç‚¹ç»“å°¾çš„ï¼‰
                    if current_sentence:
                        sentence_text = "".join(current_sentence)
                        if sentence_text:
                            sentence_count += 1
                            transcript.append({
                                "text": sentence_text,
                                "start_time": round(current_start / 1000.0, 2),
                                "end_time": round(current_end / 1000.0, 2),
                                "speaker_id": str((sentence_count - 1) % 5 + 1)
                            })
                    
                    logger.info(f"ğŸ“ åˆå¹¶å®Œæˆ: {len(raw_stamp)}ä¸ªè¯ -> {len(transcript)}ä¸ªå¥å­")
                else:
                    # å®Œå…¨æ²¡æœ‰æ—¶é—´æˆ³ä¿¡æ¯
                    logger.warning("âš ï¸ æ— æ—¶é—´æˆ³ä¿¡æ¯ï¼Œè¿”å›çº¯æ–‡æœ¬")
                    transcript.append({
                        "text": full_text,
                        "start_time": 0.0,
                        "end_time": 0.0,
                        "speaker_id": "1"
                    })

        logger.info(f"âœ… è¯†åˆ«æˆåŠŸ: {file.filename} (é•¿åº¦: {len(full_text)}å­—)")
        
        # ===== çƒ­è¯åå¤„ç†æ›¿æ¢ï¼ˆSenseVoiceSmall ä¸“ç”¨ï¼‰=====
        # SenseVoiceSmall ä¸æ”¯æŒåŸç”Ÿçƒ­è¯ï¼Œéœ€è¦åœ¨ç»“æœä¸­è¿›è¡Œæ–‡æœ¬æ›¿æ¢
        try:
            if combined_hotwords:
                hotword_svc = get_hotword_service()
                # è¯»å– hotwords.json æ–‡ä»¶è·å– mappings
                import json
                hotwords_path = Path(__file__).parent / "hotwords.json"
                if hotwords_path.exists():
                    with open(hotwords_path, 'r', encoding='utf-8') as f:
                        hotwords_data = json.load(f)
                    mappings = hotwords_data.get("mappings", {})
                else:
                    mappings = {}
                
                if mappings:
                    # åˆå¹¶æ‰€æœ‰æ˜ å°„è¡¨
                    all_mappings = {}
                    for category, mapping_dict in mappings.items():
                        if isinstance(mapping_dict, dict):
                            all_mappings.update(mapping_dict)
                    
                    if all_mappings:
                        logger.info(f"ğŸ”„ åº”ç”¨çƒ­è¯æ˜ å°„: {len(all_mappings)} ä¸ª")
                        
                        # å¯¹ transcript ä¸­çš„æ¯ä¸ªæ–‡æœ¬è¿›è¡Œæ›¿æ¢
                        for item in transcript:
                            text = item.get("text", "")
                            for oral_form, standard_form in all_mappings.items():
                                text = text.replace(oral_form, standard_form)
                            item["text"] = text
                        
                        # åŒæ—¶æ›´æ–° full_text
                        for oral_form, standard_form in all_mappings.items():
                            full_text = full_text.replace(oral_form, standard_form)
                        
                        logger.info("âœ… çƒ­è¯æ›¿æ¢å®Œæˆ")
        except Exception as e:
            logger.warning(f"âš ï¸ çƒ­è¯æ›¿æ¢å¤±è´¥: {e}")
        
        # ===== å£°çº¹è¯†åˆ«ï¼ˆå¯é€‰ï¼Œå¦‚æœå£°çº¹åº“ä¸ºç©ºåˆ™è·³è¿‡ï¼‰=====
        matched_info = {}
        try:
            # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¯åŠ¨æ—¶çš„ä¾èµ–é”™è¯¯
            # æ³¨æ„ï¼šdatasets å…¼å®¹æ€§ä¿®å¤å·²åœ¨æ–‡ä»¶å¼€å¤´æ‰§è¡Œ
            from voice_matcher import get_voice_matcher
            
            voice_matcher = get_voice_matcher()
            if voice_matcher and voice_matcher.enabled and transcript and temp_file_path:
                logger.info("ğŸ™ï¸ å¼€å§‹å£°çº¹åŒ¹é…...")
                
                # 1. ä¸ºæ¯ä¸ªè¯´è¯äººæå–éŸ³é¢‘ç‰‡æ®µ
                speaker_segments = voice_matcher.extract_speaker_segments(
                    audio_path=str(temp_file_path),
                    transcript=transcript,
                    duration=10  # æå–10ç§’
                )
                
                if speaker_segments:
                    logger.info(f"âœ… æå–åˆ° {len(speaker_segments)} ä¸ªè¯´è¯äººçš„éŸ³é¢‘ç‰‡æ®µ")
                    
                    # 2. åŒ¹é…è¯´è¯äººèº«ä»½
                    matched = voice_matcher.match_speakers(
                        speaker_segments=speaker_segments,
                        threshold=0.75  # ç›¸ä¼¼åº¦é˜ˆå€¼75%
                    )
                    
                    if matched:
                        logger.info(f"âœ… åŒ¹é…æˆåŠŸ: {len(matched)} ä¸ªè¯´è¯äºº")
                        
                        # 3. æ›¿æ¢speaker_idä¸ºçœŸå®å§“å
                        transcript = voice_matcher.replace_speaker_ids(transcript, matched)
                        
                        # æ·»åŠ åŒ¹é…ä¿¡æ¯åˆ°è¿”å›æ•°æ®
                        matched_info = {
                            speaker_id: {
                                "name": name,
                                "employee_id": employee_id,
                                "similarity": similarity
                            }
                            for speaker_id, (employee_id, name, similarity) in matched.items()
                        }
                    else:
                        logger.warning("âš ï¸ æœªåŒ¹é…åˆ°ä»»ä½•è¯´è¯äºº")
                        matched_info = {}
                else:
                    logger.warning("âš ï¸ æœªèƒ½æå–è¯´è¯äººéŸ³é¢‘ç‰‡æ®µ")
                    matched_info = {}
            else:
                matched_info = {}
                if not voice_matcher:
                    logger.warning("âš ï¸ å£°çº¹åŒ¹é…å™¨æœªåˆå§‹åŒ–")
                elif not voice_matcher.enabled:
                    logger.info("â„¹ï¸ å£°çº¹åº“ä¸ºç©ºï¼Œè·³è¿‡å£°çº¹åŒ¹é…")
                    
        except ImportError as e:
            logger.warning(f"âš ï¸ å£°çº¹åŒ¹é…æ¨¡å—å¯¼å…¥å¤±è´¥ï¼ˆä¾èµ–ç¼ºå¤±ï¼‰ï¼Œè·³è¿‡å£°çº¹åŒ¹é…")
            logger.warning(f"   é”™è¯¯è¯¦æƒ…: {e}")
            logger.warning(f"   å¦‚éœ€ä½¿ç”¨å£°çº¹è¯†åˆ«ï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š")
            logger.warning(f"   pip install 'datasets>=2.14.0' 'chromadb==0.5.0'")
            logger.warning(f"   è¿™æ˜¯ datasets ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼Œè¯·å°è¯•ï¼š")
            logger.warning(f"   1. ä½¿ç”¨å…¼å®¹ç‰ˆæœ¬: pip install 'datasets==2.17.0' æˆ– 'datasets==2.18.0'")
            logger.warning(f"   2. æˆ–å‡çº§ modelscope: pip install -U modelscope")
            logger.warning(f"   3. å¦‚æœ flagembedding éœ€è¦ datasets>=2.19.0ï¼Œè€ƒè™‘åˆ›å»ºç‹¬ç«‹ç¯å¢ƒ")
            logger.warning(f"   æ³¨æ„ï¼šå·²å°è¯•è‡ªåŠ¨ä¿®è¡¥ï¼Œä½†å¯èƒ½ä¸å¤Ÿï¼Œå»ºè®®ä½¿ç”¨å…¼å®¹ç‰ˆæœ¬")
            matched_info = {}
        except Exception as e:
            logger.error(f"âŒ å£°çº¹åŒ¹é…å¤±è´¥: {e}", exc_info=True)
            matched_info = {}
        
        return {
            "code": 0,
            "msg": "success",
            "text": full_text,
            "html": html_text,
            "data": {
                "text": full_text,
                "html": html_text,
                "transcript": transcript,
                "voice_matched": matched_info if matched_info else None  # å£°çº¹åŒ¹é…ç»“æœ
            }
        }

    except Exception as e:
        logger.error(f"âŒ è¯†åˆ«å‡ºé”™: {file.filename} - {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail="Internal Server Error")
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œå˜é‡
        if temp_file_path and temp_file_path.exists():
            try:
                temp_file_path.unlink()
            except Exception:
                pass

        if 'input_data' in locals(): del input_data
        if 'res' in locals(): del res
        
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            
        logger.info("ğŸ§¹ å†…å­˜æ¸…ç†å®Œæˆï¼Œå‡†å¤‡è¿æ¥ä¸‹ä¸€ä¸ªä»»åŠ¡")


# =============================================
# çƒ­è¯ç®¡ç†API
# =============================================

@router.get("/hotwords")
async def get_hotwords():
    """è·å–å½“å‰çƒ­è¯åˆ—è¡¨"""
    try:
        hotword_svc = get_hotword_service()
        return {
            "code": 0,
            "msg": "success",
            "data": {
                "categories": hotword_svc.get_categories(),
                "hotwords": hotword_svc.hotwords_cache,
                "stats": hotword_svc.get_stats(),
                "total": len(hotword_svc.get_all_hotwords())
            }
        }
    except Exception as e:
        logger.error(f"âŒ è·å–çƒ­è¯å¤±è´¥: {e}")
        return {"code": 500, "msg": str(e)}


@router.post("/hotwords/reload")
async def reload_hotwords():
    """é‡æ–°åŠ è½½çƒ­è¯é…ç½®"""
    try:
        hotword_svc = get_hotword_service()
        success = hotword_svc.reload()
        
        if success:
            return {
                "code": 0,
                "msg": "çƒ­è¯é‡è½½æˆåŠŸ",
                "data": {
                    "total": len(hotword_svc.get_all_hotwords()),
                    "stats": hotword_svc.get_stats()
                }
            }
        else:
            return {"code": 500, "msg": "é‡è½½å¤±è´¥"}
    except Exception as e:
        logger.error(f"âŒ é‡è½½çƒ­è¯å¤±è´¥: {e}")
        return {"code": 500, "msg": str(e)}


app.include_router(router)

if __name__ == "__main__":
    logger.info("ğŸš€ å¯åŠ¨ HTTP æœåŠ¡: http://0.0.0.0:8002")
    uvicorn.run(app, host="0.0.0.0", port=8002)