"""
å£°çº¹åŒ¹é…æœåŠ¡
ç”¨äºå°†ASRè¯†åˆ«çš„speaker_idæ˜ å°„åˆ°çœŸå®å‘˜å·¥å§“å
"""
# ä¿®å¤ datasets å…¼å®¹æ€§é—®é¢˜ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ modelscope ä¹‹å‰ï¼‰
def _fix_datasets_compatibility():
    """ä¿®å¤ datasets ä¸ modelscope çš„å…¼å®¹æ€§é—®é¢˜"""
    try:
        import datasets
        
        # ä¿®å¤ LargeList å¯¼å…¥
        if not hasattr(datasets, 'LargeList'):
            try:
                from datasets import LargeList
            except ImportError:
                try:
                    import pyarrow as pa
                    if hasattr(pa, 'large_list'):
                        datasets.LargeList = pa.large_list
                    elif hasattr(pa, 'LargeList'):
                        datasets.LargeList = pa.LargeList
                except Exception:
                    pass
        
        # ä¿®å¤ _FEATURE_TYPES å¯¼å…¥ï¼ˆdatasets 2.19+ ä¸­å¯èƒ½å·²ç§»é™¤ï¼‰
        try:
            from datasets.features.features import _FEATURE_TYPES
        except ImportError:
            try:
                # å°è¯•ä»æ–°ä½ç½®å¯¼å…¥
                from datasets.features import _FEATURE_TYPES
            except ImportError:
                try:
                    # å¦‚æœä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªå…¼å®¹çš„å ä½ç¬¦
                    import datasets.features.features as features_module
                    if not hasattr(features_module, '_FEATURE_TYPES'):
                        # åˆ›å»ºä¸€ä¸ªç©ºçš„å­—å…¸ä½œä¸ºå ä½ç¬¦
                        features_module._FEATURE_TYPES = {}
                except Exception:
                    pass
    except Exception:
        pass  # å¦‚æœ datasets éƒ½å¯¼å…¥ä¸äº†ï¼Œè®©åç»­ä»£ç è‡ªå·±å¤„ç†é”™è¯¯

# ç«‹å³æ‰§è¡Œä¿®å¤
_fix_datasets_compatibility()

import logging
import chromadb
import torch
from funasr import AutoModel
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import subprocess
import tempfile
import os

logger = logging.getLogger(__name__)


class VoiceMatcher:
    """å£°çº¹åŒ¹é…å™¨"""
    
    def __init__(self, 
                 chroma_host: str = "192.168.211.74",
                 chroma_port: int = 8000,
                 collection_name: str = "employee_voice_voiceprint",
                 device: str = None):
        """
        åˆå§‹åŒ–å£°çº¹åŒ¹é…å™¨
        
        Args:
            chroma_host: ChromaDBåœ°å€
            chroma_port: ChromaDBç«¯å£
            collection_name: å£°çº¹åº“é›†åˆåç§°
            device: è®¾å¤‡ï¼ˆcuda/cpuï¼‰
        """
        self.enabled = False
        
        try:
            # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
            if device is None:
                self.device = "cuda" if torch.cuda.is_available() else "cpu"
            else:
                self.device = device
            
            logger.info(f"ğŸ™ï¸ æ­£åœ¨åˆå§‹åŒ–å£°çº¹åŒ¹é…å™¨... (è®¾å¤‡: {self.device})")
            
            # åŠ è½½Cam++å£°çº¹æ¨¡å‹ï¼ˆä½¿ç”¨ FunASR AutoModelï¼Œç›´æ¥è¾“å‡º spk_embedding å‘é‡ï¼‰
            logger.info("ğŸ“¦ åŠ è½½ Cam++ å£°çº¹æ¨¡å‹ (FunASR AutoModel)...")
            self.embedding_model = AutoModel(
                model="iic/speech_campplus_sv_zh-cn_16k-common",
                device=self.device,
                disable_update=True
            )
            logger.info("âœ… å£°çº¹æ¨¡å‹åŠ è½½æˆåŠŸï¼ˆæ”¯æŒè¾“å‡º spk_embeddingï¼‰")
            
            # è¿æ¥ChromaDB
            logger.info(f"ğŸ”Œ è¿æ¥ ChromaDB: {chroma_host}:{chroma_port}")
            self.client = chromadb.HttpClient(
                host=chroma_host,
                port=chroma_port
            )
            
            # è·å–/åˆ›å»ºä¸“ç”¨çš„å£°çº¹åº“é›†åˆï¼ˆCam++ï¼Œ192ç»´ï¼‰ï¼Œä¸æ–‡æœ¬å‘é‡åº“å®Œå…¨éš”ç¦»
            CAMPP_DIM = 192
            logger.info(f"ğŸ”Œ è¿æ¥å£°çº¹åº“é›†åˆ: {collection_name} (æœŸæœ›ç»´åº¦: {CAMPP_DIM})")
            self.collection = self.client.get_or_create_collection(
                name=collection_name,
                metadata={
                    "hnsw:space": "cosine",
                    "embedding_dimension": CAMPP_DIM,
                    "model": "cam++"
                }
            )
            
            # æ£€æŸ¥å£°çº¹åº“æ˜¯å¦ä¸ºç©º
            count = self.collection.count()
            if count == 0:
                logger.warning("âš ï¸ å£°çº¹åº“ä¸ºç©ºï¼Œå£°çº¹è¯†åˆ«å°†è¢«ç¦ç”¨ï¼ˆè¯·å…ˆå½•å…¥å‘˜å·¥å£°çº¹ï¼‰")
                self.enabled = False
            else:
                logger.info(f"âœ… å£°çº¹åº“å·²å°±ç»ªï¼Œå…± {count} ä¸ªå‘˜å·¥å£°çº¹ï¼ˆ192ç»´ Cam++ï¼‰")
                self.enabled = True
            
        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ å£°çº¹åŒ¹é…å™¨åˆå§‹åŒ–å¤±è´¥: {error_msg}")
            
            # æ ¹æ®é”™è¯¯ç±»å‹ç»™å‡ºå…·ä½“çš„ä¿®å¤å»ºè®®
            if "simplejson" in error_msg or "No module named 'simplejson'" in error_msg:
                logger.error("   ğŸ’¡ ç¼ºå°‘ä¾èµ–: simplejson")
                logger.error("   ğŸ“¦ è§£å†³æ–¹æ¡ˆ: pip install simplejson")
            elif "sortedcontainers" in error_msg or "No module named 'sortedcontainers'" in error_msg:
                logger.error("   ğŸ’¡ ç¼ºå°‘ä¾èµ–: sortedcontainers")
                logger.error("   ğŸ“¦ è§£å†³æ–¹æ¡ˆ: pip install sortedcontainers")
            elif "chromadb" in error_msg.lower() or "è¿æ¥" in error_msg or "refused" in error_msg.lower():
                logger.error("   ğŸ’¡ ChromaDB è¿æ¥å¤±è´¥")
                logger.error("   ğŸ“¦ è§£å†³æ–¹æ¡ˆ: æ£€æŸ¥ ChromaDB æœåŠ¡æ˜¯å¦å¯åŠ¨")
                logger.error("      å¯åŠ¨å‘½ä»¤: docker run -d --name chromadb -p 8000:8000 chromadb/chroma:latest")
            elif "datasets" in error_msg.lower() or "LargeList" in error_msg or "_FEATURE_TYPES" in error_msg:
                logger.error("   ğŸ’¡ datasets ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜")
                logger.error("   ğŸ“¦ è§£å†³æ–¹æ¡ˆ: pip install 'datasets==2.17.0'")
            else:
                logger.error("   ğŸ’¡ è¯·æŸ¥çœ‹ä¸Šæ–¹é”™è¯¯ä¿¡æ¯ï¼Œæ ¹æ®é”™è¯¯ç±»å‹ä¿®å¤")
            
            logger.warning("âš ï¸ å£°çº¹è¯†åˆ«åŠŸèƒ½å°†è¢«ç¦ç”¨ï¼Œå°†ä½¿ç”¨é»˜è®¤speaker_id")
            self.enabled = False
    
    def extract_speaker_segments(self,
                                  audio_path: str,
                                  transcript: List[Dict],
                                  duration: int = 10) -> Dict[str, str]:
        """
        ä¸ºæ¯ä¸ªè¯´è¯äººæå–éŸ³é¢‘ç‰‡æ®µ
        
        Args:
            audio_path: åŸå§‹éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            transcript: ASRè¯†åˆ«ç»“æœï¼ŒåŒ…å«speaker_idå’Œæ—¶é—´æˆ³
            duration: æå–éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        
        Returns:
            {speaker_id: audio_segment_path}
        """
        if not self.enabled:
            return {}
        
        speaker_segments = {}
        speaker_times = {}  # {speaker_id: [(start, end), ...]}
        
        # 1. æ”¶é›†æ¯ä¸ªè¯´è¯äººçš„æ‰€æœ‰æ—¶é—´æ®µ
        for item in transcript:
            speaker_id = item.get("speaker_id", "unknown")
            start_time = item.get("start_time", 0)
            end_time = item.get("end_time", 0)
            
            if speaker_id not in speaker_times:
                speaker_times[speaker_id] = []
            
            speaker_times[speaker_id].append((start_time, end_time))
        
        # 2. ä¸ºæ¯ä¸ªè¯´è¯äººæå–éŸ³é¢‘ç‰‡æ®µ
        for speaker_id, times in speaker_times.items():
            if speaker_id == "unknown":
                continue
            
            try:
                # æ‰¾å‡ºè¯¥è¯´è¯äººæœ€é•¿çš„è¿ç»­ç‰‡æ®µ
                sorted_times = sorted(times, key=lambda x: x[1] - x[0], reverse=True)
                
                # å–å‰å‡ æ®µï¼Œç´¯è®¡è¾¾åˆ°æŒ‡å®šæ—¶é•¿
                accumulated_duration = 0
                selected_segments = []
                
                for start, end in sorted_times:
                    segment_duration = end - start
                    if segment_duration >= 2:  # è‡³å°‘2ç§’çš„ç‰‡æ®µæ‰è€ƒè™‘
                        selected_segments.append((start, end))
                        accumulated_duration += segment_duration
                        
                        if accumulated_duration >= duration:
                            break
                
                if not selected_segments:
                    logger.warning(f"âš ï¸ è¯´è¯äºº {speaker_id} æ²¡æœ‰è¶³å¤Ÿé•¿çš„éŸ³é¢‘ç‰‡æ®µ")
                    continue
                
                # æå–ç¬¬ä¸€æ®µï¼ˆæœ€é•¿çš„ï¼‰
                start, end = selected_segments[0]
                segment_path = self._extract_audio_segment(
                    audio_path, 
                    start, 
                    min(end, start + duration),
                    speaker_id
                )
                
                if segment_path:
                    speaker_segments[speaker_id] = segment_path
                    logger.info(f"âœ… æå–è¯´è¯äºº {speaker_id} éŸ³é¢‘: {start:.1f}s - {end:.1f}s")
                
            except Exception as e:
                logger.error(f"âŒ æå–è¯´è¯äºº {speaker_id} éŸ³é¢‘å¤±è´¥: {e}")
        
        return speaker_segments
    
    def _extract_audio_segment(self,
                                audio_path: str,
                                start_time: float,
                                end_time: float,
                                speaker_id: str) -> Optional[str]:
        """
        ä½¿ç”¨ffmpegæå–éŸ³é¢‘ç‰‡æ®µ
        
        Args:
            audio_path: åŸå§‹éŸ³é¢‘è·¯å¾„
            start_time: å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
            end_time: ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
            speaker_id: è¯´è¯äººID
        
        Returns:
            æå–çš„éŸ³é¢‘ç‰‡æ®µè·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            temp_dir = Path(tempfile.gettempdir())
            output_path = temp_dir / f"speaker_{speaker_id}_{int(start_time)}.wav"
            
            # ä½¿ç”¨ffmpegæå–ç‰‡æ®µ
            cmd = [
                "ffmpeg",
                "-i", audio_path,
                "-ss", str(start_time),
                "-t", str(end_time - start_time),
                "-ac", "1",              # å•å£°é“
                "-ar", "16000",          # 16kHzé‡‡æ ·ç‡
                "-y",
                "-loglevel", "error",
                str(output_path)
            ]
            
            subprocess.run(cmd, check=True, capture_output=True, timeout=30)
            
            # ç¡®ä¿æ–‡ä»¶å­˜åœ¨å¹¶è¿”å›ç»å¯¹è·¯å¾„
            if output_path.exists():
                return str(output_path.resolve())
            else:
                logger.error(f"âŒ æå–çš„éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {output_path}")
                return None
            
        except FileNotFoundError:
            logger.error("âŒ ffmpeg æœªå®‰è£…ï¼Œæ— æ³•æå–éŸ³é¢‘ç‰‡æ®µ")
            return None
        except subprocess.CalledProcessError as e:
            logger.error(f"âŒ ffmpeg æå–å¤±è´¥: {e.stderr.decode() if e.stderr else str(e)}")
            return None
        except Exception as e:
            logger.error(f"âŒ æå–éŸ³é¢‘ç‰‡æ®µå¼‚å¸¸: {e}")
            return None
    
    def match_speakers(self, 
                      speaker_segments: Dict[str, str],
                      threshold: float = 0.75) -> Dict[str, Tuple[str, str, float]]:
        """
        åŒ¹é…è¯´è¯äººèº«ä»½
        
        Args:
            speaker_segments: {speaker_id: audio_path}
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰
        
        Returns:
            {speaker_id: (employee_id, name, similarity)}
        """
        if not self.enabled:
            return {}
        
        matched = {}
        
        for speaker_id, audio_path in speaker_segments.items():
            try:
                # 1. æå–å£°çº¹å‘é‡
                vector = self._extract_vector(audio_path)
                
                if vector is None:
                    logger.warning(f"âš ï¸ è¯´è¯äºº {speaker_id} å£°çº¹æå–å¤±è´¥")
                    continue
                
                # 2. åœ¨å£°çº¹åº“ä¸­æœç´¢
                results = self.collection.query(
                    query_embeddings=[vector],
                    n_results=1
                )
                
                if not results['ids'] or len(results['ids'][0]) == 0:
                    logger.warning(f"âš ï¸ è¯´è¯äºº {speaker_id} æœªåœ¨å£°çº¹åº“ä¸­æ‰¾åˆ°åŒ¹é…")
                    continue
                
                # 3. è·å–åŒ¹é…ç»“æœ
                employee_id = results['ids'][0][0]
                metadata = results['metadatas'][0][0]
                distance = results['distances'][0][0] if 'distances' in results else 0.5
                
                # è·ç¦»è½¬ç›¸ä¼¼åº¦ï¼ˆcosineè·ç¦»: 0=å®Œå…¨ç›¸åŒ, 2=å®Œå…¨ç›¸åï¼‰
                similarity = 1 - (distance / 2.0)
                
                name = metadata.get('name', 'æœªçŸ¥')
                
                if similarity >= threshold:
                    matched[speaker_id] = (employee_id, name, similarity)
                    logger.info(f"âœ… è¯´è¯äºº {speaker_id} åŒ¹é…æˆåŠŸ: {name} (ç›¸ä¼¼åº¦: {similarity:.2%})")
                else:
                    logger.warning(f"âš ï¸ è¯´è¯äºº {speaker_id} ç›¸ä¼¼åº¦è¿‡ä½: {similarity:.2%} < {threshold:.2%}")
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.remove(audio_path)
                except:
                    pass
                
            except Exception as e:
                logger.error(f"âŒ åŒ¹é…è¯´è¯äºº {speaker_id} å¤±è´¥: {e}")
        
        return matched
    
    def _extract_vector(self, audio_path: str) -> Optional[List[float]]:
        """
        æå–å£°çº¹å‘é‡
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        
        Returns:
            å£°çº¹å‘é‡ï¼ˆ192ç»´ï¼‰ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # ç¡®ä¿è·¯å¾„æ˜¯ç»å¯¹è·¯å¾„å­—ç¬¦ä¸²ï¼ˆWindowsè·¯å¾„å¤„ç†ï¼‰
            original_path = audio_path
            logger.debug(f"ğŸ” _extract_vector è¾“å…¥: {original_path}, ç±»å‹: {type(original_path)}")
            
            if isinstance(audio_path, Path):
                audio_path = str(audio_path.resolve())
            else:
                audio_path = str(Path(audio_path).resolve())
            
            logger.debug(f"ğŸ” å¤„ç†åè·¯å¾„: {audio_path}")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(audio_path):
                logger.error(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
                logger.error(f"   åŸå§‹è·¯å¾„: {original_path}")
                logger.error(f"   è·¯å¾„ç±»å‹: {type(original_path)}")
                return None
            
            logger.info(f"ğŸ” æå–å£°çº¹å‘é‡: {audio_path}")
            logger.debug(f"   è·¯å¾„ç±»å‹: {type(audio_path)}, è·¯å¾„å€¼: {repr(audio_path)}")
            
            try:
                # ä½¿ç”¨ FunASR AutoModel æå–å£°çº¹å‘é‡
                # ä¸è¯´è¯äººåˆ†ç¦»æ¨¡å—ä¿æŒä¸€è‡´ï¼šgenerate(input=audio_path)ï¼Œè¿”å›åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ å« spk_embedding
                emb_res = self.embedding_model.generate(input=audio_path)
                logger.debug(f"   æ¨¡å‹è¿”å›ç±»å‹: {type(emb_res)}, å†…å®¹æ¦‚è¦: {emb_res}")
                
                if not emb_res or len(emb_res) == 0:
                    logger.error("âŒ å£°çº¹æ¨¡å‹æœªè¿”å›ç»“æœ")
                    return None
                
                emb = emb_res[0].get("spk_embedding", None)
                if emb is None:
                    logger.error(f"âŒ æ¨¡å‹æœªè¿”å› spk_embeddingï¼Œè¿”å›é”®: {list(emb_res[0].keys())}")
                    return None
                
                # è½¬ä¸º numpy / listï¼Œå¹¶ç¡®ä¿æ˜¯ä¸€ç»´å‘é‡
                import numpy as np
                emb_array = np.array(emb)
                if emb_array.ndim > 1:
                    emb_array = emb_array.flatten()
                
                vector = emb_array.tolist()
                logger.debug(f"   âœ… æˆåŠŸæå–å£°çº¹å‘é‡ï¼Œç»´åº¦: {len(vector)}")
                return vector
            
            except Exception as e:
                error_msg = str(e)
                logger.error(f"âŒ å£°çº¹å‘é‡æå–å¤±è´¥: {error_msg}")
                import traceback
                logger.debug(f"   è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
                return None
                
        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ æå–å£°çº¹å‘é‡å¼‚å¸¸: {error_msg}")
            logger.error(f"   éŸ³é¢‘è·¯å¾„: {audio_path if 'audio_path' in locals() else 'æœªçŸ¥'}")
            logger.error(f"   è·¯å¾„ç±»å‹: {type(audio_path) if 'audio_path' in locals() else 'æœªçŸ¥'}")
            import traceback
            logger.debug(f"   è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return None
    
    def replace_speaker_ids(self,
                           transcript: List[Dict],
                           matched: Dict[str, Tuple[str, str, float]]) -> List[Dict]:
        """
        å°†speaker_idæ›¿æ¢ä¸ºçœŸå®å§“å
        
        Args:
            transcript: ASRè¯†åˆ«ç»“æœ
            matched: åŒ¹é…ç»“æœ {speaker_id: (employee_id, name, similarity)}
        
        Returns:
            æ›¿æ¢åçš„transcript
        """
        if not matched:
            return transcript
        
        for item in transcript:
            speaker_id = item.get("speaker_id", "unknown")
            
            if speaker_id in matched:
                employee_id, name, similarity = matched[speaker_id]
                item["speaker_name"] = name
                item["employee_id"] = employee_id
                item["voice_similarity"] = round(similarity, 3)
                logger.debug(f"æ›¿æ¢: speaker_{speaker_id} â†’ {name}")
        
        return transcript


# å…¨å±€å•ä¾‹
_voice_matcher = None


def get_voice_matcher() -> Optional[VoiceMatcher]:
    """è·å–å£°çº¹åŒ¹é…å™¨å•ä¾‹"""
    global _voice_matcher
    if _voice_matcher is None:
        try:
            _voice_matcher = VoiceMatcher()
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–å£°çº¹åŒ¹é…å™¨å¤±è´¥: {e}")
            return None
    return _voice_matcher
