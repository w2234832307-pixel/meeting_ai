"""
å£°çº¹åŒ¹é…æœåŠ¡
ç”¨äºå°†ASRè¯†åˆ«çš„speaker_idæ˜ å°„åˆ°çœŸå®å‘˜å·¥å§“å
"""
import logging
import chromadb
import torch
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import subprocess
import tempfile
import os

logger = logging.getLogger(__name__)


class VoiceMatcher:
    """å£°çº¹åŒ¹é…å™¨"""
    
    def __init__(self, 
                 chroma_host: str = "192.168.211.74",
                 chroma_port: int = 8000,
                 collection_name: str = "employee_voice_library",
                 device: str = None):
        """
        åˆå§‹åŒ–å£°çº¹åŒ¹é…å™¨
        
        Args:
            chroma_host: ChromaDBåœ°å€
            chroma_port: ChromaDBç«¯å£
            collection_name: å£°çº¹åº“é›†åˆåç§°
            device: è®¾å¤‡ï¼ˆcuda/cpuï¼‰
        """
        self.enabled = False
        
        try:
            # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
            if device is None:
                self.device = "cuda" if torch.cuda.is_available() else "cpu"
            else:
                self.device = device
            
            logger.info(f"ğŸ™ï¸ æ­£åœ¨åˆå§‹åŒ–å£°çº¹åŒ¹é…å™¨... (è®¾å¤‡: {self.device})")
            
            # åŠ è½½Cam++å£°çº¹æ¨¡å‹
            logger.info("ğŸ“¦ åŠ è½½ Cam++ å£°çº¹æ¨¡å‹...")
            self.embedding_model = pipeline(
                task=Tasks.speaker_verification,
                model='iic/speech_campplus_sv_zh-cn_16k-common',
                model_revision='v1.0.0',
                device=self.device
            )
            logger.info("âœ… å£°çº¹æ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # è¿æ¥ChromaDB
            logger.info(f"ğŸ”Œ è¿æ¥ ChromaDB: {chroma_host}:{chroma_port}")
            self.client = chromadb.HttpClient(
                host=chroma_host,
                port=chroma_port
            )
            
            # è·å–å£°çº¹åº“é›†åˆ
            self.collection = self.client.get_or_create_collection(
                name=collection_name,
                metadata={"hnsw:space": "cosine"}
            )
            logger.info(f"âœ… è¿æ¥å£°çº¹åº“æˆåŠŸ: {collection_name}")
            
            # æ£€æŸ¥å£°çº¹åº“æ˜¯å¦ä¸ºç©º
            count = self.collection.count()
            if count == 0:
                logger.warning("âš ï¸ å£°çº¹åº“ä¸ºç©ºï¼Œå£°çº¹è¯†åˆ«å°†è¢«ç¦ç”¨")
                self.enabled = False
            else:
                logger.info(f"âœ… å£°çº¹åº“å·²å°±ç»ªï¼Œå…± {count} ä¸ªå‘˜å·¥å£°çº¹")
                self.enabled = True
            
        except Exception as e:
            logger.error(f"âŒ å£°çº¹åŒ¹é…å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            logger.warning("âš ï¸ å£°çº¹è¯†åˆ«åŠŸèƒ½å°†è¢«ç¦ç”¨ï¼Œå°†ä½¿ç”¨é»˜è®¤speaker_id")
            self.enabled = False
    
    def extract_speaker_segments(self,
                                  audio_path: str,
                                  transcript: List[Dict],
                                  duration: int = 10) -> Dict[str, str]:
        """
        ä¸ºæ¯ä¸ªè¯´è¯äººæå–éŸ³é¢‘ç‰‡æ®µ
        
        Args:
            audio_path: åŸå§‹éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            transcript: ASRè¯†åˆ«ç»“æœï¼ŒåŒ…å«speaker_idå’Œæ—¶é—´æˆ³
            duration: æå–éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        
        Returns:
            {speaker_id: audio_segment_path}
        """
        if not self.enabled:
            return {}
        
        speaker_segments = {}
        speaker_times = {}  # {speaker_id: [(start, end), ...]}
        
        # 1. æ”¶é›†æ¯ä¸ªè¯´è¯äººçš„æ‰€æœ‰æ—¶é—´æ®µ
        for item in transcript:
            speaker_id = item.get("speaker_id", "unknown")
            start_time = item.get("start_time", 0)
            end_time = item.get("end_time", 0)
            
            if speaker_id not in speaker_times:
                speaker_times[speaker_id] = []
            
            speaker_times[speaker_id].append((start_time, end_time))
        
        # 2. ä¸ºæ¯ä¸ªè¯´è¯äººæå–éŸ³é¢‘ç‰‡æ®µ
        for speaker_id, times in speaker_times.items():
            if speaker_id == "unknown":
                continue
            
            try:
                # æ‰¾å‡ºè¯¥è¯´è¯äººæœ€é•¿çš„è¿ç»­ç‰‡æ®µ
                sorted_times = sorted(times, key=lambda x: x[1] - x[0], reverse=True)
                
                # å–å‰å‡ æ®µï¼Œç´¯è®¡è¾¾åˆ°æŒ‡å®šæ—¶é•¿
                accumulated_duration = 0
                selected_segments = []
                
                for start, end in sorted_times:
                    segment_duration = end - start
                    if segment_duration >= 2:  # è‡³å°‘2ç§’çš„ç‰‡æ®µæ‰è€ƒè™‘
                        selected_segments.append((start, end))
                        accumulated_duration += segment_duration
                        
                        if accumulated_duration >= duration:
                            break
                
                if not selected_segments:
                    logger.warning(f"âš ï¸ è¯´è¯äºº {speaker_id} æ²¡æœ‰è¶³å¤Ÿé•¿çš„éŸ³é¢‘ç‰‡æ®µ")
                    continue
                
                # æå–ç¬¬ä¸€æ®µï¼ˆæœ€é•¿çš„ï¼‰
                start, end = selected_segments[0]
                segment_path = self._extract_audio_segment(
                    audio_path, 
                    start, 
                    min(end, start + duration),
                    speaker_id
                )
                
                if segment_path:
                    speaker_segments[speaker_id] = segment_path
                    logger.info(f"âœ… æå–è¯´è¯äºº {speaker_id} éŸ³é¢‘: {start:.1f}s - {end:.1f}s")
                
            except Exception as e:
                logger.error(f"âŒ æå–è¯´è¯äºº {speaker_id} éŸ³é¢‘å¤±è´¥: {e}")
        
        return speaker_segments
    
    def _extract_audio_segment(self,
                                audio_path: str,
                                start_time: float,
                                end_time: float,
                                speaker_id: str) -> Optional[str]:
        """
        ä½¿ç”¨ffmpegæå–éŸ³é¢‘ç‰‡æ®µ
        
        Args:
            audio_path: åŸå§‹éŸ³é¢‘è·¯å¾„
            start_time: å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
            end_time: ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
            speaker_id: è¯´è¯äººID
        
        Returns:
            æå–çš„éŸ³é¢‘ç‰‡æ®µè·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            temp_dir = Path(tempfile.gettempdir())
            output_path = temp_dir / f"speaker_{speaker_id}_{int(start_time)}.wav"
            
            # ä½¿ç”¨ffmpegæå–ç‰‡æ®µ
            cmd = [
                "ffmpeg",
                "-i", audio_path,
                "-ss", str(start_time),
                "-t", str(end_time - start_time),
                "-ac", "1",              # å•å£°é“
                "-ar", "16000",          # 16kHzé‡‡æ ·ç‡
                "-y",
                "-loglevel", "error",
                str(output_path)
            ]
            
            subprocess.run(cmd, check=True, capture_output=True, timeout=30)
            return str(output_path)
            
        except FileNotFoundError:
            logger.error("âŒ ffmpeg æœªå®‰è£…ï¼Œæ— æ³•æå–éŸ³é¢‘ç‰‡æ®µ")
            return None
        except subprocess.CalledProcessError as e:
            logger.error(f"âŒ ffmpeg æå–å¤±è´¥: {e.stderr.decode() if e.stderr else str(e)}")
            return None
        except Exception as e:
            logger.error(f"âŒ æå–éŸ³é¢‘ç‰‡æ®µå¼‚å¸¸: {e}")
            return None
    
    def match_speakers(self, 
                      speaker_segments: Dict[str, str],
                      threshold: float = 0.75) -> Dict[str, Tuple[str, str, float]]:
        """
        åŒ¹é…è¯´è¯äººèº«ä»½
        
        Args:
            speaker_segments: {speaker_id: audio_path}
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰
        
        Returns:
            {speaker_id: (employee_id, name, similarity)}
        """
        if not self.enabled:
            return {}
        
        matched = {}
        
        for speaker_id, audio_path in speaker_segments.items():
            try:
                # 1. æå–å£°çº¹å‘é‡
                vector = self._extract_vector(audio_path)
                
                if vector is None:
                    logger.warning(f"âš ï¸ è¯´è¯äºº {speaker_id} å£°çº¹æå–å¤±è´¥")
                    continue
                
                # 2. åœ¨å£°çº¹åº“ä¸­æœç´¢
                results = self.collection.query(
                    query_embeddings=[vector],
                    n_results=1
                )
                
                if not results['ids'] or len(results['ids'][0]) == 0:
                    logger.warning(f"âš ï¸ è¯´è¯äºº {speaker_id} æœªåœ¨å£°çº¹åº“ä¸­æ‰¾åˆ°åŒ¹é…")
                    continue
                
                # 3. è·å–åŒ¹é…ç»“æœ
                employee_id = results['ids'][0][0]
                metadata = results['metadatas'][0][0]
                distance = results['distances'][0][0] if 'distances' in results else 0.5
                
                # è·ç¦»è½¬ç›¸ä¼¼åº¦ï¼ˆcosineè·ç¦»: 0=å®Œå…¨ç›¸åŒ, 2=å®Œå…¨ç›¸åï¼‰
                similarity = 1 - (distance / 2.0)
                
                name = metadata.get('name', 'æœªçŸ¥')
                
                if similarity >= threshold:
                    matched[speaker_id] = (employee_id, name, similarity)
                    logger.info(f"âœ… è¯´è¯äºº {speaker_id} åŒ¹é…æˆåŠŸ: {name} (ç›¸ä¼¼åº¦: {similarity:.2%})")
                else:
                    logger.warning(f"âš ï¸ è¯´è¯äºº {speaker_id} ç›¸ä¼¼åº¦è¿‡ä½: {similarity:.2%} < {threshold:.2%}")
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.remove(audio_path)
                except:
                    pass
                
            except Exception as e:
                logger.error(f"âŒ åŒ¹é…è¯´è¯äºº {speaker_id} å¤±è´¥: {e}")
        
        return matched
    
    def _extract_vector(self, audio_path: str) -> Optional[List[float]]:
        """
        æå–å£°çº¹å‘é‡
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        
        Returns:
            å£°çº¹å‘é‡ï¼ˆ192ç»´ï¼‰ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            res = self.embedding_model(audio_path)
            
            if res and 'spk_embedding' in res:
                vector = res['spk_embedding']
                
                # è½¬æ¢ä¸ºPython list
                if hasattr(vector, 'tolist'):
                    vector = vector.tolist()
                
                return vector
            else:
                logger.error(f"âŒ æ¨¡å‹æœªè¿”å› spk_embedding: {res}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ æå–å£°çº¹å‘é‡å¼‚å¸¸: {e}")
            return None
    
    def replace_speaker_ids(self,
                           transcript: List[Dict],
                           matched: Dict[str, Tuple[str, str, float]]) -> List[Dict]:
        """
        å°†speaker_idæ›¿æ¢ä¸ºçœŸå®å§“å
        
        Args:
            transcript: ASRè¯†åˆ«ç»“æœ
            matched: åŒ¹é…ç»“æœ {speaker_id: (employee_id, name, similarity)}
        
        Returns:
            æ›¿æ¢åçš„transcript
        """
        if not matched:
            return transcript
        
        for item in transcript:
            speaker_id = item.get("speaker_id", "unknown")
            
            if speaker_id in matched:
                employee_id, name, similarity = matched[speaker_id]
                item["speaker_name"] = name
                item["employee_id"] = employee_id
                item["voice_similarity"] = round(similarity, 3)
                logger.debug(f"æ›¿æ¢: speaker_{speaker_id} â†’ {name}")
        
        return transcript


# å…¨å±€å•ä¾‹
_voice_matcher = None


def get_voice_matcher() -> Optional[VoiceMatcher]:
    """è·å–å£°çº¹åŒ¹é…å™¨å•ä¾‹"""
    global _voice_matcher
    if _voice_matcher is None:
        try:
            _voice_matcher = VoiceMatcher()
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–å£°çº¹åŒ¹é…å™¨å¤±è´¥: {e}")
            return None
    return _voice_matcher
