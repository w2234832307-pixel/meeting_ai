#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç‹¬ç«‹çš„ Pyannote è¯´è¯äººåˆ†ç¦»æœåŠ¡
"""
import os
import logging
from typing import List, Optional
from pathlib import Path

from fastapi import FastAPI, UploadFile, File, Form
from pydantic import BaseModel
from dotenv import load_dotenv

# é¿å…ä¾èµ– pyannote å†…éƒ¨çš„ AudioDecoderï¼Œæ‰‹åŠ¨è§£ç éŸ³é¢‘ä¸º waveform ä¼ ç»™ pipelineï¼Œç»•è¿‡ AudioDecoder æŠ¥é”™
import torch
import soundfile as sf
import subprocess
import tempfile

# å¼ºåˆ¶ç¦»çº¿ï¼šå¿…é¡»åœ¨å¯¼å…¥ pyannote/huggingface ç›¸å…³æ¨¡å—å‰è®¾ç½®ï¼Œé¿å…ä»»ä½•è”ç½‘ HEAD/ä¸‹è½½
os.environ["HF_HUB_OFFLINE"] = os.getenv("HF_HUB_OFFLINE", "1") or "1"
os.environ["TRANSFORMERS_OFFLINE"] = os.getenv("TRANSFORMERS_OFFLINE", "1") or "1"

# ç¡®ä¿ pyannote_diarization.py åœ¨åŒä¸€ç›®å½•ä¸‹
from pyannote_diarization import perform_pyannote_diarization, get_pyannote_pipeline, process_audio_with_pipeline

# é…ç½®æ—¥å¿—æ ¼å¼
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("PyannoteServer")

# åŠ è½½ .env æ–‡ä»¶
env_path = Path(__file__).parent / ".env"
if env_path.exists():
    load_dotenv(dotenv_path=env_path)

# ================= æ•°æ®æ¨¡å‹ =================

class TranscriptItem(BaseModel):
    text: str
    start_time: float
    end_time: float
    speaker_id: str | None = None

class DiarizeRequest(BaseModel):
    audio_path: str
    transcript: List[TranscriptItem]

class DiarizeResponse(BaseModel):
    transcript: List[TranscriptItem]

class RTTMRequest(BaseModel):
    audio_path: str

class RTTMResponse(BaseModel):
    rttm: str
    error: Optional[str] = None

# ================= APP å®šä¹‰ =================

app = FastAPI(title="Pyannote Diarization Service", version="1.0.0")


@app.on_event("startup")
async def startup_event():
    """FastAPI å¯åŠ¨æ—¶é¢„åŠ è½½ pipelineï¼ˆå…¨å±€å•ä¾‹ï¼‰"""
    logger.info("ğŸš€ å¯åŠ¨æ—¶é¢„åŠ è½½ Pyannote pipeline...")
    hf_token = os.getenv("HF_TOKEN") or None
    pipeline = get_pyannote_pipeline(use_auth_token=hf_token)
    if pipeline:
        logger.info("âœ… Pyannote pipeline é¢„åŠ è½½æˆåŠŸï¼ˆå…¨å±€å•ä¾‹ï¼Œåç»­è¯·æ±‚ç›´æ¥ä½¿ç”¨ï¼‰")
    else:
        logger.warning("âš ï¸ Pyannote pipeline é¢„åŠ è½½å¤±è´¥ï¼Œå°†åœ¨é¦–æ¬¡è¯·æ±‚æ—¶åŠ è½½")


def _extract_annotation(diarization):
    """
    å…¼å®¹ä¸åŒç‰ˆæœ¬ Pyannoteï¼š
    - æ—§ç‰ˆ: pipeline(...) ç›´æ¥è¿”å›æ”¯æŒ itertracks çš„ Annotation
    - 3.x: å¯èƒ½è¿”å› DiarizeOutputï¼ŒçœŸæ­£çš„ Annotation åœ¨æŸä¸ªå±æ€§é‡Œ
    """
    # æ—§ç‰ˆï¼šç›´æ¥å°±æ˜¯ Annotation
    if hasattr(diarization, "itertracks"):
        return diarization

    # å°è¯•é€šè¿‡ __dict__ æˆ– vars() è®¿é—®ï¼ˆé€‚ç”¨äº dataclass/NamedTupleï¼‰
    try:
        obj_dict = vars(diarization) if hasattr(diarization, "__dict__") else {}
        for key, value in obj_dict.items():
            if value is not None and hasattr(value, "itertracks"):
                return value
    except:
        pass

    # å°è¯•é€šè¿‡ç´¢å¼•è®¿é—®ï¼ˆå¦‚æœæ˜¯ NamedTupleï¼‰
    try:
        if hasattr(diarization, "__len__"):
            for i in range(len(diarization)):
                ann = diarization[i]
                if ann is not None and hasattr(ann, "itertracks"):
                    return ann
    except:
        pass

    # æ–°ç‰ˆï¼šDiarizeOutput dataclass - å°è¯•å¤šç§å¯èƒ½çš„å±æ€§å
    possible_attrs = ["annotation", "speaker", "output", "result", "diarization", "labels"]
    ann = None
    
    for attr in possible_attrs:
        try:
            ann = getattr(diarization, attr, None)
            if ann is not None and hasattr(ann, "itertracks"):
                return ann
        except:
            continue
    
    # å¦‚æœæ˜¯ dataclassï¼Œå°è¯•è®¿é—®æ‰€æœ‰å­—æ®µ
    if hasattr(diarization, "__dataclass_fields__"):
        for field_name in diarization.__dataclass_fields__.keys():
            try:
                ann = getattr(diarization, field_name, None)
                if ann is not None and hasattr(ann, "itertracks"):
                    return ann
            except:
                continue
    
    # å°è¯• dir() æŸ¥æ‰¾æ‰€æœ‰å±æ€§
    for attr_name in dir(diarization):
        if attr_name.startswith("_"):
            continue
        try:
            ann = getattr(diarization, attr_name)
            if ann is not None and hasattr(ann, "itertracks"):
                return ann
        except:
            continue

    # æœ‰äº›ç‰ˆæœ¬å¯èƒ½è¿”å› dict
    if isinstance(diarization, dict):
        for key in ["annotation", "speaker", "output", "result", "diarization"]:
            ann = diarization.get(key)
            if ann is not None and hasattr(ann, "itertracks"):
                return ann

    # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œæ‰“å°æ‰€æœ‰å±æ€§ä»¥ä¾¿è°ƒè¯•
    attrs = [a for a in dir(diarization) if not a.startswith("_")]
    try:
        obj_dict = vars(diarization) if hasattr(diarization, "__dict__") else {}
        logger.error(f"DiarizeOutput å¯¹è±¡è¯¦æƒ…: {obj_dict}")
    except:
        pass
    
    raise TypeError(
        f"Unsupported diarization output type: {type(diarization)}\n"
        f"Available attributes: {attrs}\n"
        f"Type: {type(diarization).__name__}\n"
        f"è¯·æ£€æŸ¥ Pyannote ç‰ˆæœ¬å’Œ DiarizeOutput çš„å®é™…ç»“æ„"
    )

@app.post("/rttm", response_model=RTTMResponse)
async def get_rttm(
    audio_path: Optional[str] = Form(None),
    audio_url: Optional[str] = Form(None),
    file: Optional[UploadFile] = File(None)
) -> RTTMResponse:
    """
    è·å– RTTM æ ¼å¼ç»“æœï¼ˆç”¨äºå¹¶è¡Œå¤„ç†ï¼‰
    æ”¯æŒä¸‰ç§è¾“å…¥æ–¹å¼ï¼š
    1. æ–‡ä»¶ä¸Šä¼ : file
    2. URL: audio_url
    3. æœ¬åœ°è·¯å¾„: audio_path (ä»…å½“æœåŠ¡ç«¯å¯è®¿é—®æ—¶)
    """
    hf_token = os.getenv("HF_TOKEN") or None

    try:
        # è·å– pipeline (ä¼˜å…ˆè¯» offline_config.yaml)
        pipeline = get_pyannote_pipeline(use_auth_token=hf_token)

        if pipeline is None:
            return RTTMResponse(rttm="", error="Failed to load Pyannote pipeline")

        # ç¡®å®šéŸ³é¢‘æ¥æº
        audio_path_to_use: Optional[str] = None
        tmp_path: Optional[str] = None
        file_id: str = "audio"

        try:
            # ä¼˜å…ˆçº§ï¼šæ–‡ä»¶ä¸Šä¼  > URL > æœ¬åœ°è·¯å¾„
            if file is not None:
                import tempfile
                suffix = Path(file.filename or "audio.mp3").suffix or ".mp3"
                file_id = Path(file.filename or "audio").stem
                logger.info(f"ğŸ“¤ [RTTMè¯·æ±‚] æ¥æ”¶æ–‡ä»¶ä¸Šä¼ : {file.filename}")
                
                with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                    content = await file.read()
                    tmp.write(content)
                    tmp_path = tmp.name
                audio_path_to_use = tmp_path
                logger.info(f"âœ… æ–‡ä»¶å·²ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶: {tmp_path}")
                
            elif audio_url:
                import requests
                import tempfile
                
                logger.info(f"ğŸ”— [RTTMè¯·æ±‚] æ£€æµ‹åˆ°éŸ³é¢‘ URLï¼Œæ­£åœ¨æœåŠ¡å™¨ç«¯ä¸‹è½½: {audio_url}")
                file_id = Path(audio_url).stem
                resp = requests.get(audio_url, timeout=300, stream=True)
                resp.raise_for_status()

                suffix = Path(audio_url).suffix or ".mp3"
                with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                    for chunk in resp.iter_content(chunk_size=8192):
                        if chunk:
                            tmp.write(chunk)
                    tmp_path = tmp.name
                audio_path_to_use = tmp_path
                logger.info(f"âœ… éŸ³é¢‘å·²ä¸‹è½½åˆ°ä¸´æ—¶æ–‡ä»¶: {tmp_path}")
                
            elif audio_path:
                # æ£€æŸ¥æ˜¯å¦æ˜¯ URLï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
                if audio_path.startswith(("http://", "https://")):
                    import requests
                    import tempfile
                    
                    logger.info(f"ğŸ”— [RTTMè¯·æ±‚] æ£€æµ‹åˆ°éŸ³é¢‘ URLï¼ˆæ—§æ¥å£æ ¼å¼ï¼‰ï¼Œæ­£åœ¨æœåŠ¡å™¨ç«¯ä¸‹è½½: {audio_path}")
                    file_id = Path(audio_path).stem
                    resp = requests.get(audio_path, timeout=300, stream=True)
                    resp.raise_for_status()

                    suffix = Path(audio_path).suffix or ".mp3"
                    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                        for chunk in resp.iter_content(chunk_size=8192):
                            if chunk:
                                tmp.write(chunk)
                        tmp_path = tmp.name
                    audio_path_to_use = tmp_path
                    logger.info(f"âœ… éŸ³é¢‘å·²ä¸‹è½½åˆ°ä¸´æ—¶æ–‡ä»¶: {tmp_path}")
                else:
                    # æœ¬åœ°è·¯å¾„ï¼ˆä»…å½“æœåŠ¡ç«¯å¯è®¿é—®æ—¶ï¼‰
                    if os.path.exists(audio_path):
                        audio_path_to_use = audio_path
                        file_id = Path(audio_path).stem
                        logger.info(f"ğŸ“‚ [RTTMè¯·æ±‚] ä½¿ç”¨æœ¬åœ°è·¯å¾„: {audio_path}")
                    else:
                        raise FileNotFoundError(
                            f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼ˆå¯èƒ½æ˜¯è·¨ç³»ç»Ÿè·¯å¾„ï¼‰: {audio_path}ã€‚"
                            f"è¯·ä½¿ç”¨æ–‡ä»¶ä¸Šä¼ ï¼ˆfileï¼‰æˆ– URLï¼ˆaudio_urlï¼‰æ–¹å¼ã€‚"
                        )
            else:
                return RTTMResponse(rttm="", error="ç¼ºå°‘éŸ³é¢‘è¾“å…¥ï¼šè¯·æä¾› fileã€audio_url æˆ– audio_path ä¹‹ä¸€")

            if not audio_path_to_use or not os.path.exists(audio_path_to_use):
                raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path_to_use}")

            # å¼€å§‹æ¨ç†ï¼šæ‰‹åŠ¨è§£ç éŸ³é¢‘ï¼Œç»•è¿‡ pyannote å†…éƒ¨ AudioDecoder
            # å¦‚æœæ ¼å¼ä¸æ”¯æŒï¼ˆå¦‚ M4Aï¼‰ï¼Œä½¿ç”¨ ffmpeg è½¬æ¢
            converted_audio_path = None
            try:
                # å°è¯•ç›´æ¥è¯»å–
                data, sample_rate = sf.read(audio_path_to_use)
            except Exception as e:
                # å¦‚æœ soundfile ä¸æ”¯æŒè¯¥æ ¼å¼ï¼Œä½¿ç”¨ ffmpeg è½¬æ¢ä¸º WAV
                logger.info(f"âš ï¸ soundfile ä¸æ”¯æŒè¯¥æ ¼å¼ï¼Œä½¿ç”¨ ffmpeg è½¬æ¢: {audio_path_to_use}")
                try:
                    # ä½¿ç”¨ ffmpeg è½¬æ¢ä¸º WAV
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_wav:
                        converted_audio_path = tmp_wav.name
                    
                    cmd = [
                        "ffmpeg", "-i", audio_path_to_use,
                        "-ac", "1",  # å•å£°é“
                        "-ar", "16000",  # 16kHz é‡‡æ ·ç‡
                        "-f", "wav",
                        "-y",  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                        converted_audio_path
                    ]
                    
                    result = subprocess.run(
                        cmd,
                        check=True,
                        capture_output=True,
                        timeout=60
                    )
                    
                    # è¯»å–è½¬æ¢åçš„ WAV æ–‡ä»¶
                    data, sample_rate = sf.read(converted_audio_path)
                    logger.info(f"âœ… éŸ³é¢‘æ ¼å¼è½¬æ¢æˆåŠŸ: {converted_audio_path}")
                except subprocess.CalledProcessError as ffmpeg_error:
                    error_msg = ffmpeg_error.stderr.decode() if ffmpeg_error.stderr else str(ffmpeg_error)
                    raise RuntimeError(f"ffmpeg è½¬æ¢å¤±è´¥: {error_msg}") from e
                except FileNotFoundError:
                    raise RuntimeError("ffmpeg æœªå®‰è£…ï¼Œæ— æ³•å¤„ç† M4A ç­‰æ ¼å¼ã€‚è¯·å®‰è£…: apt-get install ffmpeg æˆ– conda install ffmpeg") from e
            # soundfile è¿”å›çš„æ˜¯ [T] æˆ– [T, C]ï¼Œè€Œ pyannote æœŸæœ›çš„æ˜¯ [C, T]
            if data.ndim == 1:
                data = data[None, :]
            else:
                data = data.T  # (channels, time)

            waveform = torch.tensor(data, dtype=torch.float32)
            
            # ä½¿ç”¨å…¬å…±å‡½æ•°å¤„ç†éŸ³é¢‘ï¼ˆæ”¯æŒé•¿éŸ³é¢‘åˆ†æ®µå¤„ç†ï¼‰
            diarization = process_audio_with_pipeline(pipeline, waveform, sample_rate)

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰
            if tmp_path and os.path.exists(tmp_path):
                try:
                    os.remove(tmp_path)
                    logger.info(f"ğŸ§¹ å·²æ¸…ç† RTTM ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶: {tmp_path}")
                except Exception as e:
                    logger.warning(f"âš ï¸ æ¸…ç† RTTM ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
            
            # æ¸…ç†æ ¼å¼è½¬æ¢äº§ç”Ÿçš„ä¸´æ—¶æ–‡ä»¶
            if 'converted_audio_path' in locals() and converted_audio_path and os.path.exists(converted_audio_path):
                try:
                    os.remove(converted_audio_path)
                    logger.debug(f"ğŸ§¹ å·²æ¸…ç†æ ¼å¼è½¬æ¢ä¸´æ—¶æ–‡ä»¶: {converted_audio_path}")
                except Exception as e:
                    logger.warning(f"âš ï¸ æ¸…ç†æ ¼å¼è½¬æ¢ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

        # å…¼å®¹ä¸åŒç‰ˆæœ¬è¾“å‡ºï¼Œæ‹¿åˆ°çœŸæ­£çš„ Annotation
        annotation = _extract_annotation(diarization)

        # æ ¼å¼åŒ–è¾“å‡º
        # ä¸ºäº†åç»­å¤„ç†ç®€å•ç»Ÿä¸€ï¼Œè¿™é‡Œå¼ºåˆ¶å°†æ‰€æœ‰è¯´è¯äººæ ‡ç­¾è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ SPEAKER_XX
        rttm_lines = []
        label_to_index: dict = {}
        next_speaker_index = 0

        for turn, _, speaker in annotation.itertracks(yield_label=True):
            start = turn.start
            duration = turn.end - turn.start

            # åŸå§‹æ ‡ç­¾å¯èƒ½ä¸º Noneã€ç©ºå­—ç¬¦ä¸²ã€æ•´æ•°ã€'A'/'B' ç­‰å„ç§å½¢å¼
            raw_label = speaker if speaker not in (None, "") else f"UNK_{next_speaker_index}"

            # ç»Ÿä¸€æ˜ å°„åˆ°è¿ç»­çš„æ•´æ•° ID
            if raw_label not in label_to_index:
                label_to_index[raw_label] = next_speaker_index
                next_speaker_index += 1

            speaker_idx = label_to_index[raw_label]
            speaker_str = f"SPEAKER_{speaker_idx:02d}"

            rttm_lines.append(
                f"SPEAKER {file_id} 1 {start:.3f} {duration:.3f} <NA> <NA> {speaker_str} <NA> <NA>"
            )

        rttm_content = "\n".join(rttm_lines)
        logger.info(f"âœ… RTTM ç”ŸæˆæˆåŠŸ ({len(rttm_lines)} ä¸ªç‰‡æ®µ)")
        return RTTMResponse(rttm=rttm_content)

    except Exception as e:
        logger.error(f"âŒ RTTM ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
        return RTTMResponse(rttm="", error=str(e))


@app.post("/diarize", response_model=DiarizeResponse)
async def diarize(req: DiarizeRequest) -> DiarizeResponse:
    """
    æ ‡å‡†è¯´è¯äººåˆ†ç¦»æ¥å£ï¼ˆåˆå¹¶ Transcriptï¼‰
    """
    hf_token = os.getenv("HF_TOKEN") or None
    
    logger.info(f"ğŸ“‚ [Diarizeè¯·æ±‚] éŸ³é¢‘: {req.audio_path}, å­—å¹•æ¡æ•°: {len(req.transcript)}")

    # 1. è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
    transcript_dicts: List[dict] = [
        {
            "text": item.text,
            "start_time": item.start_time,
            "end_time": item.end_time,
            "speaker_id": item.speaker_id,
        }
        for item in req.transcript
    ]

    # 2. è°ƒç”¨æ ¸å¿ƒé€»è¾‘ (è¿™å°±æ˜¯æˆ‘ä»¬åˆšæ‰ä¿®æ”¹è¿‡çš„é‚£ä¸ªæ–‡ä»¶)
    updated = perform_pyannote_diarization(
        audio_path=req.audio_path,
        transcript=transcript_dicts,
        use_auth_token=hf_token,
    )

    # 3. å°è£…è¿”å›
    resp_items: List[TranscriptItem] = [
        TranscriptItem(
            text=item.get("text", ""),
            start_time=float(item.get("start_time", 0.0)),
            end_time=float(item.get("end_time", 0.0)),
            speaker_id=str(item.get("speaker_id")) if item.get("speaker_id") else None,
        )
        for item in updated
    ]

    return DiarizeResponse(transcript=resp_items)


if __name__ == "__main__":
    import uvicorn
    
    host = os.getenv("PYANNOTE_HOST", "0.0.0.0")
    port = int(os.getenv("PYANNOTE_PORT", "8100"))
    
    print(f"\nğŸš€ Pyannote æœåŠ¡å¯åŠ¨ä¸­...")
    print(f"ğŸ‘‰ ç›‘å¬: http://{host}:{port}")
    
    uvicorn.run(
        "pyannote_server:app",
        host=host,
        port=port,
        reload=False,
        log_level="info"
    )