# FunASR ç‹¬ç«‹è¯­éŸ³è¯†åˆ«æœåŠ¡

ç‹¬ç«‹éƒ¨ç½²çš„ FunASR è¯­éŸ³è¯†åˆ«æœåŠ¡ï¼Œæä¾› HTTP API ä¾›å…¶ä»–æœåŠ¡è°ƒç”¨ã€‚

## ğŸ¯ åŠŸèƒ½ç‰¹ç‚¹

- âœ… ç‹¬ç«‹éƒ¨ç½²ï¼Œèµ„æºéš”ç¦»
- âœ… æ”¯æŒ GPU åŠ é€Ÿ
- âœ… HTTP API æ¥å£
- âœ… å¯è¢«å¤šä¸ªæœåŠ¡å…±äº«
- âœ… æ˜“äºæ‰©å±•å’Œç»´æŠ¤

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
cd funasr_standalone
python -m venv venv

# Windows
.\venv\Scripts\Activate.ps1

# Linux/Mac
source venv/bin/activate
```

### 2. å®‰è£…ä¾èµ–

#### CPU ç‰ˆæœ¬ï¼ˆé»˜è®¤ï¼‰

```bash
pip install -r requirements.txt
```

#### GPU ç‰ˆæœ¬ï¼ˆCUDA 11.8ï¼‰

```bash
pip install fastapi uvicorn python-multipart funasr modelscope
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118
```

#### GPU ç‰ˆæœ¬ï¼ˆCUDA 12.1ï¼‰

```bash
pip install fastapi uvicorn python-multipart funasr modelscope
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### 3. é…ç½®ç¯å¢ƒå˜é‡

```bash
# å¤åˆ¶é…ç½®æ–‡ä»¶
cp .env.example .env

# ç¼–è¾‘é…ç½®ï¼ˆå¦‚æœéœ€è¦ï¼‰
# Windows: notepad .env
# Linux/Mac: nano .env
```

**é…ç½®ç¤ºä¾‹ï¼ˆGPUï¼‰**ï¼š
```ini
FUNASR_DEVICE=cuda
FUNASR_SERVICE_PORT=8002
```

**é…ç½®ç¤ºä¾‹ï¼ˆCPUï¼‰**ï¼š
```ini
FUNASR_DEVICE=cpu
FUNASR_SERVICE_PORT=8002
FUNASR_NCPU=8
```

### 4. å¯åŠ¨æœåŠ¡

```bash
python main.py
```

**é¢„æœŸè¾“å‡º**ï¼š
```
==================================================
ğŸš€ FunASR æœåŠ¡å¯åŠ¨
ğŸ“ åœ°å€: http://0.0.0.0:8002
ğŸ¤ æ¨¡å‹: paraformer-zh
ğŸ’» è®¾å¤‡: cuda
==================================================
âœ… FunASR æ¨¡å‹åŠ è½½æˆåŠŸï¼è®¾å¤‡: cuda
INFO:     Uvicorn running on http://0.0.0.0:8002
```

---

## ğŸ“¡ API æ¥å£

### 1. å¥åº·æ£€æŸ¥

```bash
curl http://localhost:8002/health
```

**å“åº”**ï¼š
```json
{
  "status": "healthy",
  "model_loaded": true,
  "device": "cuda"
}
```

### 2. è¯­éŸ³è¯†åˆ«

```bash
curl -X POST "http://localhost:8002/transcribe" \
  -F "file=@audio.mp3" \
  -F "enable_punc=true"
```

**å“åº”**ï¼š
```json
{
  "text": "å®Œæ•´çš„è¯†åˆ«æ–‡æœ¬",
  "transcript": [
    {
      "text": "ç¬¬ä¸€å¥è¯",
      "start_time": 0.0,
      "end_time": 2.5,
      "speaker_id": "1"
    },
    {
      "text": "ç¬¬äºŒå¥è¯",
      "start_time": 2.5,
      "end_time": 5.0,
      "speaker_id": "1"
    }
  ]
}
```

### 3. Python è°ƒç”¨ç¤ºä¾‹

```python
import requests

url = "http://localhost:8002/transcribe"

with open("audio.mp3", "rb") as f:
    files = {"file": f}
    response = requests.post(url, files=files)
    result = response.json()
    
    print(f"è¯†åˆ«æ–‡æœ¬: {result['text']}")
    print(f"é€å­—ç¨¿: {result['transcript']}")
```

---

## ğŸ”§ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡

| å˜é‡ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `FUNASR_SERVICE_HOST` | 0.0.0.0 | æœåŠ¡ç›‘å¬åœ°å€ |
| `FUNASR_SERVICE_PORT` | 8002 | æœåŠ¡ç«¯å£ |
| `FUNASR_DEVICE` | cuda | è®¾å¤‡ç±»å‹ï¼ˆcuda/cpuï¼‰ |
| `FUNASR_MODEL_NAME` | paraformer-zh | æ¨¡å‹åç§° |
| `FUNASR_NCPU` | 4 | CPU æ ¸å¿ƒæ•° |
| `FUNASR_BATCH_SIZE` | 300 | æ‰¹å¤„ç†å¤§å° |

---

## ğŸ³ Docker éƒ¨ç½²ï¼ˆå¯é€‰ï¼‰

### 1. åˆ›å»º Dockerfile

```dockerfile
FROM python:3.10-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .

# å®‰è£… Python ä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶ä»£ç 
COPY main.py .
COPY .env .

# æš´éœ²ç«¯å£
EXPOSE 8002

# å¯åŠ¨æœåŠ¡
CMD ["python", "main.py"]
```

### 2. æ„å»ºé•œåƒ

```bash
docker build -t funasr-service:latest .
```

### 3. è¿è¡Œå®¹å™¨

```bash
# CPU ç‰ˆæœ¬
docker run -d -p 8002:8002 funasr-service:latest

# GPU ç‰ˆæœ¬
docker run -d --gpus all -p 8002:8002 funasr-service:latest
```

---

## ğŸ” ç›‘æ§å’Œæ—¥å¿—

### æŸ¥çœ‹æ—¥å¿—

```bash
# æœåŠ¡æ—¥å¿—ä¼šè¾“å‡ºåˆ°æ§åˆ¶å°
python main.py

# Docker å®¹å™¨æ—¥å¿—
docker logs -f <container_id>
```

### æ€§èƒ½ç›‘æ§

è®¿é—® FastAPI è‡ªå¸¦çš„æ–‡æ¡£é¡µé¢ï¼š
- Swagger UI: http://localhost:8002/docs
- ReDoc: http://localhost:8002/redoc

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. GPU åŠ é€Ÿ

ç¡®ä¿é…ç½®äº† GPUï¼š
```ini
FUNASR_DEVICE=cuda
```

### 2. æ‰¹å¤„ç†ä¼˜åŒ–

æ ¹æ® GPU æ˜¾å­˜è°ƒæ•´æ‰¹å¤„ç†å¤§å°ï¼š
```ini
FUNASR_BATCH_SIZE=500  # æ˜¾å­˜å¤§çš„å¯ä»¥è°ƒå¤§
```

### 3. CPU æ ¸å¿ƒæ•°

CPU æ¨¡å¼ä¸‹è°ƒæ•´æ ¸å¿ƒæ•°ï¼š
```ini
FUNASR_NCPU=16  # æ ¹æ®æœåŠ¡å™¨ CPU è°ƒæ•´
```

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: æ¨¡å‹ä¸‹è½½å¤ªæ…¢ï¼Ÿ

**A**: è®¾ç½®é•œåƒï¼š
```bash
export HF_ENDPOINT=https://hf-mirror.com
```

### Q2: GPU ä¸å¯ç”¨ï¼Ÿ

**A**: æ£€æŸ¥ CUDAï¼š
```bash
python -c "import torch; print(torch.cuda.is_available())"
```

### Q3: å†…å­˜ä¸è¶³ï¼Ÿ

**A**: é™ä½æ‰¹å¤„ç†å¤§å°æˆ–ä½¿ç”¨ CPUï¼š
```ini
FUNASR_DEVICE=cpu
FUNASR_BATCH_SIZE=100
```

---

## ğŸ“Š æ€§èƒ½å‚è€ƒ

| é…ç½® | å¤„ç†é€Ÿåº¦ | æ˜¾å­˜å ç”¨ |
|------|----------|----------|
| CPU (8æ ¸) | ~0.5x å®æ—¶ | 2GB |
| GPU (RTX 3060) | ~5x å®æ—¶ | 4GB |
| GPU (A100) | ~20x å®æ—¶ | 6GB |

---

## ğŸ”— é›†æˆåˆ°ä¸»æœåŠ¡

ä¸»æœåŠ¡çš„é…ç½®ï¼ˆ`meeting_ai/.env`ï¼‰ï¼š

```ini
# ASR æœåŠ¡é…ç½®
ASR_SERVICE_TYPE=funasr
FUNASR_SERVICE_URL=http://localhost:8002
```

ä¸»æœåŠ¡ä¼šè‡ªåŠ¨é€šè¿‡ HTTP è°ƒç”¨è¿™ä¸ªç‹¬ç«‹æœåŠ¡ã€‚

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [FunASR å®˜æ–¹æ–‡æ¡£](https://github.com/alibaba-damo-academy/FunASR)
- [ä¸»æœåŠ¡éƒ¨ç½²æ–‡æ¡£](../å¿«é€Ÿéƒ¨ç½²æŒ‡å—.md)

---

**æœåŠ¡éƒ¨ç½²å®Œæˆåï¼Œä¸»æœåŠ¡å°±å¯ä»¥é€šè¿‡ HTTP è°ƒç”¨äº†ï¼** ğŸ‰
