#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Pyannote è¯´è¯äººåˆ†ç¦»æ¨¡å—
ä½¿ç”¨ä¸“ä¸šçš„ Pyannote.audio æ¨¡å‹è¿›è¡Œè¯´è¯äººåˆ†ç¦»
"""
import logging
from typing import List, Dict, Optional
from pathlib import Path

logger = logging.getLogger(__name__)

try:
    from pyannote.audio import Pipeline
    PYANNOTE_AVAILABLE = True
except ImportError:
    PYANNOTE_AVAILABLE = False
    logger.warning("âš ï¸ Pyannote.audio æœªå®‰è£…ï¼Œè¯´è¯äººåˆ†ç¦»åŠŸèƒ½å°†ä¸å¯ç”¨")
    logger.warning("   å®‰è£…å‘½ä»¤: pip install pyannote.audio")


# å…¨å±€ pipeline ç¼“å­˜ï¼ˆé¿å…é‡å¤åŠ è½½ï¼‰
_pipeline_cache = None


def get_pyannote_pipeline(use_auth_token: Optional[str] = None):
    """
    è·å– Pyannote pipelineï¼ˆå¸¦ç¼“å­˜ï¼‰
    
    Args:
        use_auth_token: HuggingFace token
    
    Returns:
        Pipeline å¯¹è±¡ï¼Œå¤±è´¥è¿”å› None
    """
    global _pipeline_cache
    
    if _pipeline_cache is not None:
        return _pipeline_cache
    
    if not PYANNOTE_AVAILABLE:
        return None
    
    try:
        import os
        from pathlib import Path
        
        hf_token = use_auth_token or os.getenv("HF_TOKEN")
        
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        current_file = Path(__file__).resolve()
        project_root = current_file.parent.parent
        local_model_path = project_root / "models" / "pyannote_diarization"
        
        pipeline = None
        use_local_model = False
        
        # æ£€æŸ¥æœ¬åœ°æ¨¡å‹
        if local_model_path.exists() and (local_model_path / "config.yaml").exists():
            logger.info(f"âœ… æ£€æµ‹åˆ°é¡¹ç›®æœ¬åœ°æ¨¡å‹: {local_model_path}")
            
            local_segmentation_path = project_root / "models" / "pyannote_segmentation"
            local_embedding_path = project_root / "models" / "pyannote_wespeaker"
            
            has_local_segmentation = local_segmentation_path.exists() and (local_segmentation_path / "config.yaml").exists()
            has_local_embedding = local_embedding_path.exists() and (local_embedding_path / "config.yaml").exists()
            
            if has_local_segmentation and has_local_embedding:
                try:
                    import yaml
                    import shutil
                    
                    config_file = local_model_path / "config.yaml"
                    with open(config_file, 'r', encoding='utf-8') as f:
                        config = yaml.safe_load(f)
                    
                    if 'pipeline' in config and 'params' in config['pipeline']:
                        config['pipeline']['params']['segmentation'] = str(local_segmentation_path.resolve())
                        config['pipeline']['params']['embedding'] = str(local_embedding_path.resolve())
                    
                    temp_config_file = local_model_path / "config.yaml.local"
                    with open(temp_config_file, 'w', encoding='utf-8') as f:
                        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
                    
                    original_config_file = local_model_path / "config.yaml.original"
                    if not original_config_file.exists():
                        shutil.copy2(config_file, original_config_file)
                    
                    shutil.copy2(temp_config_file, config_file)
                    
                    try:
                        pipeline = Pipeline.from_pretrained(str(local_model_path), local_files_only=True)
                        logger.info("âœ… æˆåŠŸä»é¡¹ç›®æœ¬åœ°è·¯å¾„åŠ è½½ Pyannote æ¨¡å‹")
                        use_local_model = True
                    finally:
                        if original_config_file.exists():
                            shutil.copy2(original_config_file, config_file)
                        if temp_config_file.exists():
                            temp_config_file.unlink()
                except Exception as e:
                    logger.warning(f"âš ï¸ ä»æœ¬åœ°è·¯å¾„åŠ è½½å¤±è´¥: {e}")
        
        # å¦‚æœæœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°è¯•ä» HuggingFace åŠ è½½
        if not use_local_model:
            cache_dirs = [
                Path.home() / ".cache" / "pyannote",
                Path.home() / ".cache" / "huggingface" / "hub",
            ]
            
            model_cached = False
            for cache_dir in cache_dirs:
                if cache_dir.exists():
                    model_path = cache_dir / "models--pyannote--speaker-diarization-3.1"
                    if model_path.exists():
                        model_cached = True
                        break
            
            try:
                if hf_token:
                    try:
                        pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1", token=hf_token)
                    except TypeError:
                        pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1", use_auth_token=hf_token)
                else:
                    pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1")
                logger.info("âœ… Pyannote pipeline åŠ è½½æˆåŠŸ")
            except Exception as load_error:
                error_str = str(load_error).lower()
                if ("network" in error_str or "unreachable" in error_str) and model_cached:
                    try:
                        pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1", local_files_only=True)
                        logger.info("âœ… ä½¿ç”¨æœ¬åœ°ç¼“å­˜åŠ è½½ Pyannote pipeline")
                    except:
                        logger.error(f"âŒ æ— æ³•ä½¿ç”¨æœ¬åœ°ç¼“å­˜: {load_error}")
                        return None
                else:
                    logger.error(f"âŒ åŠ è½½ Pyannote pipeline å¤±è´¥: {load_error}")
                    return None
        
        _pipeline_cache = pipeline
        return pipeline
        
    except Exception as e:
        logger.error(f"âŒ åŠ è½½ Pyannote pipeline å¤±è´¥: {e}")
        return None


def perform_pyannote_diarization(
    audio_path: str,
    transcript: List[Dict],
    use_auth_token: Optional[str] = None
) -> List[Dict]:
    """
    ä½¿ç”¨ Pyannote è¿›è¡Œè¯´è¯äººåˆ†ç¦»
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        transcript: ASRè¯†åˆ«ç»“æœï¼ŒåŒ…å«textã€start_timeã€end_time
        use_auth_token: HuggingFace tokenï¼ˆå¦‚æœéœ€è¦è®¿é—®ç§æœ‰æ¨¡å‹ï¼‰
    
    Returns:
        æ›´æ–°åçš„transcriptï¼ŒåŒ…å«speaker_idå­—æ®µ
    """
    if not PYANNOTE_AVAILABLE:
        logger.error("âŒ Pyannote.audio æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨è¯´è¯äººåˆ†ç¦»")
        logger.error("   è¯·è¿è¡Œ: pip install pyannote.audio")
        # è¿”å›åŸå§‹transcriptï¼Œæ‰€æœ‰ç‰‡æ®µæ ‡è®°ä¸ºspeaker_id="0"
        for item in transcript:
            if 'speaker_id' not in item:
                item['speaker_id'] = "0"
        return transcript
    
    try:
        logger.info("ğŸ¤ ä½¿ç”¨ Pyannote.audio è¿›è¡Œè¯´è¯äººåˆ†ç¦»...")
        
        # è·å– pipelineï¼ˆå¸¦ç¼“å­˜ï¼‰
        pipeline = get_pyannote_pipeline(use_auth_token)
        if pipeline is None:
            logger.error("âŒ æ— æ³•åŠ è½½ Pyannote pipeline")
            for item in transcript:
                if 'speaker_id' not in item:
                    item['speaker_id'] = "0"
            return transcript
        
        # å¤„ç†éŸ³é¢‘
        # ä¼˜å…ˆä½¿ç”¨é¡¹ç›®ä¸­çš„æœ¬åœ°æ¨¡å‹è·¯å¾„
        try:
            import os
            from pathlib import Path
            
            # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„ tokenï¼Œå…¶æ¬¡ä»ç¯å¢ƒå˜é‡è¯»å–
            hf_token = use_auth_token or os.getenv("HF_TOKEN")
            
            # 1. é¦–å…ˆæ£€æŸ¥é¡¹ç›®ä¸­çš„æœ¬åœ°æ¨¡å‹ç›®å½•
            # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œç„¶åæ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•
            current_file = Path(__file__).resolve()
            # funasr_standalone/pyannote_diarization.py -> é¡¹ç›®æ ¹ç›®å½•
            project_root = current_file.parent.parent
            local_model_path = project_root / "models" / "pyannote_diarization"
            
            pipeline = None
            use_local_model = False
            
            # æ£€æŸ¥æœ¬åœ°æ¨¡å‹ç›®å½•æ˜¯å¦å­˜åœ¨ä¸”åŒ…å« config.yaml
            if local_model_path.exists() and (local_model_path / "config.yaml").exists():
                logger.info(f"âœ… æ£€æµ‹åˆ°é¡¹ç›®æœ¬åœ°æ¨¡å‹: {local_model_path}")
                
                # æ£€æŸ¥å­æ¨¡å‹æ˜¯å¦ä¹Ÿåœ¨æœ¬åœ°
                local_segmentation_path = project_root / "models" / "pyannote_segmentation"
                local_embedding_path = project_root / "models" / "pyannote_wespeaker"
                
                has_local_segmentation = local_segmentation_path.exists() and (local_segmentation_path / "config.yaml").exists()
                has_local_embedding = local_embedding_path.exists() and (local_embedding_path / "config.yaml").exists()
                
                if has_local_segmentation:
                    logger.info(f"âœ… æ£€æµ‹åˆ°æœ¬åœ°åˆ†å‰²æ¨¡å‹: {local_segmentation_path}")
                else:
                    logger.warning(f"âš ï¸ æœªæ£€æµ‹åˆ°æœ¬åœ°åˆ†å‰²æ¨¡å‹: {local_segmentation_path}")
                
                if has_local_embedding:
                    logger.info(f"âœ… æ£€æµ‹åˆ°æœ¬åœ°åµŒå…¥æ¨¡å‹: {local_embedding_path}")
                else:
                    logger.warning(f"âš ï¸ æœªæ£€æµ‹åˆ°æœ¬åœ°åµŒå…¥æ¨¡å‹: {local_embedding_path}")
                
                # å¦‚æœæ‰€æœ‰å­æ¨¡å‹éƒ½åœ¨æœ¬åœ°ï¼Œä¿®æ”¹ config.yaml ä»¥ä½¿ç”¨æœ¬åœ°è·¯å¾„
                if has_local_segmentation and has_local_embedding:
                    try:
                        try:
                            import yaml
                        except ImportError:
                            logger.error("âŒ ç¼ºå°‘ PyYAML åº“ï¼Œæ— æ³•ä¿®æ”¹é…ç½®æ–‡ä»¶")
                            logger.error("   è¯·å®‰è£…: pip install PyYAML")
                            raise ImportError("PyYAML is required to modify config.yaml")
                        
                        import shutil
                        
                        # è¯»å–åŸå§‹ config.yaml
                        config_file = local_model_path / "config.yaml"
                        with open(config_file, 'r', encoding='utf-8') as f:
                            config = yaml.safe_load(f)
                        
                        # ä¿®æ”¹å­æ¨¡å‹è·¯å¾„ä¸ºæœ¬åœ°è·¯å¾„ï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
                        if 'pipeline' in config and 'params' in config['pipeline']:
                            config['pipeline']['params']['segmentation'] = str(local_segmentation_path.resolve())
                            config['pipeline']['params']['embedding'] = str(local_embedding_path.resolve())
                            logger.info(f"   å·²æ›´æ–°é…ç½®ï¼šsegmentation -> {local_segmentation_path}")
                            logger.info(f"   å·²æ›´æ–°é…ç½®ï¼šembedding -> {local_embedding_path}")
                        
                        # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
                        temp_config_file = local_model_path / "config.yaml.local"
                        with open(temp_config_file, 'w', encoding='utf-8') as f:
                            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
                        
                        # å¤‡ä»½åŸå§‹é…ç½®æ–‡ä»¶
                        original_config_file = local_model_path / "config.yaml.original"
                        if not original_config_file.exists():
                            shutil.copy2(config_file, original_config_file)
                        
                        # ä½¿ç”¨ä¸´æ—¶é…ç½®æ–‡ä»¶
                        shutil.copy2(temp_config_file, config_file)
                        logger.info("   å·²ä¸´æ—¶ä¿®æ”¹ config.yaml ä»¥ä½¿ç”¨æœ¬åœ°å­æ¨¡å‹")
                        
                        try:
                            # ä½¿ç”¨æœ¬åœ°è·¯å¾„åŠ è½½æ¨¡å‹
                            pipeline = Pipeline.from_pretrained(str(local_model_path))
                            logger.info("âœ… æˆåŠŸä»é¡¹ç›®æœ¬åœ°è·¯å¾„åŠ è½½ Pyannote æ¨¡å‹ï¼ˆä½¿ç”¨æœ¬åœ°å­æ¨¡å‹ï¼‰")
                            use_local_model = True
                        finally:
                            # æ¢å¤åŸå§‹é…ç½®æ–‡ä»¶
                            if original_config_file.exists():
                                shutil.copy2(original_config_file, config_file)
                                logger.info("   å·²æ¢å¤åŸå§‹ config.yaml")
                            if temp_config_file.exists():
                                temp_config_file.unlink()
                    except ImportError:
                        logger.warning("   âš ï¸ ç¼ºå°‘ yaml åº“ï¼Œæ— æ³•ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼Œå°è¯•ç›´æ¥åŠ è½½...")
                        try:
                            pipeline = Pipeline.from_pretrained(str(local_model_path))
                            logger.info("âœ… æˆåŠŸä»é¡¹ç›®æœ¬åœ°è·¯å¾„åŠ è½½ Pyannote æ¨¡å‹")
                            use_local_model = True
                        except Exception as local_load_error:
                            logger.warning(f"âš ï¸ ä»æœ¬åœ°è·¯å¾„åŠ è½½å¤±è´¥: {local_load_error}")
                            logger.info("   å°†å°è¯•ä» HuggingFace æˆ–ç¼“å­˜åŠ è½½...")
                    except Exception as config_error:
                        logger.warning(f"âš ï¸ ä¿®æ”¹é…ç½®æ–‡ä»¶å¤±è´¥: {config_error}")
                        logger.info("   å°è¯•ç›´æ¥åŠ è½½æ¨¡å‹...")
                        try:
                            pipeline = Pipeline.from_pretrained(str(local_model_path))
                            logger.info("âœ… æˆåŠŸä»é¡¹ç›®æœ¬åœ°è·¯å¾„åŠ è½½ Pyannote æ¨¡å‹")
                            use_local_model = True
                        except Exception as local_load_error:
                            logger.warning(f"âš ï¸ ä»æœ¬åœ°è·¯å¾„åŠ è½½å¤±è´¥: {local_load_error}")
                            logger.info("   å°†å°è¯•ä» HuggingFace æˆ–ç¼“å­˜åŠ è½½...")
                else:
                    # å¦‚æœå­æ¨¡å‹ä¸å®Œæ•´ï¼Œå°è¯•ç›´æ¥åŠ è½½ï¼ˆå¯èƒ½ä¼šä»ç½‘ç»œä¸‹è½½ç¼ºå¤±çš„ï¼‰
                    try:
                        pipeline = Pipeline.from_pretrained(str(local_model_path))
                        logger.info("âœ… æˆåŠŸä»é¡¹ç›®æœ¬åœ°è·¯å¾„åŠ è½½ Pyannote æ¨¡å‹")
                        use_local_model = True
                    except Exception as local_load_error:
                        logger.warning(f"âš ï¸ ä»æœ¬åœ°è·¯å¾„åŠ è½½å¤±è´¥: {local_load_error}")
                        logger.info("   å°†å°è¯•ä» HuggingFace æˆ–ç¼“å­˜åŠ è½½...")
            
            # 2. å¦‚æœæœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°è¯•ä» HuggingFace æˆ–ç¼“å­˜åŠ è½½
            if not use_local_model:
                # æ£€æŸ¥æœ¬åœ°ç¼“å­˜ç›®å½•ï¼ˆPyannote é€šå¸¸ç¼“å­˜åˆ° ~/.cache/pyannote/ æˆ– ~/.cache/huggingface/ï¼‰
                cache_dirs = [
                    Path.home() / ".cache" / "pyannote",
                    Path.home() / ".cache" / "huggingface" / "hub",
                ]
                
                model_cached = False
                for cache_dir in cache_dirs:
                    if cache_dir.exists():
                        # æ£€æŸ¥æ˜¯å¦æœ‰ speaker-diarization-3.1 çš„ç¼“å­˜
                        model_path = cache_dir / "models--pyannote--speaker-diarization-3.1"
                        if model_path.exists():
                            model_cached = True
                            logger.info(f"âœ… æ£€æµ‹åˆ°æœ¬åœ°æ¨¡å‹ç¼“å­˜: {model_path}")
                            break
                
                # å°è¯•åŠ è½½æ¨¡å‹
                try:
                    if hf_token:
                        # æ–°ç‰ˆæœ¬çš„ transformers ä½¿ç”¨ token å‚æ•°ï¼Œè€Œä¸æ˜¯ use_auth_token
                        try:
                            pipeline = Pipeline.from_pretrained(
                                "pyannote/speaker-diarization-3.1",
                                token=hf_token
                            )
                        except TypeError:
                            # å…¼å®¹æ—§ç‰ˆæœ¬ï¼Œå¦‚æœ token å‚æ•°ä¸æ”¯æŒï¼Œå°è¯• use_auth_token
                            pipeline = Pipeline.from_pretrained(
                                "pyannote/speaker-diarization-3.1",
                                use_auth_token=hf_token
                            )
                    else:
                        # å°è¯•ä¸ä½¿ç”¨tokenï¼ˆå¦‚æœæ¨¡å‹æ˜¯å…¬å¼€çš„æˆ–å·²ç¼“å­˜ï¼‰
                        pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1")
                    logger.info("âœ… Pyannote æ¨¡å‹åŠ è½½æˆåŠŸï¼ˆä» HuggingFaceï¼‰")
                except Exception as load_error:
                    error_str = str(load_error).lower()
                    if "network" in error_str or "unreachable" in error_str or "connection" in error_str:
                        if model_cached:
                            logger.warning(f"âš ï¸ ç½‘ç»œä¸å¯è¾¾ï¼Œä½†æ£€æµ‹åˆ°æœ¬åœ°ç¼“å­˜ï¼Œå°è¯•ä½¿ç”¨ç¼“å­˜...")
                            # å¦‚æœç½‘ç»œä¸å¯è¾¾ä½†æœ‰ç¼“å­˜ï¼Œå°è¯•å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°
                            try:
                                # å°è¯•ä»ç¼“å­˜ç›®å½•ç›´æ¥åŠ è½½
                                pipeline = Pipeline.from_pretrained(
                                    "pyannote/speaker-diarization-3.1",
                                    local_files_only=True  # ä»…ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
                                )
                                logger.info("âœ… æˆåŠŸä½¿ç”¨æœ¬åœ°ç¼“å­˜åŠ è½½æ¨¡å‹")
                            except Exception as local_error:
                                logger.error(f"âŒ æ— æ³•ä½¿ç”¨æœ¬åœ°ç¼“å­˜: {local_error}")
                                raise load_error  # æŠ›å‡ºåŸå§‹é”™è¯¯
                        else:
                            logger.error(f"âŒ ç½‘ç»œä¸å¯è¾¾ä¸”æ— æœ¬åœ°ç¼“å­˜: {load_error}")
                            logger.error("   è§£å†³æ–¹æ¡ˆ:")
                            logger.error("   1. ç¡®ä¿ç½‘ç»œå¯ä»¥è®¿é—® HuggingFaceï¼Œæˆ–é…ç½®ä»£ç†")
                            logger.error("   2. æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°ç¼“å­˜:")
                            logger.error("      python -c \"from pyannote.audio import Pipeline; Pipeline.from_pretrained('pyannote/speaker-diarization-3.1', token='YOUR_TOKEN')\"")
                            logger.error("   3. æˆ–ä½¿ç”¨å·²ä¸‹è½½çš„æ¨¡å‹è·¯å¾„")
                            raise load_error
                    else:
                        raise load_error
                    
        except Exception as e:
            logger.error(f"âŒ åŠ è½½ Pyannote æ¨¡å‹å¤±è´¥: {e}")
            logger.error("   è¯·ç¡®ä¿:")
            logger.error("   1. å·²å®‰è£… pyannote.audio: pip install pyannote.audio")
            logger.error("   2. åœ¨ HuggingFace ä¸Šæ¥å—æ¨¡å‹ä½¿ç”¨åè®®: https://huggingface.co/pyannote/speaker-diarization-3.1")
            logger.error("   3. å¦‚æœç½‘ç»œä¸å¯è¾¾ï¼Œè¯·å…ˆåœ¨æœ‰ç½‘ç»œçš„æœºå™¨ä¸Šä¸‹è½½æ¨¡å‹ï¼Œç„¶åå¤åˆ¶ç¼“å­˜ç›®å½•")
            logger.error("   4. ç¼“å­˜ç›®å½•é€šå¸¸åœ¨: ~/.cache/pyannote/ æˆ– ~/.cache/huggingface/hub/")
            # é™çº§ï¼šè¿”å›åŸå§‹transcript
            for item in transcript:
                if 'speaker_id' not in item:
                    item['speaker_id'] = "0"
            return transcript
        
        # å¤„ç†éŸ³é¢‘
        logger.info(f"ğŸ“‚ å¤„ç†éŸ³é¢‘æ–‡ä»¶: {audio_path}")
        diarization = pipeline(audio_path)
        
        # æ„å»ºè¯´è¯äººæ—¶é—´æ˜ å°„
        # diarizationæ ¼å¼: (start, end, speaker_label)
        speaker_segments = []
        for turn, _, speaker in diarization.itertracks(yield_label=True):
            speaker_segments.append({
                'start_time': turn.start,
                'end_time': turn.end,
                'speaker_id': speaker
            })
        
        logger.info(f"âœ… Pyannote è¯†åˆ«å‡º {len(set(s['speaker_id'] for s in speaker_segments))} ä¸ªè¯´è¯äºº")
        logger.info(f"   å…± {len(speaker_segments)} ä¸ªè¯´è¯äººç‰‡æ®µ")
        
        # å°†è¯´è¯äººä¿¡æ¯æ˜ å°„åˆ°transcript
        # å¯¹äºæ¯ä¸ªtranscriptç‰‡æ®µï¼Œæ‰¾åˆ°æ—¶é—´é‡å çš„è¯´è¯äººç‰‡æ®µ
        for item in transcript:
            item_start = item.get('start_time', 0)
            item_end = item.get('end_time', 0)
            
            # æ‰¾åˆ°æ—¶é—´é‡å çš„è¯´è¯äººç‰‡æ®µ
            matched_speaker = None
            max_overlap = 0
            
            for seg in speaker_segments:
                seg_start = seg['start_time']
                seg_end = seg['end_time']
                
                # è®¡ç®—é‡å æ—¶é—´
                overlap_start = max(item_start, seg_start)
                overlap_end = min(item_end, seg_end)
                overlap = max(0, overlap_end - overlap_start)
                
                # å¦‚æœé‡å æ—¶é—´è¶…è¿‡ç‰‡æ®µé•¿åº¦çš„50%ï¼Œè®¤ä¸ºæ˜¯åŒ¹é…çš„
                item_duration = item_end - item_start
                if item_duration > 0 and overlap / item_duration > 0.5:
                    if overlap > max_overlap:
                        max_overlap = overlap
                        matched_speaker = seg['speaker_id']
            
            # å¦‚æœæ‰¾åˆ°åŒ¹é…çš„è¯´è¯äººï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨æœ€è¿‘çš„è¯´è¯äºº
            if matched_speaker:
                item['speaker_id'] = matched_speaker
            else:
                # æ‰¾åˆ°æœ€è¿‘çš„è¯´è¯äººç‰‡æ®µ
                min_distance = float('inf')
                nearest_speaker = None
                
                for seg in speaker_segments:
                    seg_start = seg['start_time']
                    seg_end = seg['end_time']
                    seg_center = (seg_start + seg_end) / 2
                    item_center = (item_start + item_end) / 2
                    
                    distance = abs(item_center - seg_center)
                    if distance < min_distance:
                        min_distance = distance
                        nearest_speaker = seg['speaker_id']
                
                item['speaker_id'] = nearest_speaker if nearest_speaker else "SPEAKER_00"
        
        # è§„èŒƒåŒ–è¯´è¯äººIDï¼ˆä»SPEAKER_00, SPEAKER_01... è½¬æ¢ä¸º 0, 1, 2...ï¼‰
        speaker_id_map = {}
        speaker_counter = 0
        
        for item in transcript:
            original_id = item.get('speaker_id', 'SPEAKER_00')
            if original_id not in speaker_id_map:
                speaker_id_map[original_id] = str(speaker_counter)
                speaker_counter += 1
            item['speaker_id'] = speaker_id_map[original_id]
        
        logger.info(f"âœ… è¯´è¯äººåˆ†ç¦»å®Œæˆï¼Œå…±è¯†åˆ«å‡º {len(speaker_id_map)} ä¸ªè¯´è¯äºº")
        
        return transcript
        
    except Exception as e:
        logger.error(f"âŒ Pyannote è¯´è¯äººåˆ†ç¦»å¤±è´¥: {e}", exc_info=True)
        # é™çº§ï¼šè¿”å›åŸå§‹transcriptï¼Œæ‰€æœ‰ç‰‡æ®µæ ‡è®°ä¸ºspeaker_id="0"
        for item in transcript:
            if 'speaker_id' not in item:
                item['speaker_id'] = "0"
        return transcript
