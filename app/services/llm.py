import json
import re
import time
from typing import Dict
from openai import OpenAI, APITimeoutError, APIConnectionError
from app.core.config import settings
from app.core.logger import logger


def remove_thinking_tags(text: str) -> str:
    """
    ç§»é™¤LLMè¾“å‡ºä¸­çš„æ€è€ƒè¿‡ç¨‹æ ‡ç­¾
    æ”¯æŒå¤šç§æ ¼å¼ï¼š
    1. <think>...</think>
    2. <p>...æ€è€ƒå†…å®¹...</p>...<h3>ä¼šè®®çºªè¦</h3>
    3. HTMLåµŒå¥—çš„å„ç§å˜ä½“
    """
    if not text:
        return text
    
    original_length = len(text)
    
    # === ç­–ç•¥1: ç§»é™¤æ ‡å‡† <think> æ ‡ç­¾ ===
    text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL | re.IGNORECASE)
    
    # === ç­–ç•¥2: ç§»é™¤éæ ‡å‡†æ ¼å¼ - ä»å¼€å¤´åˆ°ç¬¬ä¸€ä¸ª Markdown æ ‡é¢˜ä¹‹å‰çš„æ‰€æœ‰å†…å®¹ ===
    # æ£€æµ‹æ˜¯å¦ä»¥ <p> å¼€å¤´ï¼Œä¸”åé¢æœ‰ Markdown æ ‡é¢˜ï¼ˆ###ã€##ã€#ï¼‰
    match = re.search(r'^[\s\S]*?(?=#{1,3}\s)', text)
    if match and match.group(0).strip().startswith('<p>'):
        # ç§»é™¤ä»å¼€å¤´åˆ°ç¬¬ä¸€ä¸ªæ ‡é¢˜ä¹‹å‰çš„æ‰€æœ‰ HTML æ®µè½ï¼ˆæ€è€ƒå†…å®¹ï¼‰
        text = re.sub(r'^.*?(?=#{1,3}\s)', '', text, flags=re.DOTALL)
        logger.info("ğŸ§¹ æ£€æµ‹åˆ°éæ ‡å‡†æ€è€ƒæ ¼å¼ï¼Œå·²ç§»é™¤å¼€å¤´çš„ HTML æ®µè½")
    
    # === ç­–ç•¥3: ç§»é™¤åŒ…å«æ€è€ƒå…³é”®è¯çš„ <p> æ®µè½ ===
    # å¸¸è§æ€è€ƒå…³é”®è¯ï¼šå¥½çš„ã€é¦–å…ˆã€æ¥ä¸‹æ¥ã€éœ€è¦æ³¨æ„ã€æœ€å
    thinking_keywords = [
        r'<p>[\s\S]*?å¥½çš„ï¼Œæˆ‘éœ€è¦.*?</p>',
        r'<p>[\s\S]*?é¦–å…ˆ.*?</p>',
        r'<p>[\s\S]*?æ¥ä¸‹æ¥.*?</p>',
        r'<p>[\s\S]*?éœ€è¦æ³¨æ„.*?</p>',
        r'<p>[\s\S]*?æœ€åï¼Œéœ€è¦ç¡®ä¿.*?</p>',
        r'<p>[\s\S]*?</think></p>',  # æ®‹ç•™çš„ </think> æ ‡ç­¾
    ]
    for pattern in thinking_keywords:
        text = re.sub(pattern, '', text, flags=re.DOTALL | re.IGNORECASE)
    
    # === æ¸…ç†æ®‹ç•™ ===
    # ç§»é™¤ç©ºçš„ <p> æ ‡ç­¾
    text = re.sub(r'<p>\s*</p>', '', text, flags=re.DOTALL)
    
    # ç§»é™¤å¼€å¤´çš„ <p> å’Œå¼•å·ï¼ˆå¦‚æœè¿˜æœ‰æ®‹ç•™ï¼‰
    text = re.sub(r'^[\s"]*<p>\s*', '', text)
    
    # ç§»é™¤å¤šä½™çš„ç©ºç™½è¡Œ
    text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)
    
    # å»é™¤å¼€å¤´å’Œç»“å°¾çš„ç©ºç™½å’Œå¼•å·
    text = text.strip().strip('"').strip()
    
    removed_chars = original_length - len(text)
    if removed_chars > 0:
        logger.info(f"ğŸ§¹ å·²æ¸…ç†æ€è€ƒå†…å®¹: ç§»é™¤ {removed_chars} å­—ç¬¦")
    
    return text

class LLMService:
    def __init__(self, api_key: str = None, base_url: str = None, model_name: str = None):
        """
        åˆå§‹åŒ– LLM æœåŠ¡
        
        Args:
            api_key: APIå¯†é’¥ï¼ˆå¦‚æœä¸ºNoneï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
            base_url: APIåœ°å€ï¼ˆå¦‚æœä¸ºNoneï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
            model_name: æ¨¡å‹åç§°ï¼ˆå¦‚æœä¸ºNoneï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
        """
        # ä½¿ç”¨ä¼ å…¥å‚æ•°æˆ–é…ç½®æ–‡ä»¶å€¼
        self.api_key = api_key or settings.LLM_API_KEY
        self.base_url = base_url or settings.LLM_BASE_URL
        self.model = model_name or settings.LLM_MODEL_NAME
        
        # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ (å…¼å®¹ DeepSeek)
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=self.base_url
        )
        
        logger.info(f"ğŸ•µï¸â€â™‚ï¸ LLM è¿æ¥åœ°å€: {self.base_url}")
        logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {self.model}")

    def judge_rag(self, raw_text: str, template_id: str) -> dict:
        """
        ä¸ä»…åˆ¤æ–­æ˜¯å¦éœ€è¦æœï¼Œè¿˜è¦ç”Ÿæˆâ€œæœä»€ä¹ˆâ€
        """
        logger.info("ğŸ§  LLM æ­£åœ¨åˆ†æ RAG æ„å›¾å¹¶æå–å…³é”®è¯...")
        
        # æˆ‘ä»¬æŠŠæ•´æ®µæ–‡æœ¬ä¼ è¿›å»ï¼ˆæˆ–è€…æˆªå–å‰ 2000 å­—ï¼Œå–å†³äº LLM ä¸Šä¸‹æ–‡çª—å£ï¼‰
        # è®© LLM å¿½ç•¥åºŸè¯ï¼Œæå–æ ¸å¿ƒå®ä½“
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¼šè®®ç§˜ä¹¦ã€‚è¯·åˆ†æä»¥ä¸‹ä¼šè®®è®°å½•ï¼ˆASRè¯†åˆ«æ–‡æœ¬ï¼‰ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦æ£€ç´¢å†å²çŸ¥è¯†åº“æ¥è¾…åŠ©ç”Ÿæˆçºªè¦ã€‚
        
        ã€ä¼šè®®å†…å®¹ã€‘ï¼š
        "{raw_text[:2000]}..." 
        
        ã€åˆ¤æ–­æ ‡å‡†ã€‘ï¼š
        å¦‚æœæ–‡ä¸­å‡ºç°äº†æ¨¡ç³ŠæŒ‡ä»£ï¼ˆå¦‚"ä¸Šæ¬¡è¯´çš„"ã€"é‚£ä¸ªé¡¹ç›®"ï¼‰æˆ–æåˆ°å…·ä½“çš„å†å²é—®é¢˜ã€æŠ€æœ¯åè¯ï¼Œåˆ™éœ€è¦æ£€ç´¢ã€‚
        
        è¯·ä¸¥æ ¼è¿”å› JSON æ ¼å¼ï¼š
        {{
            "need_rag": true,
            "search_query": "æå–å‡ºçš„æ ¸å¿ƒæœç´¢å…³é”®è¯ï¼Œç”¨ç©ºæ ¼åˆ†éš”ï¼Œä¸è¦åŒ…å«åºŸè¯" 
        }}
        æˆ–è€…
        {{
            "need_rag": false,
            "search_query": ""
        }}
        """

        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.1,
                    response_format={"type": "json_object"},
                    timeout=10  # è®¾ç½®è¶…æ—¶æ—¶é—´10ç§’
                )
                content = response.choices[0].message.content
                return json.loads(content)
                
            except (APITimeoutError, APIConnectionError) as e:
                if attempt < max_retries - 1:
                    logger.warning(f"âš ï¸ ç½‘ç»œæ³¢åŠ¨ï¼Œæ­£åœ¨ç¬¬ {attempt+1} æ¬¡é‡è¯• RAG åˆ†æ...")
                    time.sleep(2)  
                else:
                    logger.error(f"âŒ RAG åˆ†ææœ€ç»ˆå¤±è´¥: {e}")
            except Exception as e:
                # å…¶ä»–é”™è¯¯ï¼ˆå¦‚ä»£ç é€»è¾‘é”™ï¼‰ä¸é‡è¯•ï¼Œç›´æ¥é€€å‡º
                logger.error(f"âŒ RAG åˆ†æé€»è¾‘é”™è¯¯: {e}")
                break
        
        # å…œåº•è¿”å›
        return {"need_rag": False, "search_query": ""}
        
    def generate_markdown(
        self, 
        raw_text: str, 
        context: str = "", 
        template_id: str = "default", 
        custom_instruction: str = None  # <--- æ¥æ”¶å‚æ•°
    ) -> str:
        logger.info(f"ğŸ§  LLM æ­£åœ¨ç”Ÿæˆæ•°æ®... (æ¨¡æ¿æŒ‡ç¤ºé•¿åº¦: {len(template_id)})")
        
        # ------------------------------------------------------------------
        # 1. å¤„ç†ç”¨æˆ·æŒ‡ä»¤ (User Instruction)
        # ------------------------------------------------------------------
        user_requirement_section = ""
        if custom_instruction and custom_instruction.strip():
            user_requirement_section = f"""
### ğŸ”¥ ç”¨æˆ·ç‰¹åˆ«å¼ºè°ƒçš„è¦æ±‚ (æœ€é«˜ä¼˜å…ˆçº§)
ç”¨æˆ·å¯¹æœ¬æ¬¡ç”Ÿæˆæœ‰ä»¥ä¸‹å…·ä½“æŒ‡ç¤ºï¼Œè¯·**åŠ¡å¿…æ»¡è¶³**ï¼š
> "{custom_instruction}"
"""

        # ------------------------------------------------------------------
        # 2. å®šä¹‰æ ¸å¿ƒæŒ‡ä»¤ (System Prompt)
        # ------------------------------------------------------------------
        core_instruction = """
è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹å¡«ç©ºè§„åˆ™ï¼š
ä½ æ˜¯ä¸€åæ‹¥æœ‰10å¹´ç»éªŒçš„é«˜çº§ä¼šè®®ç§˜ä¹¦ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ã€ä¼šè®®å½•éŸ³è½¬å½•æ–‡æœ¬ã€‘ï¼Œç²¾ç¡®å¡«å……ç”¨æˆ·æä¾›çš„ã€ä¼šè®®çºªè¦æ¨¡æ¿ã€‘ã€‚

è§„åˆ™ï¼š
1. **æ ¼å¼å¼ºåˆ¶**ï¼šå¿…é¡»ä½¿ç”¨ Markdown æ ‡å‡†æ ‡é¢˜è¯­æ³• (#, ##, ###)ï¼Œä¸¥ç¦ä»…ä½¿ç”¨åŠ ç²—ã€‚
2. **æ™ºèƒ½å¡«ç©º**ï¼šæ ¹æ®å½•éŸ³å†…å®¹æå–æ—¶é—´ã€äººå‘˜ã€å†³è®®ã€‚
3. **å†…å®¹æ˜ å°„**ï¼šè‹¥å½•éŸ³ä¸­æ— å¯¹åº”å†…å®¹ï¼Œå¡«"æ— "æˆ–ç•™ç©ºï¼Œä¸å¯ç¼–é€ ã€‚
4. **è¯­æ°”é£æ ¼**ï¼šå®¢è§‚ã€ç®€ç»ƒã€ä¸“ä¸šã€‚
5. **è¾“å‡ºè¦æ±‚**ï¼šç›´æ¥è¾“å‡ºä¼šè®®çºªè¦å†…å®¹ï¼Œä¸è¦åŒ…å«æ€è€ƒè¿‡ç¨‹ã€ä¸è¦ä½¿ç”¨<think>æ ‡ç­¾ã€ä¸è¦è¾“å‡ºä»»ä½•é¢å¤–çš„HTMLæ ‡ç­¾ã€‚
"""

        # ------------------------------------------------------------------
        # 3. åŠ¨æ€æ„å»º Prompt
        # ------------------------------------------------------------------
        # åˆ¤æ–­æ˜¯æ–‡ä»¶å†…å®¹è¿˜æ˜¯ID
        is_custom_content = len(template_id) > 50 and ("\n" in template_id or "\r" in template_id)
        
        system_prompt = core_instruction
        
        if is_custom_content:
            # === æƒ…å†µ A: ç”¨æˆ·æä¾›äº† Word é‡Œçš„å…·ä½“å†…å®¹ ===
            logger.info("ğŸ“„ è¯†åˆ«åˆ°è‡ªå®šä¹‰æ¨¡æ¿å†…å®¹ï¼Œä½¿ç”¨åŠ¨æ€æç¤ºè¯æ„å»º...")
            
            user_input = f"""
è¯·æ ¹æ®ä»¥ä¸‹å½•éŸ³æ–‡æœ¬ï¼Œä¸¥æ ¼æŒ‰ç…§ã€ä¼šè®®çºªè¦æ¨¡æ¿ã€‘çš„æ ¼å¼ç”Ÿæˆå†…å®¹ã€‚

{user_requirement_section}

----------------
ã€ä¼šè®®çºªè¦æ¨¡æ¿ç»“æ„ã€‘(è¯·å®Œå…¨ç…§æ¬æ­¤ç»“æ„å¡«å……)ï¼š
{template_id}

----------------
ã€å†å²èƒŒæ™¯èµ„æ–™ (RAG)ã€‘ï¼š
{context if context else "æ— "}

----------------
ã€ä¼šè®®å½•éŸ³è½¬å½•æ–‡æœ¬ã€‘ï¼š
{raw_text}

----------------
è¯·å¼€å§‹ç”Ÿæˆï¼š
"""
        else:
            # === æƒ…å†µ B: ä¼ å…¥çš„æ˜¯ default è¿™ç§ç®€çŸ­ ID ===
            logger.info(f"ğŸ”‘ ä½¿ç”¨é¢„è®¾æ¨¡æ¿ ID: {template_id}")
            template_config = self._get_template(template_id)
            
            if "system_prompt" in template_config:
                system_prompt = template_config["system_prompt"]
            
            user_input = template_config.get("user_prompt_template", "").format(
                context=context if context else "æ— ",
                raw_text=raw_text,
                user_requirement_section=user_requirement_section 
            )

        # ------------------------------------------------------------------
        # 4. è°ƒç”¨ LLM
        # ------------------------------------------------------------------
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_input}
                ],
                temperature=0.3
            )
            content = response.choices[0].message.content
            
            # æ¸…ç†æ€è€ƒè¿‡ç¨‹
            content = remove_thinking_tags(content)
            
            usage = response.usage
            tokens = (usage.total_tokens if usage else 0)
            logger.info(f"âœ… ç”Ÿæˆå®Œæˆï¼Œæ¶ˆè€— Token: {tokens}")
            return content
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
            return f"ç”Ÿæˆå¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯: {str(e)}"

    def _get_template(self, template_id: str) -> Dict[str, str]:
        templates = {
            "default": {
                "system_prompt": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é«˜çº§ç§˜ä¹¦ï¼Œè´Ÿè´£å°†è¯­éŸ³è¯†åˆ«çš„æ–‡æœ¬æ•´ç†æˆç»“æ„æ¸…æ™°çš„ Markdown ä¼šè®®çºªè¦ã€‚",
                
                "user_prompt_template": """
è¯·æ ¹æ®ä»¥ä¸‹å†…å®¹ç”Ÿæˆä¼šè®®çºªè¦ã€‚

ã€å‚è€ƒå†å²ä¿¡æ¯ã€‘ï¼š
{context}

ã€Taskã€‘ï¼š
æ ¹æ®ä¸‹æ–¹çš„ã€Meeting Transcriptã€‘ï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„ä¼šè®®çºªè¦ã€‚

{user_requirement_section}

ã€åŸå§‹è¯­éŸ³æ–‡æœ¬ã€‘ï¼š
{raw_text}

ã€è¦æ±‚ã€‘ï¼š
1. ä½¿ç”¨ Markdown æ ¼å¼ã€‚
2. åŒ…å«æ ‡é¢˜ã€å‚ä¸äººã€å†³ç­–ç»“è®ºã€å¾…åŠäº‹é¡¹ã€‚
3. å»é™¤å£è¯­åºŸè¯ã€‚
"""
            }
        }
        return templates.get(template_id, templates["default"])
    
    def chat(self, prompt: str, temperature: float = 0.7, max_tokens: int = 2000) -> str:
        """
        ç®€å•çš„èŠå¤©æ¥å£ï¼ˆç”¨äºæ–°çš„åŠ¨æ€æ¨¡æ¿ç³»ç»Ÿï¼‰
        
        Args:
            prompt: å®Œæ•´çš„æç¤ºè¯
            temperature: ç”Ÿæˆæ¸©åº¦
            max_tokens: æœ€å¤§tokenæ•°
        
        Returns:
            æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬
        """
        logger.info("ğŸ’¬ LLM Chat è°ƒç”¨...")
        
        try:
            print("-" * 30)
            print(f"ğŸ•µï¸ [Debug] æ­£åœ¨è¯·æ±‚çš„ API åœ°å€ (Base URL): {self.client.base_url}") 
            print(f"ğŸ•µï¸ [Debug] ä½¿ç”¨çš„æ¨¡å‹åç§°: {self.model}")                           
            key_preview = str(self.client.api_key)[:8] if self.client.api_key else "None"
            print(f"ğŸ•µï¸ [Debug] ä½¿ç”¨çš„ API Key: {key_preview}...")                      
            print("-" * 30)
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            content = response.choices[0].message.content
            # æ¸…ç†æ€è€ƒè¿‡ç¨‹
            content = remove_thinking_tags(content)
            logger.info(f"âœ… LLM ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(content)}")
            return content
            
        except Exception as e:
            logger.error(f"âŒ LLM Chat è°ƒç”¨å¤±è´¥: {e}")
            raise

llm_service = LLMService()