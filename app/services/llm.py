import json
import re
import time
from typing import Dict
from openai import OpenAI, APITimeoutError, APIConnectionError
from app.core.config import settings
from app.core.logger import logger


def remove_thinking_tags(text: str) -> str:
    """
    ç§»é™¤LLMè¾“å‡ºä¸­çš„æ€è€ƒè¿‡ç¨‹æ ‡ç­¾
    æ”¯æŒå¤šç§æ ¼å¼ï¼š
    1. <think>...</think>
    2. <p>...æ€è€ƒå†…å®¹...</p>...<h3>ä¼šè®®çºªè¦</h3>
    3. HTMLåµŒå¥—çš„å„ç§å˜ä½“
    4. <p>è¯­ç§ï¼šä¸­æ–‡<br /></think></p> (è·¨è¡Œæ®‹ç•™)
    """
    if not text:
        return text
    
    original_length = len(text)
    
    # === ç­–ç•¥1: ç§»é™¤æ ‡å‡† <think> æ ‡ç­¾ï¼ˆåŒ…æ‹¬è·¨è¡Œï¼‰ ===
    text = re.sub(r'<think>[\s\S]*?</think>', '', text, flags=re.IGNORECASE)
    
    # === ç­–ç•¥2: ç§»é™¤æ®‹ç•™çš„ </think> æ ‡ç­¾åŠå…¶æ‰€åœ¨çš„æ®µè½ ===
    # åŒ¹é…åŒ…å« </think> çš„æ•´ä¸ª <p> æ ‡ç­¾ï¼ˆåŒ…æ‹¬è·¨è¡Œã€åŒ…å« <br />ï¼‰
    text = re.sub(r'<p>[\s\S]*?</think>[\s\S]*?</p>', '', text, flags=re.IGNORECASE)
    
    # === ç­–ç•¥3: ç§»é™¤å¼€å¤´çš„æ€è€ƒå†…å®¹ - ä»å¼€å¤´åˆ°ç¬¬ä¸€ä¸ª Markdown æ ‡é¢˜ ===
    # æ£€æµ‹æ˜¯å¦ä»¥ <p> æˆ–ç©ºç™½å¼€å¤´ï¼Œä¸”åé¢æœ‰ Markdown æ ‡é¢˜ï¼ˆ###ã€##ã€#ï¼‰
    if re.search(r'^[\s\S]*?#{1,3}\s', text):
        # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªæ ‡é¢˜çš„ä½ç½®
        match = re.search(r'#{1,3}\s', text)
        if match:
            # æ£€æŸ¥æ ‡é¢˜ä¹‹å‰çš„å†…å®¹æ˜¯å¦åŒ…å«æ€è€ƒå…³é”®è¯
            before_title = text[:match.start()]
            thinking_indicators = ['è¯­ç§', 'å¥½çš„', 'é¦–å…ˆ', 'æ¥ä¸‹æ¥', 'éœ€è¦', 'æ€è€ƒ', '<p>', '</think>']
            if any(indicator in before_title for indicator in thinking_indicators):
                text = text[match.start():]
                logger.info("ğŸ§¹ æ£€æµ‹åˆ°å¼€å¤´çš„æ€è€ƒå†…å®¹ï¼Œå·²ç§»é™¤")
    
    # === ç­–ç•¥4: ç§»é™¤åŒ…å«æ€è€ƒå…³é”®è¯çš„ <p> æ®µè½ ===
    thinking_patterns = [
        r'<p>[\s\S]*?è¯­ç§[\s\S]*?</p>',  # è¯­ç§æ ‡è¯†
        r'<p>[\s\S]*?å¥½çš„ï¼Œæˆ‘.*?</p>',
        r'<p>[\s\S]*?é¦–å…ˆ.*?</p>',
        r'<p>[\s\S]*?æ¥ä¸‹æ¥.*?</p>',
        r'<p>[\s\S]*?éœ€è¦æ³¨æ„.*?</p>',
        r'<p>[\s\S]*?æœ€åï¼Œéœ€è¦.*?</p>',
    ]
    for pattern in thinking_patterns:
        text = re.sub(pattern, '', text, flags=re.IGNORECASE)
    
    # === æ¸…ç†æ®‹ç•™ ===
    # ç§»é™¤ç©ºçš„ <p> æ ‡ç­¾
    text = re.sub(r'<p>\s*</p>', '', text)
    
    # ç§»é™¤å¼€å¤´çš„æ— ç”¨æ ‡ç­¾å’Œç©ºç™½
    text = re.sub(r'^[\s"<>/\n]*', '', text)
    
    # ç§»é™¤å¤šä½™çš„ç©ºç™½è¡Œ
    text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)
    
    # å»é™¤å¼€å¤´å’Œç»“å°¾çš„ç©ºç™½å’Œå¼•å·
    text = text.strip().strip('"').strip()
    
    removed_chars = original_length - len(text)
    if removed_chars > 0:
        logger.info(f"ğŸ§¹ å·²æ¸…ç†æ€è€ƒå†…å®¹: ç§»é™¤ {removed_chars} å­—ç¬¦")
    
    return text


def add_highlighting(text: str) -> str:
    """
    å¢å¼ºç‰ˆé«˜äº®å‡½æ•°
    """
    if not text:
        return text

    # å®šä¹‰æ ·å¼
    STYLES = {
        "person": 'style="background-color: #dbeafe; color: #1e40af; padding: 0 2px; border-radius: 3px;"',
        "date": 'style="background-color: #dcfce7; color: #166534; padding: 0 2px; border-radius: 3px;"',
        "uncertain": 'style="background-color: #fee2e2; color: #991b1b; text-decoration: underline dashed;"',
        "project": 'style="background-color: #f3e8ff; color: #6b21a8; font-weight: 500;"'
    }

    # === 1. äººåä¼˜åŒ– ===
    # 1.1 åŒ¹é… Markdown åŠ ç²—/Strong/å¼•å· (ä¿ç•™åŸé€»è¾‘)
    text = re.sub(r'["â€œ]([ä¸€-é¾¥]{1,4})["â€]', f'<mark {STYLES["person"]}>\\1</mark>', text) # å¢åŠ äº†ä¸­æ–‡å¼•å·æ”¯æŒ
    text = re.sub(r'<strong>([ä¸€-é¾¥]{1,10})</strong>', f'<mark {STYLES["person"]}>\\1</mark>', text)
    text = re.sub(r'\*\*([ä¸€-é¾¥]{1,10})\*\*', f'<mark {STYLES["person"]}>\\1</mark>', text)
    
    # 1.2 [æ–°å¢] åŒ¹é… "å§“+ç§°è°“" (ç®€å•ç‰ˆNER)
    # é¿å…åŒ¹é…åˆ° "æ€»å…±" é‡Œçš„ "æ€»"ï¼Œè¦æ±‚å‰é¢æ˜¯äººåå¸¸è§çš„å­—
    text = re.sub(
        r'([å¼ ç‹æèµµåˆ˜é™ˆæ¨é»„å´å‘¨å¾å­™é©¬æœ±èƒ¡æ—éƒ­ä½•é«˜ç½—][ä¸€-é¾¥]{0,2})(ç»ç†|æ€»|è€å¸ˆ|å·¥|è‘£|æ€»ç›‘|ç»„é•¿)',
        f'<mark {STYLES["person"]}>\\1\\2</mark>',
        text
    )

    # === 2. é¡¹ç›®åä¼˜åŒ– ===
    project_patterns = [
        # 2.1 è‹±æ–‡å¤§å†™ (æ’é™¤å¸¸ç”¨éé¡¹ç›®è¯)
        (r'\b(?!(?:ID|OK|NO|Yes|HI|BYE|TODO|PPT|PDF|WORD|EXCEL|CEO|CTO|CFO|HR|KPI)\b)([A-Z]{2,10})\b', 
         f'<mark {STYLES["project"]}>\\1</mark>'),
        
        # 2.2 ä¸­æ–‡é¡¹ç›®å (æ”¶ç´§åŒ¹é…èŒƒå›´ï¼Œæ’é™¤ "çš„" "äº†" "æ˜¯" ç­‰å¼€å¤´)
        # {2,12} é™åˆ¶é•¿åº¦ï¼Œ[^...] æ’é™¤å¸¸ç”¨è™šè¯å¼€å¤´
        (r'(?<![ä¸€-é¾¥])([a-zA-Z0-9\u4e00-\u9fa5]{2,12}(?:é¡¹ç›®|äº§å“|ç³»ç»Ÿ|å¹³å°|å·¥å…·|æœåŠ¡|è®¡åˆ’|æ–¹æ¡ˆ|ä¸­å°|å¤§è„‘))', 
         f'<mark {STYLES["project"]}>\\1</mark>'),
    ]
    for pattern, replacement in project_patterns:
        text = re.sub(pattern, replacement, text)

    # === 3. æ—¥æœŸ (ä¿ç•™åŸé€»è¾‘ï¼Œæ•ˆæœå·²ç»ä¸é”™) ===
    date_patterns = [
        (r'(å‘¨[ä¸€äºŒä¸‰å››äº”å…­æ—¥å¤©])', f'<mark {STYLES["date"]}>\\1</mark>'),
        (r'(ä»Šå¤©|æ˜å¤©|åå¤©|æ˜¨å¤©|å‰å¤©)', f'<mark {STYLES["date"]}>\\1</mark>'),
        (r'(æœ¬å‘¨|ä¸‹å‘¨|ä¸Šå‘¨|è¿™å‘¨|ä¸Šä¸Šå‘¨)', f'<mark {STYLES["date"]}>\\1</mark>'),
        (r'(æœ¬æœˆ|ä¸‹æœˆ|ä¸Šæœˆ|è¿™ä¸ªæœˆ)', f'<mark {STYLES["date"]}>\\1</mark>'),
        (r'(\d{1,2}æœˆ\d{1,2}æ—¥)', f'<mark {STYLES["date"]}>\\1</mark>'),
        (r'(\d{4}[-/]\d{1,2}[-/]\d{1,2})', f'<mark {STYLES["date"]}>\\1</mark>'),
        (r'(\d{1,2}:\d{2})', f'<mark {STYLES["date"]}>\\1</mark>'), # æ–°å¢ï¼šæ”¯æŒ 14:00 è¿™ç§æ—¶é—´
    ]
    for pattern, replacement in date_patterns:
        text = re.sub(pattern, replacement, text)

    # === 4. å­˜ç–‘ (ä¿ç•™åŸé€»è¾‘) ===
    uncertain_patterns = [
        (r'(?:ã€|\[)å­˜ç–‘[ï¼š:]\s*([^ã€‘\]]+)(?:ã€‘|\])', f'<mark {STYLES["uncertain"]}>\\1</mark>'),
    ]
    for pattern, replacement in uncertain_patterns:
        text = re.sub(pattern, replacement, text)

    return text

class LLMService:
    def __init__(self, api_key: str = None, base_url: str = None, model_name: str = None):
        """
        åˆå§‹åŒ– LLM æœåŠ¡
        
        Args:
            api_key: APIå¯†é’¥ï¼ˆå¦‚æœä¸ºNoneï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
            base_url: APIåœ°å€ï¼ˆå¦‚æœä¸ºNoneï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
            model_name: æ¨¡å‹åç§°ï¼ˆå¦‚æœä¸ºNoneï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
        """
        # ä½¿ç”¨ä¼ å…¥å‚æ•°æˆ–é…ç½®æ–‡ä»¶å€¼
        self.api_key = api_key or settings.LLM_API_KEY
        self.base_url = base_url or settings.LLM_BASE_URL
        self.model = model_name or settings.LLM_MODEL_NAME
        
        # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ (å…¼å®¹ DeepSeek)
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=self.base_url
        )
        
        logger.info(f"ğŸ•µï¸â€â™‚ï¸ LLM è¿æ¥åœ°å€: {self.base_url}")
        logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {self.model}")

    def judge_rag(self, raw_text: str, template_id: str) -> dict:
        """
        ä¸ä»…åˆ¤æ–­æ˜¯å¦éœ€è¦æœï¼Œè¿˜è¦ç”Ÿæˆâ€œæœä»€ä¹ˆâ€
        """
        logger.info("ğŸ§  LLM æ­£åœ¨åˆ†æ RAG æ„å›¾å¹¶æå–å…³é”®è¯...")
        
        # æˆ‘ä»¬æŠŠæ•´æ®µæ–‡æœ¬ä¼ è¿›å»ï¼ˆæˆ–è€…æˆªå–å‰ 2000 å­—ï¼Œå–å†³äº LLM ä¸Šä¸‹æ–‡çª—å£ï¼‰
        # è®© LLM å¿½ç•¥åºŸè¯ï¼Œæå–æ ¸å¿ƒå®ä½“
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¼šè®®ç§˜ä¹¦ã€‚è¯·åˆ†æä»¥ä¸‹ä¼šè®®è®°å½•ï¼ˆASRè¯†åˆ«æ–‡æœ¬ï¼‰ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦æ£€ç´¢å†å²çŸ¥è¯†åº“æ¥è¾…åŠ©ç”Ÿæˆçºªè¦ã€‚
        
        ã€ä¼šè®®å†…å®¹ã€‘ï¼š
        "{raw_text[:2000]}..." 
        
        ã€åˆ¤æ–­æ ‡å‡†ã€‘ï¼š
        å¦‚æœæ–‡ä¸­å‡ºç°äº†æ¨¡ç³ŠæŒ‡ä»£ï¼ˆå¦‚"ä¸Šæ¬¡è¯´çš„"ã€"é‚£ä¸ªé¡¹ç›®"ï¼‰æˆ–æåˆ°å…·ä½“çš„å†å²é—®é¢˜ã€æŠ€æœ¯åè¯ï¼Œåˆ™éœ€è¦æ£€ç´¢ã€‚
        
        è¯·ä¸¥æ ¼è¿”å› JSON æ ¼å¼ï¼š
        {{
            "need_rag": true,
            "search_query": "æå–å‡ºçš„æ ¸å¿ƒæœç´¢å…³é”®è¯ï¼Œç”¨ç©ºæ ¼åˆ†éš”ï¼Œä¸è¦åŒ…å«åºŸè¯" 
        }}
        æˆ–è€…
        {{
            "need_rag": false,
            "search_query": ""
        }}
        """

        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.1,
                    response_format={"type": "json_object"},
                    timeout=10  # è®¾ç½®è¶…æ—¶æ—¶é—´10ç§’
                )
                content = response.choices[0].message.content
                return json.loads(content)
                
            except (APITimeoutError, APIConnectionError) as e:
                if attempt < max_retries - 1:
                    logger.warning(f"âš ï¸ ç½‘ç»œæ³¢åŠ¨ï¼Œæ­£åœ¨ç¬¬ {attempt+1} æ¬¡é‡è¯• RAG åˆ†æ...")
                    time.sleep(2)  
                else:
                    logger.error(f"âŒ RAG åˆ†ææœ€ç»ˆå¤±è´¥: {e}")
            except Exception as e:
                # å…¶ä»–é”™è¯¯ï¼ˆå¦‚ä»£ç é€»è¾‘é”™ï¼‰ä¸é‡è¯•ï¼Œç›´æ¥é€€å‡º
                logger.error(f"âŒ RAG åˆ†æé€»è¾‘é”™è¯¯: {e}")
                break
        
        # å…œåº•è¿”å›
        return {"need_rag": False, "search_query": ""}
        
    def generate_markdown(
        self, 
        raw_text: str, 
        context: str = "", 
        template_id: str = "default", 
        custom_instruction: str = None  # <--- æ¥æ”¶å‚æ•°
    ) -> str:
        logger.info(f"ğŸ§  LLM æ­£åœ¨ç”Ÿæˆæ•°æ®... (æ¨¡æ¿æŒ‡ç¤ºé•¿åº¦: {len(template_id)})")
        
        # ------------------------------------------------------------------
        # 1. å¤„ç†ç”¨æˆ·æŒ‡ä»¤ (User Instruction)
        # ------------------------------------------------------------------
        user_requirement_section = ""
        if custom_instruction and custom_instruction.strip():
            user_requirement_section = f"""
### ğŸ”¥ ç”¨æˆ·ç‰¹åˆ«å¼ºè°ƒçš„è¦æ±‚ (æœ€é«˜ä¼˜å…ˆçº§)
ç”¨æˆ·å¯¹æœ¬æ¬¡ç”Ÿæˆæœ‰ä»¥ä¸‹å…·ä½“æŒ‡ç¤ºï¼Œè¯·**åŠ¡å¿…æ»¡è¶³**ï¼š
> "{custom_instruction}"
"""

        # ------------------------------------------------------------------
        # 2. å®šä¹‰æ ¸å¿ƒæŒ‡ä»¤ (System Prompt)
        # ------------------------------------------------------------------
        core_instruction = """
è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹å¡«ç©ºè§„åˆ™ï¼š
ä½ æ˜¯ä¸€åæ‹¥æœ‰10å¹´ç»éªŒçš„é«˜çº§ä¼šè®®ç§˜ä¹¦ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ã€ä¼šè®®å½•éŸ³è½¬å½•æ–‡æœ¬ã€‘ï¼Œç²¾ç¡®å¡«å……ç”¨æˆ·æä¾›çš„ã€ä¼šè®®çºªè¦æ¨¡æ¿ã€‘ã€‚

è§„åˆ™ï¼š
1. **æ ¼å¼å¼ºåˆ¶**ï¼šå¿…é¡»ä½¿ç”¨ Markdown æ ‡å‡†æ ‡é¢˜è¯­æ³• (#, ##, ###)ï¼Œä¸¥ç¦ä»…ä½¿ç”¨åŠ ç²—ã€‚
2. **æ™ºèƒ½å¡«ç©º**ï¼šæ ¹æ®å½•éŸ³å†…å®¹æå–æ—¶é—´ã€äººå‘˜ã€å†³è®®ã€‚
3. **å†…å®¹æ˜ å°„**ï¼šè‹¥å½•éŸ³ä¸­æ— å¯¹åº”å†…å®¹ï¼Œå¡«"æ— "æˆ–ç•™ç©ºï¼Œä¸å¯ç¼–é€ ã€‚
4. **è¯­æ°”é£æ ¼**ï¼šå®¢è§‚ã€ç®€ç»ƒã€ä¸“ä¸šã€‚
5. **è¾“å‡ºè¦æ±‚**ï¼šç›´æ¥è¾“å‡ºä¼šè®®çºªè¦å†…å®¹ï¼Œä¸è¦åŒ…å«æ€è€ƒè¿‡ç¨‹ã€ä¸è¦ä½¿ç”¨<think>æ ‡ç­¾ã€ä¸è¦è¾“å‡ºä»»ä½•é¢å¤–çš„HTMLæ ‡ç­¾ã€‚
"""

        # ------------------------------------------------------------------
        # 3. åŠ¨æ€æ„å»º Prompt
        # ------------------------------------------------------------------
        # åˆ¤æ–­æ˜¯æ–‡ä»¶å†…å®¹è¿˜æ˜¯ID
        is_custom_content = len(template_id) > 50 and ("\n" in template_id or "\r" in template_id)
        
        system_prompt = core_instruction
        
        if is_custom_content:
            # === æƒ…å†µ A: ç”¨æˆ·æä¾›äº† Word é‡Œçš„å…·ä½“å†…å®¹ ===
            logger.info("ğŸ“„ è¯†åˆ«åˆ°è‡ªå®šä¹‰æ¨¡æ¿å†…å®¹ï¼Œä½¿ç”¨åŠ¨æ€æç¤ºè¯æ„å»º...")
            
            user_input = f"""
è¯·æ ¹æ®ä»¥ä¸‹å½•éŸ³æ–‡æœ¬ï¼Œä¸¥æ ¼æŒ‰ç…§ã€ä¼šè®®çºªè¦æ¨¡æ¿ã€‘çš„æ ¼å¼ç”Ÿæˆå†…å®¹ã€‚

{user_requirement_section}

----------------
ã€ä¼šè®®çºªè¦æ¨¡æ¿ç»“æ„ã€‘(è¯·å®Œå…¨ç…§æ¬æ­¤ç»“æ„å¡«å……)ï¼š
{template_id}

----------------
ã€å†å²èƒŒæ™¯èµ„æ–™ (RAG)ã€‘ï¼š
{context if context else "æ— "}

----------------
ã€ä¼šè®®å½•éŸ³è½¬å½•æ–‡æœ¬ã€‘ï¼š
{raw_text}

----------------
è¯·å¼€å§‹ç”Ÿæˆï¼š
"""
        else:
            # === æƒ…å†µ B: ä¼ å…¥çš„æ˜¯ default è¿™ç§ç®€çŸ­ ID ===
            logger.info(f"ğŸ”‘ ä½¿ç”¨é¢„è®¾æ¨¡æ¿ ID: {template_id}")
            template_config = self._get_template(template_id)
            
            if "system_prompt" in template_config:
                system_prompt = template_config["system_prompt"]
            
            user_input = template_config.get("user_prompt_template", "").format(
                context=context if context else "æ— ",
                raw_text=raw_text,
                user_requirement_section=user_requirement_section 
            )

        # ------------------------------------------------------------------
        # 4. è°ƒç”¨ LLM
        # ------------------------------------------------------------------
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_input}
                ],
                temperature=0.3
            )
            content = response.choices[0].message.content
            
            # æ¸…ç†æ€è€ƒè¿‡ç¨‹
            content = remove_thinking_tags(content)
            
            # æ·»åŠ é«˜äº®æ ‡è®°
            content = add_highlighting(content)
            
            usage = response.usage
            tokens = (usage.total_tokens if usage else 0)
            logger.info(f"âœ… ç”Ÿæˆå®Œæˆï¼Œæ¶ˆè€— Token: {tokens}")
            return content
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
            return f"ç”Ÿæˆå¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯: {str(e)}"

    def _get_template(self, template_id: str) -> Dict[str, str]:
        templates = {
            "default": {
                "system_prompt": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é«˜çº§ç§˜ä¹¦ï¼Œè´Ÿè´£å°†è¯­éŸ³è¯†åˆ«çš„æ–‡æœ¬æ•´ç†æˆç»“æ„æ¸…æ™°çš„ Markdown ä¼šè®®çºªè¦ã€‚",
                
                "user_prompt_template": """
è¯·æ ¹æ®ä»¥ä¸‹å†…å®¹ç”Ÿæˆä¼šè®®çºªè¦ã€‚

ã€å‚è€ƒå†å²ä¿¡æ¯ã€‘ï¼š
{context}

ã€Taskã€‘ï¼š
æ ¹æ®ä¸‹æ–¹çš„ã€Meeting Transcriptã€‘ï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„ä¼šè®®çºªè¦ã€‚

{user_requirement_section}

ã€åŸå§‹è¯­éŸ³æ–‡æœ¬ã€‘ï¼š
{raw_text}

ã€è¦æ±‚ã€‘ï¼š
1. ä½¿ç”¨ Markdown æ ¼å¼ã€‚
2. åŒ…å«æ ‡é¢˜ã€å‚ä¸äººã€å†³ç­–ç»“è®ºã€å¾…åŠäº‹é¡¹ã€‚
3. å»é™¤å£è¯­åºŸè¯ã€‚
"""
            }
        }
        return templates.get(template_id, templates["default"])
    
    def chat(self, prompt: str, temperature: float = 0.7, max_tokens: int = 2000) -> str:
        """
        ç®€å•çš„èŠå¤©æ¥å£ï¼ˆç”¨äºæ–°çš„åŠ¨æ€æ¨¡æ¿ç³»ç»Ÿï¼‰
        
        Args:
            prompt: å®Œæ•´çš„æç¤ºè¯
            temperature: ç”Ÿæˆæ¸©åº¦
            max_tokens: æœ€å¤§tokenæ•°
        
        Returns:
            æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬
        """
        logger.info("ğŸ’¬ LLM Chat è°ƒç”¨...")
        
        try:
            print("-" * 30)
            print(f"ğŸ•µï¸ [Debug] æ­£åœ¨è¯·æ±‚çš„ API åœ°å€ (Base URL): {self.client.base_url}") 
            print(f"ğŸ•µï¸ [Debug] ä½¿ç”¨çš„æ¨¡å‹åç§°: {self.model}")                           
            key_preview = str(self.client.api_key)[:8] if self.client.api_key else "None"
            print(f"ğŸ•µï¸ [Debug] ä½¿ç”¨çš„ API Key: {key_preview}...")                      
            print("-" * 30)
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            content = response.choices[0].message.content
            
            # æ¸…ç†æ€è€ƒè¿‡ç¨‹
            content = remove_thinking_tags(content)
            
            # æ·»åŠ é«˜äº®æ ‡è®°
            content = add_highlighting(content)
            
            logger.info(f"âœ… LLM ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(content)}")
            return content
            
        except Exception as e:
            logger.error(f"âŒ LLM Chat è°ƒç”¨å¤±è´¥: {e}")
            raise

llm_service = LLMService()