"""
å†å²ä¼šè®®å¤„ç†æœåŠ¡
æ”¯æŒæ£€ç´¢æ¨¡å¼å’Œæ€»ç»“æ¨¡å¼ä¸¤ç§å¤„ç†æ–¹å¼
"""
import asyncio
from typing import List, Dict, Optional, Any
from app.core.logger import logger
from app.services.vector import vector_service
from app.services.llm_factory import get_llm_service_by_name


class MeetingHistoryService:
    """å†å²ä¼šè®®å¤„ç†æœåŠ¡"""
    
    @staticmethod
    def determine_mode(
        meeting_ids: List[str],
        user_requirement: Optional[str],
        history_mode: str = "auto",
        threshold: int = 5
    ) -> str:
        """
        åˆ¤æ–­å†å²ä¼šè®®å¤„ç†æ¨¡å¼
        
        Args:
            meeting_ids: ä¼šè®®IDåˆ—è¡¨
            user_requirement: ç”¨æˆ·éœ€æ±‚
            history_mode: ç”¨æˆ·æŒ‡å®šçš„æ¨¡å¼ï¼ˆauto/retrieval/summaryï¼‰
            threshold: æ£€ç´¢æ¨¡å¼çš„ä¼šè®®æ•°é‡é˜ˆå€¼
        
        Returns:
            æ¨¡å¼åç§°ï¼ˆretrieval/summaryï¼‰
        """
        # ç”¨æˆ·æ‰‹åŠ¨æŒ‡å®š
        if history_mode in ["retrieval", "summary"]:
            logger.info(f"ğŸ¯ ç”¨æˆ·æŒ‡å®šæ¨¡å¼: {history_mode}")
            return history_mode
        
        # è‡ªåŠ¨åˆ¤æ–­
        meeting_count = len(meeting_ids)
        has_requirement = user_requirement and len(user_requirement.strip()) > 10
        
        # åœºæ™¯1ï¼šä¼šè®®å°‘ + æœ‰éœ€æ±‚ â†’ æ£€ç´¢æ¨¡å¼ï¼ˆç²¾ç¡®ï¼‰
        if meeting_count <= threshold and has_requirement:
            logger.info(
                f"ğŸ” è‡ªåŠ¨é€‰æ‹©æ£€ç´¢æ¨¡å¼ "
                f"(ä¼šè®®æ•°: {meeting_count}, æœ‰éœ€æ±‚: {has_requirement})"
            )
            return "retrieval"
        
        # åœºæ™¯2ï¼šä¼šè®®å¤š æˆ– æ— éœ€æ±‚ â†’ æ€»ç»“æ¨¡å¼ï¼ˆå®è§‚ï¼‰
        logger.info(
            f"ğŸ“ è‡ªåŠ¨é€‰æ‹©æ€»ç»“æ¨¡å¼ "
            f"(ä¼šè®®æ•°: {meeting_count}, æœ‰éœ€æ±‚: {has_requirement})"
        )
        return "summary"
    
    @staticmethod
    async def process_by_retrieval(
        meeting_ids: List[str],
        user_requirement: Optional[str],
        current_transcript: str,
        top_k: int = 10,
        llm_model: str = "auto"
    ) -> Dict[str, Any]:
        """
        æ£€ç´¢æ¨¡å¼ï¼šä»å†å²ä¼šè®®ä¸­ç²¾ç¡®æ£€ç´¢ç›¸å…³ä¿¡æ¯
        
        é€‚ç”¨åœºæ™¯ï¼šä¼šè®®æ•°é‡å°‘ï¼ˆ<= 5ï¼‰ä¸”æœ‰æ˜ç¡®éœ€æ±‚
        
        Args:
            meeting_ids: å†å²ä¼šè®®IDåˆ—è¡¨
            user_requirement: ç”¨æˆ·éœ€æ±‚
            current_transcript: å½“å‰ä¼šè®®è½¬å½•
            top_k: æ£€ç´¢æ•°é‡
            llm_model: LLMæ¨¡å‹åç§°
        
        Returns:
            {
                "mode": "retrieval",
                "relevant_segments": [...],
                "summary": "...",
                "meeting_count": N
            }
        """
        logger.info(f"ğŸ” æ£€ç´¢æ¨¡å¼: ä» {len(meeting_ids)} ä¸ªä¼šè®®ä¸­æ£€ç´¢ç›¸å…³å†…å®¹")
        
        if not vector_service or not vector_service.is_available():
            logger.warning("âš ï¸ å‘é‡æœåŠ¡ä¸å¯ç”¨ï¼Œè¿”å›ç©ºç»“æœ")
            return {
                "mode": "retrieval",
                "relevant_segments": [],
                "summary": "å‘é‡æœåŠ¡ä¸å¯ç”¨",
                "meeting_count": len(meeting_ids)
            }
        
        # æ„å»ºæ£€ç´¢æŸ¥è¯¢
        # ä¼˜å…ˆä½¿ç”¨ user_requirementï¼Œå¦åˆ™ä½¿ç”¨å½“å‰ä¼šè®®çš„å…³é”®å†…å®¹
        query = user_requirement if user_requirement else current_transcript[:500]
        
        # ä»å‘é‡åº“æ£€ç´¢ï¼ˆå¸¦è¿‡æ»¤ï¼‰
        try:
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å‘é‡æœåŠ¡æ”¯æŒ filters å‚æ•°
            # å¦‚æœä½ çš„ vector_service ä¸æ”¯æŒï¼Œéœ€è¦ä¿®æ”¹ search_similar æ–¹æ³•
            search_results = await MeetingHistoryService._search_with_filter(
                query=query,
                meeting_ids=meeting_ids,
                top_k=top_k
            )
            
            if not search_results:
                return {
                    "mode": "retrieval",
                    "relevant_segments": [],
                    "summary": "æœªåœ¨å†å²ä¼šè®®ä¸­æ‰¾åˆ°ç›¸å…³å†…å®¹",
                    "meeting_count": len(meeting_ids)
                }
            
            # æ„å»ºç›¸å…³ç‰‡æ®µåˆ—è¡¨
            relevant_segments = [
                {
                    "meeting_id": result.get("metadata", {}).get("meeting_id", "æœªçŸ¥"),
                    "text": result.get("text", ""),
                    "speaker": result.get("metadata", {}).get("speaker", "æœªçŸ¥"),
                    "timestamp": result.get("metadata", {}).get("timestamp", ""),
                    "relevance_score": result.get("score", 0.0)
                }
                for result in search_results
            ]
            
            # ç”¨ LLM ç”Ÿæˆç®€è¦æ€»ç»“
            segments_text = "\n\n".join([
                f"[{seg['meeting_id']} - {seg['speaker']} - {seg['timestamp']}]\n"
                f"{seg['text']}"
                for seg in relevant_segments
            ])
            
            llm_service = get_llm_service_by_name(llm_model)
            
            prompt = f"""
ä»¥ä¸‹æ˜¯ä» {len(meeting_ids)} ä¸ªå†å²ä¼šè®®ä¸­æ£€ç´¢åˆ°çš„ç›¸å…³ç‰‡æ®µï¼š

{segments_text}

è¯·ç”Ÿæˆä¸€ä»½ç®€è¦æ€»ç»“ï¼ˆ150å­—ä»¥å†…ï¼‰ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚
"""
            
            summary = await asyncio.to_thread(llm_service.chat, prompt)
            
            return {
                "mode": "retrieval",
                "relevant_segments": relevant_segments,
                "summary": summary,
                "meeting_count": len(meeting_ids)
            }
            
        except Exception as e:
            logger.error(f"âŒ æ£€ç´¢æ¨¡å¼å¤„ç†å¤±è´¥: {e}")
            return {
                "mode": "retrieval",
                "relevant_segments": [],
                "summary": f"æ£€ç´¢å¤±è´¥: {str(e)}",
                "meeting_count": len(meeting_ids)
            }
    
    @staticmethod
    async def process_by_summary(
        meeting_ids: List[str],
        user_requirement: Optional[str],
        llm_model: str = "auto"
    ) -> Dict[str, Any]:
        """
        æ€»ç»“æ¨¡å¼ï¼šå¯¹å¤§é‡å†å²ä¼šè®®è¿›è¡Œåˆ†å—æ€»ç»“ï¼ˆMap-Reduceï¼‰
        
        é€‚ç”¨åœºæ™¯ï¼šä¼šè®®æ•°é‡å¤šï¼ˆ> 5ï¼‰æˆ–æ— æ˜ç¡®éœ€æ±‚
        
        Args:
            meeting_ids: å†å²ä¼šè®®IDåˆ—è¡¨
            user_requirement: ç”¨æˆ·éœ€æ±‚
            llm_model: LLMæ¨¡å‹åç§°
        
        Returns:
            {
                "mode": "summary",
                "meeting_summaries": [...],
                "overall_summary": "...",
                "key_themes": [...],
                "processed_count": N,
                "total_count": N
            }
        """
        logger.info(f"ğŸ“ æ€»ç»“æ¨¡å¼: å¯¹ {len(meeting_ids)} ä¸ªä¼šè®®è¿›è¡Œåˆ†å—æ€»ç»“")
        
        llm_service = get_llm_service_by_name(llm_model)
        
        # === Map é˜¶æ®µï¼šå¹¶è¡Œç”Ÿæˆå•ä¼šè®®æ‘˜è¦ ===
        async def summarize_single_meeting(meeting_id: str) -> Dict[str, Any]:
            """æ€»ç»“å•ä¸ªä¼šè®®"""
            try:
                # ä»å‘é‡åº“è·å–ä¼šè®®å†…å®¹
                meeting_content = await MeetingHistoryService._get_meeting_content(
                    meeting_id
                )
                
                if not meeting_content:
                    return {
                        "meeting_id": meeting_id,
                        "summary": "æ— æ³•è·å–ä¼šè®®å†…å®¹",
                        "status": "failed"
                    }
                
                prompt = f"""
è¯·æ€»ç»“ä»¥ä¸‹ä¼šè®®çš„å…³é”®ä¿¡æ¯ï¼ˆ150å­—ä»¥å†…ï¼‰ï¼š

ã€ä¼šè®®å†…å®¹ã€‘
{meeting_content}

è¦æ±‚ï¼š
1. ä¸»è¦è®¨è®ºè®®é¢˜
2. é‡è¦å†³ç­–å’Œè¡ŒåŠ¨é¡¹
3. å…³é”®å‚ä¸äººå‘˜çš„è§‚ç‚¹
"""
                
                summary = await asyncio.to_thread(llm_service.chat, prompt)
                
                return {
                    "meeting_id": meeting_id,
                    "summary": summary,
                    "status": "success"
                }
            except Exception as e:
                logger.error(f"âŒ æ€»ç»“ä¼šè®® {meeting_id} å¤±è´¥: {str(e)}")
                return {
                    "meeting_id": meeting_id,
                    "summary": f"æ€»ç»“å¤±è´¥: {str(e)}",
                    "status": "failed"
                }
        
        # å¹¶è¡Œå¤„ç†æ‰€æœ‰ä¼šè®®ï¼ˆæé€Ÿï¼‰
        meeting_summaries = await asyncio.gather(*[
            summarize_single_meeting(mid) for mid in meeting_ids
        ])
        
        # è¿‡æ»¤æˆåŠŸçš„æ‘˜è¦
        successful_summaries = [
            s for s in meeting_summaries 
            if s["status"] == "success"
        ]
        
        if not successful_summaries:
            return {
                "mode": "summary",
                "meeting_summaries": [],
                "overall_summary": "æ— æ³•ç”Ÿæˆæ€»ç»“ï¼šæ‰€æœ‰ä¼šè®®å¤„ç†å¤±è´¥",
                "key_themes": [],
                "processed_count": 0,
                "total_count": len(meeting_ids)
            }
        
        # === Reduce é˜¶æ®µï¼šæ±‡æ€»ç”Ÿæˆæ•´ä½“æ€»ç»“ ===
        combined_text = "\n\n---\n\n".join([
            f"ã€ä¼šè®® {i+1}: {s['meeting_id']}ã€‘\n{s['summary']}"
            for i, s in enumerate(successful_summaries)
        ])
        
        # æ ¹æ®æ˜¯å¦æœ‰ç”¨æˆ·éœ€æ±‚ï¼Œè°ƒæ•´ prompt
        if user_requirement:
            final_prompt = f"""
åŸºäºä»¥ä¸‹ {len(successful_summaries)} ä¸ªå†å²ä¼šè®®çš„æ‘˜è¦ï¼Œç»“åˆç”¨æˆ·éœ€æ±‚ç”Ÿæˆç»¼åˆæ€»ç»“ã€‚

ã€å†å²ä¼šè®®æ‘˜è¦ã€‘
{combined_text}

ã€ç”¨æˆ·éœ€æ±‚ã€‘
{user_requirement}

è¦æ±‚ï¼š
1. é‡ç‚¹å…³æ³¨ä¸ç”¨æˆ·éœ€æ±‚ç›¸å…³çš„å†…å®¹
2. æ€»ç»“è·¨ä¼šè®®çš„ä¸»è¦ä¸»é¢˜å’Œè¶‹åŠ¿
3. æå–å…³é”®å†³ç­–å’Œè¡ŒåŠ¨é¡¹
4. æ§åˆ¶åœ¨ 300 å­—ä»¥å†…
"""
        else:
            final_prompt = f"""
åŸºäºä»¥ä¸‹ {len(successful_summaries)} ä¸ªå†å²ä¼šè®®çš„æ‘˜è¦ï¼Œç”Ÿæˆç»¼åˆæ€»ç»“ã€‚

ã€å†å²ä¼šè®®æ‘˜è¦ã€‘
{combined_text}

è¦æ±‚ï¼š
1. æ€»ç»“æ•´ä½“è®¨è®ºçš„ä¸»è¦ä¸»é¢˜ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰
2. æå–è·¨ä¼šè®®çš„å…³é”®å†³ç­–å’Œè¡ŒåŠ¨é¡¹
3. è¯†åˆ«é‡å¤è®¨è®ºçš„è®®é¢˜å’Œè¶‹åŠ¿
4. æ§åˆ¶åœ¨ 300 å­—ä»¥å†…
"""
        
        overall_summary = await asyncio.to_thread(llm_service.chat, final_prompt)
        
        # æå–ä¸»è¦ä¸»é¢˜
        key_themes = await MeetingHistoryService._extract_key_themes(
            successful_summaries,
            llm_service
        )
        
        return {
            "mode": "summary",
            "meeting_summaries": successful_summaries,
            "overall_summary": overall_summary,
            "key_themes": key_themes,
            "processed_count": len(successful_summaries),
            "total_count": len(meeting_ids)
        }
    
    @staticmethod
    async def _search_with_filter(
        query: str,
        meeting_ids: List[str],
        top_k: int = 10
    ) -> List[Dict[str, Any]]:
        """
        å¸¦è¿‡æ»¤çš„å‘é‡æ£€ç´¢
        
        æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªç®€åŒ–å®ç°ï¼Œå®é™…éœ€è¦å‘é‡åº“æ”¯æŒmetadataè¿‡æ»¤
        å¦‚æœä½ çš„ vector_service ä¸æ”¯æŒï¼Œè¿™é‡Œä¼šæ£€ç´¢æ‰€æœ‰ç»“æœå†è¿‡æ»¤
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            meeting_ids: è¦æ£€ç´¢çš„ä¼šè®®IDåˆ—è¡¨
            top_k: æ£€ç´¢æ•°é‡
        
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        try:
            # TODO: è¿™é‡Œéœ€è¦ä½ çš„ vector_service æ”¯æŒ filters å‚æ•°
            # å¦‚æœä¸æ”¯æŒï¼Œéœ€è¦ä¿®æ”¹ vector.py çš„ search_similar æ–¹æ³•
            
            # ä¸´æ—¶æ–¹æ¡ˆï¼šè°ƒç”¨æ ‡å‡†æ£€ç´¢ï¼Œç„¶åè¿‡æ»¤
            # è¿™ä¸æ˜¯æœ€ä¼˜çš„ï¼Œå› ä¸ºä¼šæ£€ç´¢å¾ˆå¤šä¸ç›¸å…³çš„ç»“æœ
            
            # è·å–å‘é‡
            query_vec = vector_service.get_embedding(query)
            if not query_vec:
                return []
            
            # æ£€ç´¢ï¼ˆè¿™é‡Œå‡è®¾ä½ çš„ collection.query æ”¯æŒè¿‡æ»¤ï¼‰
            # å¦‚æœä¸æ”¯æŒï¼Œéœ€è¦æ£€ç´¢æ›´å¤šç»“æœå†æ‰‹åŠ¨è¿‡æ»¤
            results = vector_service.collection.query(
                query_embeddings=[query_vec],
                n_results=top_k * 2,  # å¤šæ£€ç´¢ä¸€äº›ï¼Œå› ä¸ºè¦è¿‡æ»¤
                include=["documents", "metadatas", "distances"]
            )
            
            # è¿‡æ»¤åªä¿ç•™æŒ‡å®šä¼šè®®çš„ç»“æœ
            filtered_results = []
            
            if results and results.get("documents"):
                documents = results["documents"][0]
                metadatas = results.get("metadatas", [[]])[0]
                distances = results.get("distances", [[]])[0]
                
                for i, doc in enumerate(documents):
                    metadata = metadatas[i] if i < len(metadatas) else {}
                    meeting_id = metadata.get("meeting_id", "")
                    
                    # åªä¿ç•™æŒ‡å®šä¼šè®®çš„ç»“æœ
                    if meeting_id in meeting_ids or str(metadata.get("source_id", "")) in meeting_ids:
                        distance = distances[i] if i < len(distances) else float('inf')
                        similarity = 1 / (1 + distance)
                        
                        filtered_results.append({
                            "text": doc,
                            "metadata": metadata,
                            "score": similarity
                        })
                    
                    # è¾¾åˆ°æ•°é‡é™åˆ¶å°±åœæ­¢
                    if len(filtered_results) >= top_k:
                        break
            
            logger.info(f"ğŸ” æ£€ç´¢åˆ° {len(filtered_results)} æ¡ç›¸å…³å†å²è®°å½•")
            return filtered_results
            
        except Exception as e:
            logger.error(f"âŒ å‘é‡æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    @staticmethod
    async def _get_meeting_content(meeting_id: str) -> str:
        """
        è·å–ä¼šè®®å®Œæ•´å†…å®¹
        
        ä¼˜å…ˆçº§ï¼š
        1. ä»æ•°æ®åº“è·å–ç»“æ„åŒ–æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
        2. ä»å‘é‡åº“è·å–æ‰€æœ‰ç‰‡æ®µå¹¶æ‹¼æ¥
        
        Args:
            meeting_id: ä¼šè®®ID
        
        Returns:
            ä¼šè®®å†…å®¹æ–‡æœ¬
        """
        try:
            if not vector_service or not vector_service.is_available():
                return ""
            
            # ä»å‘é‡åº“è·å–è¯¥ä¼šè®®çš„æ‰€æœ‰ç‰‡æ®µ
            # ä½¿ç”¨ç©ºæŸ¥è¯¢æˆ–ç‰¹å®šæŸ¥è¯¢è·å–æ‰€æœ‰ç‰‡æ®µ
            results = vector_service.collection.get(
                where={"source_id": int(meeting_id)} if meeting_id.isdigit() else {"meeting_id": meeting_id},
                limit=100  # æœ€å¤šè·å–100ä¸ªç‰‡æ®µ
            )
            
            if not results or not results.get("documents"):
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°ä¼šè®® {meeting_id} çš„å†…å®¹")
                return ""
            
            # æ‹¼æ¥æ‰€æœ‰ç‰‡æ®µ
            documents = results["documents"]
            content = "\n".join(documents)
            
            logger.info(f"âœ… è·å–ä¼šè®® {meeting_id} å†…å®¹ï¼Œå…± {len(documents)} ä¸ªç‰‡æ®µ")
            return content
            
        except Exception as e:
            logger.error(f"âŒ è·å–ä¼šè®®å†…å®¹å¤±è´¥: {e}")
            return ""
    
    @staticmethod
    async def _extract_key_themes(
        summaries: List[Dict[str, Any]],
        llm_service
    ) -> List[str]:
        """
        ä»å¤šä¸ªä¼šè®®æ‘˜è¦ä¸­æå–ä¸»è¦ä¸»é¢˜
        
        Args:
            summaries: ä¼šè®®æ‘˜è¦åˆ—è¡¨
            llm_service: LLMæœåŠ¡å®ä¾‹
        
        Returns:
            ä¸»é¢˜å…³é”®è¯åˆ—è¡¨
        """
        try:
            combined = " ".join([s["summary"] for s in summaries])
            
            prompt = f"""
ä»ä»¥ä¸‹ä¼šè®®æ‘˜è¦ä¸­æå– 5 ä¸ªæœ€ä¸»è¦çš„è®¨è®ºä¸»é¢˜ï¼ˆå…³é”®è¯ï¼‰ï¼Œç”¨é€—å·åˆ†éš”ï¼š

{combined}

åªè¾“å‡ºä¸»é¢˜å…³é”®è¯ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""
            
            themes_text = await asyncio.to_thread(llm_service.chat, prompt)
            themes = [t.strip() for t in themes_text.split(",")]
            
            return themes[:5]  # æœ€å¤šè¿”å›5ä¸ª
            
        except Exception as e:
            logger.error(f"âŒ æå–ä¸»é¢˜å¤±è´¥: {e}")
            return []


# åˆ›å»ºå•ä¾‹å®ä¾‹
meeting_history_service = MeetingHistoryService()
