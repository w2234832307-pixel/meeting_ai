"""
LLMæœåŠ¡å·¥å‚
æ ¹æ®é…ç½®åŠ¨æ€é€‰æ‹©LLMæœåŠ¡ï¼ˆDeepSeek API / æœ¬åœ°Qwen3-14bï¼‰
"""
from typing import Protocol

from app.core.config import settings
from app.core.logger import logger
from app.core.exceptions import LLMServiceException


class LLMServiceProtocol(Protocol):
    """LLMæœåŠ¡åè®®ï¼ˆæ¥å£å®šä¹‰ï¼‰"""
    
    def judge_rag(self, raw_text: str, template_id: str) -> dict:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦RAG"""
        ...
    
    def generate_markdown(self, raw_text: str, context: str = "", template_id: str = "default") -> str:
        """ç”Ÿæˆç»“æ„åŒ–æ•°æ®"""
        ...


class LLMServiceFactory:
    """LLMæœåŠ¡å·¥å‚ç±»"""
    
    _instance = None
    _current_service = None
    
    @classmethod
    def get_service(cls) -> LLMServiceProtocol:
        """
        è·å–LLMæœåŠ¡å®ä¾‹ï¼ˆæ ¹æ®é…ç½®ï¼‰
        
        Returns:
            LLMæœåŠ¡å®ä¾‹
        
        Raises:
            LLMServiceException: æœåŠ¡åˆå§‹åŒ–å¤±è´¥
        """
        # æ ¹æ®é…ç½®é€‰æ‹©æœåŠ¡ç±»å‹
        llm_type = settings.LLM_SERVICE_TYPE.lower()
        
        logger.info(f"ğŸ”§ LLMæœåŠ¡ç±»å‹: {llm_type}")
        
        if llm_type == "api":
            return cls._get_api_llm()
        elif llm_type == "local":
            return cls._get_local_llm()
        else:
            raise LLMServiceException(
                f"ä¸æ”¯æŒçš„LLMæœåŠ¡ç±»å‹: {llm_type}ï¼Œè¯·é€‰æ‹© 'api' æˆ– 'local'"
            )
    
    @classmethod
    def _get_api_llm(cls, use_singleton: bool = True):
        """
        è·å–API LLMæœåŠ¡ï¼ˆDeepSeekç­‰ï¼‰
        
        Args:
            use_singleton: æ˜¯å¦ä½¿ç”¨å•ä¾‹ï¼ˆTrue=ä½¿ç”¨ç¼“å­˜çš„å®ä¾‹ï¼ŒFalse=åˆ›å»ºæ–°å®ä¾‹ï¼‰
        """
        try:
            if use_singleton:
                # ä½¿ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–çš„å•ä¾‹
                from app.services.llm import llm_service
                logger.info("âœ… ä½¿ç”¨API LLMæœåŠ¡ (å•ä¾‹æ¨¡å¼)")
                return llm_service
            else:
                # åŠ¨æ€åˆ›å»ºæ–°å®ä¾‹
                from app.services.llm import LLMService
                logger.info("âœ… åˆ›å»ºæ–°çš„API LLMæœåŠ¡å®ä¾‹")
                return LLMService()
            
        except Exception as e:
            logger.error(f"âŒ API LLMæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            raise LLMServiceException(f"API LLMåˆå§‹åŒ–å¤±è´¥: {str(e)}")
    
    @classmethod
    def _get_local_llm(cls, use_singleton: bool = True):
        """
        è·å–æœ¬åœ°LLMæœåŠ¡ï¼ˆQwen3-14bç­‰ï¼‰
        
        Args:
            use_singleton: æ˜¯å¦ä½¿ç”¨å•ä¾‹ï¼ˆTrue=ä½¿ç”¨ç¼“å­˜çš„å®ä¾‹ï¼ŒFalse=åˆ›å»ºæ–°å®ä¾‹ï¼‰
        """
        try:
            if use_singleton:
                # ä½¿ç”¨å•ä¾‹æ¨¡å¼
                from app.services.local_llm import get_local_llm_service
                service = get_local_llm_service()
                logger.info("âœ… ä½¿ç”¨æœ¬åœ°LLMæœåŠ¡ (å•ä¾‹æ¨¡å¼)")
                return service
            else:
                # åŠ¨æ€åˆ›å»ºæ–°å®ä¾‹
                from app.services.local_llm import LocalLLMService
                logger.info("âœ… åˆ›å»ºæ–°çš„æœ¬åœ°LLMæœåŠ¡å®ä¾‹")
                return LocalLLMService(test_on_init=False)  # åŠ¨æ€åˆ›å»ºæ—¶ä¸æµ‹è¯•è¿æ¥
            
        except Exception as e:
            logger.error(f"âŒ æœ¬åœ°LLMæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            raise LLMServiceException(f"æœ¬åœ°LLMåˆå§‹åŒ–å¤±è´¥: {str(e)}")


def get_llm_service() -> LLMServiceProtocol:
    """
    è·å–LLMæœåŠ¡ï¼ˆä¾¿æ·å‡½æ•°ï¼‰
    
    Returns:
        LLMæœåŠ¡å®ä¾‹
    """
    return LLMServiceFactory.get_service()


def get_llm_service_by_name(model_name: str = "auto") -> LLMServiceProtocol:
    """
    æ ¹æ®æ¨¡å‹åç§°åŠ¨æ€è·å–LLMæœåŠ¡
    
    æ”¯æŒçš„æ¨¡å‹ï¼š
    - auto: è‡ªåŠ¨é€‰æ‹©ï¼ˆä½¿ç”¨é…ç½®æ–‡ä»¶çš„é»˜è®¤æ¨¡å‹ï¼‰
    - deepseek: DeepSeek API
    - qwen3: æœ¬åœ° Qwen3-14b
    - api: ä½¿ç”¨APIæ¨¡å¼ï¼ˆå…¼å®¹ï¼‰
    - local: ä½¿ç”¨æœ¬åœ°æ¨¡å¼ï¼ˆå…¼å®¹ï¼‰
    
    Args:
        model_name: æ¨¡å‹åç§°
    
    Returns:
        LLMæœåŠ¡å®ä¾‹
    
    Raises:
        LLMServiceException: æœåŠ¡åˆå§‹åŒ–å¤±è´¥
    """
    # æ¨¡å‹æ˜ å°„
    model_mapping = {
        "deepseek": "api",
        "qwen3": "local",
        "api": "api",
        "local": "local"
    }
    
    # auto æ¨¡å¼ï¼šä½¿ç”¨é…ç½®æ–‡ä»¶çš„é»˜è®¤è®¾ç½®ï¼ˆä½¿ç”¨å•ä¾‹ï¼‰
    if model_name == "auto" or model_name not in model_mapping:
        if model_name != "auto":
            logger.warning(f"âš ï¸ æœªçŸ¥æ¨¡å‹ {model_name}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        return LLMServiceFactory.get_service()
    
    # è·å–æœåŠ¡ç±»å‹
    service_type = model_mapping[model_name]
    
    logger.info(f"ğŸ¯ åŠ¨æ€é€‰æ‹©æ¨¡å‹: {model_name} (ç±»å‹: {service_type})")
    
    # åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ›å»ºæ–°å®ä¾‹
    # å¦‚æœè¯·æ±‚çš„ç±»å‹ä¸å½“å‰é…ç½®ä¸åŒï¼Œåˆ›å»ºæ–°å®ä¾‹ï¼›å¦åˆ™ä½¿ç”¨å•ä¾‹
    use_singleton = (service_type == settings.LLM_SERVICE_TYPE.lower())
    
    if not use_singleton:
        logger.info(f"âš¡ åŠ¨æ€åˆ‡æ¢æ¨¡å¼: {settings.LLM_SERVICE_TYPE} -> {service_type}")
    
    # è·å–æœåŠ¡å®ä¾‹
    if service_type == "api":
        service = LLMServiceFactory._get_api_llm(use_singleton=use_singleton)
    else:
        service = LLMServiceFactory._get_local_llm(use_singleton=use_singleton)
    
    return service
